{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Smart Power documentation Navigation Every project has a dedicated section in the navigation bar. Use the dropdown below the company logo to switch between the Smart Power releases. Specific phrases in the documentation can be found using the search bar under the version selector.","title":"Home"},{"location":"#smart-power-documentation","text":"","title":"Smart Power documentation"},{"location":"#navigation","text":"Every project has a dedicated section in the navigation bar. Use the dropdown below the company logo to switch between the Smart Power releases. Specific phrases in the documentation can be found using the search bar under the version selector.","title":"Navigation"},{"location":"mesh/availability/availability/","text":"Mesh Availability A Mesh availability event provides information about periods during which Mesh objects are unavailable or partially available. The availability functionality helps track and model the operational status of assets throughout time. Types of Availability Events Revision - Represents periods when an object is completely unavailable (e.g., during maintenance or outage) Restriction - Represents periods when an object is partially available with reduced capacity Advanced Restriction - In case of restrictions that require template calculation to represent them it is possible to define Advanced restriction that links calculation with specific event Category Availability Recurrence Availability events can be defined with various recurrence patterns: Single occurrence - One-time events with a specific start and end time Daily - Repeating pattern on a daily basis Weekly - Repeating pattern on a weekly basis Monthly - Repeating pattern on a monthly basis Yearly - Repeating pattern on a yearly basis Each recurrence pattern allows specifying: How often the pattern repeats (e.g., every 2 weeks) When the pattern ends (if applicable) The time interval for each occurrence Instances An instance is a single occurrence of a revision or restriction according to its recurrence pattern. When analyzing availability, you can search for all instances that occur within a specified time period. For example, a weekly revision occurring every Monday for two months would have approximately eight instances, one for each Monday in the specified period. Categories and Statuses Availability events can have: Status - Indicates the current state of the event (e.g., planned, confirmed, canceled) Category - Classifies the type of the event (e.g., maintenance, external constraints) Reason - Text description explaining why the event exists Common Use Cases The availability functionality can be used for: Maintenance Planning - Scheduling and tracking planned downtime periods Capacity Management - Modeling partial capacity constraints Outage Tracking - Documenting unexpected unavailability periods Resource Allocation - Planning operations around known availability constraints When working with availability data, you can search for events affecting specific objects, find all instances occurring within a time period, and incorporate availability information into operational planning and analysis.","title":"Availability"},{"location":"mesh/availability/availability/#mesh-availability","text":"A Mesh availability event provides information about periods during which Mesh objects are unavailable or partially available. The availability functionality helps track and model the operational status of assets throughout time.","title":"Mesh Availability"},{"location":"mesh/availability/availability/#types-of-availability-events","text":"Revision - Represents periods when an object is completely unavailable (e.g., during maintenance or outage) Restriction - Represents periods when an object is partially available with reduced capacity Advanced Restriction - In case of restrictions that require template calculation to represent them it is possible to define Advanced restriction that links calculation with specific event Category","title":"Types of Availability Events"},{"location":"mesh/availability/availability/#availability-recurrence","text":"Availability events can be defined with various recurrence patterns: Single occurrence - One-time events with a specific start and end time Daily - Repeating pattern on a daily basis Weekly - Repeating pattern on a weekly basis Monthly - Repeating pattern on a monthly basis Yearly - Repeating pattern on a yearly basis Each recurrence pattern allows specifying: How often the pattern repeats (e.g., every 2 weeks) When the pattern ends (if applicable) The time interval for each occurrence","title":"Availability Recurrence"},{"location":"mesh/availability/availability/#instances","text":"An instance is a single occurrence of a revision or restriction according to its recurrence pattern. When analyzing availability, you can search for all instances that occur within a specified time period. For example, a weekly revision occurring every Monday for two months would have approximately eight instances, one for each Monday in the specified period.","title":"Instances"},{"location":"mesh/availability/availability/#categories-and-statuses","text":"Availability events can have: Status - Indicates the current state of the event (e.g., planned, confirmed, canceled) Category - Classifies the type of the event (e.g., maintenance, external constraints) Reason - Text description explaining why the event exists","title":"Categories and Statuses"},{"location":"mesh/availability/availability/#common-use-cases","text":"The availability functionality can be used for: Maintenance Planning - Scheduling and tracking planned downtime periods Capacity Management - Modeling partial capacity constraints Outage Tracking - Documenting unexpected unavailability periods Resource Allocation - Planning operations around known availability constraints When working with availability data, you can search for events affecting specific objects, find all instances occurring within a time period, and incorporate availability information into operational planning and analysis.","title":"Common Use Cases"},{"location":"mesh/calculations/calculations/","text":"Calculations in Mesh - general concepts This is an important and unique part of Mesh. It gives Volue and its customers the ability to define time series as expressions, rather than having a separate calculation carried out and let values be stored onto a time series then available for read. Many years ago Volue introduced the concept of virtual time series, which means the calculation is integrated as part of the read operation. Calculation expression language The expression language has a proprietary syntax. It has been around since mid 90's and is widely adopted by the Volue customers to extend their collection of available time series. Some characteristics on the language: The expressions are vector based eliminating the need for complicated loops. References to time series are done by the Mesh search and the navigation language. See example. Standard operators and operator precedence are supported (+,-,*,/). There are built-in functions covering a wide range of operations. Example 1 Assuming we have an expression on a Mesh object type HydroPlant that is bound to a time series attribute definition Income . On the HydroPlant type there is another time series attribute definition Production as well as a time dependent relation to_PriceArea to a PriceArea type object. On the PriceArea object type there is a time series attribute definition Price . The calculation of Income can be expressed like this: ## = @t('.Production') * @t('to_PriceArea.Price') Some details about this simple expression: We have two time series that are multiplied with each other to produce the result, here identified by the macro ## . In this example a reference function @t(searchSpec) is used. It is a function that returns the time series it finds by applying the search specification. The search specification has the \"current instance\", in this case an instance of the type HydroPlant , as its starting point. See the figure below showing a small physical model. In a search specification the dot (.) indicates local to the current object. Therefore '.Production' means a local attribute named Production. The search specification 'to_PriceArea.Price' means to navigate through a named relation (to_PriceArea) and then on the target object lookup the local attribute named Price. When values for a given time interval are requested for the Income series on a model object Brattset, a HydroPlant instance, the search and navigation will see the world from this instance. Navigating to_PriceArea in this case ends up in the PriceArea instance named NO3. Functions Here are some general comments to functions used in expressions: A function is defined as @function_name(arguments) . The arguments may be empty or defined as a comma separated list. Mesh calculation supports six basic data types. This is: A number - represented by letter d A string - represented by letter s A time series - represented by letter t A vector of numbers - represented by letter D A vector of strings - represented by letter S A vector of time series - represented by letter T All functions are registered with an argument list definition and a return value type. For instance, the function t used in the example above has a signature @t(s) -> t . A signature suffix ttsd means 4 arguments: a time series, a time series, a string and a number. Another example: A function named SUM has multiple signatures: @SUM(T) -> t , @SUM(t) -> d and @SUM(D) -> d . The first version takes a vector of time series and returns the sum of these time series, the second version takes a time series and returns a number and the last version takes a vector of numbers and returns a single number. A function implementation will normally have to cope with the fact that time series given as arguments may have different resolutions. Ref. example above: the Production series may have values every 15 minutes and the Price series may have values every hour. The argument to a function can be the result of another function. Calculation expression definition The time series calculation definitions are in general associated with the Mesh model definition. This means that the calculations are defined as part of the domain description and expressed using types and attributes therein. Traditionally, before Mesh, expressions referred to explicit time series and in consequence they were less generic than Mesh based expressions. Mesh and mesh information modelling have created the foundation for generalized expressions, template calculation expressions. In cases where the general template based calculation expression definition does not \"fit\" very well it is possible to associate an override expression directly onto a time series attribute on an instance in the model. This gives a 1:1 definition which must be maintained separately, therefore should be used with caution. Calculation scope with respect to time The Mesh time series calculation definitions normally do not contain anything about which time period or time interval to apply. This is something that is defined as part of the read request, i.e. asking the time series to provide values for a given time interval. A time series result is provided by addressing a time series attribute on a Mesh instance, for instance the Income attribute on a HydroPlant instance (ref. previous example), and give it a time interval to get values for (the requested interval ). Usually, all the values are calculated on the requested interval. But there might be functions that will need other data input. Examples: @DELTA(@t('.Temperature')) @TS_GLIDING_AVERAGE(@t('.Temperature'), 7) @ACCUMULATE(@t('.Precipitation'), 'YEAR') @TS_OFFSET(@t('.Temperature'), 'DAY', 1) The need for extra data on these examples are commented below. Time interval is indicated by a line where equal sign is part of the requested interval, and dots indicate extra data needed. First example @DELTA(@t('.Temperature')) : Delta operation needs previous value, hence one extra value (represented by a dot) at the beginning of requested interval. .==================== Second example @TS_GLIDING_AVERAGE(@t('.Temperature'), 7) : A time series gliding operation will use a value window to produce a center value. Hence it will need some extra data at the front and at the end to produce a consistent result. When the value is 7 this means 3 values in the front and 3 values at the end. ...====================... Third example @ACCUMULATE(@t('.Precipitation'), 'YEAR') : A time series accumulate operation will need the data from a defined start, here start of year. ..............//........==================== The // indicates that this might be many dots, depending on the start of the requested interval. Fourth example @TS_OFFSET(@t('.Temperature'), 'DAY', 1) : The function TS_OFFSET moves values from one time interval to another. In this example, the values are moved one day, i.e to the next day relative to the requested time interval. ......============ Here the dots represent 1 day and the requested time interval 2 days. Time Zones There are situations where other time zones are involved: Volue database, currently the owner of the time series data in Volue context, is using a concept of a database zone. In our European context this is UTC+1. Default time zone in calculation context is, due to backwards compatibility, the same as DB zone - UTC+1. Some calculation operations are explicitly related to time zones. For example, a transformation of a time series from higher resolution to lower resolution often needs to have a definition of the zone. A fixed interval hour series transformed to a day series needs to know which zone this day is related to. See discussion of a @TRANSFORM example below. In some cases, the function arguments are time point macros, they will also need a time zone context to have a precise meaning. See the separate chapter on time macros. Using @TRANSFORM calculation functions This function comes in many different variants defined by the different argument signatures. Here, two of them are discussed: ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM') ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM', 'LT') ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM', 'UTC') All examples transform an input series from its source resolution, for example hour resolution, into a day resolution result series. Because the functions are using DB zone (UTC+1) as a basic zone (without DaylightSavingTime (DST)) the first result will contain values created from all hours in the UTC+1 day and night. The second example will do the same, but will use zone UTC+1 with DST as its definition. This means most values come from 24 source values but could also be based on 23 or 25 values due to DST season shift. The last example is referring to the UTC zone with no DST so values are shifted one hour compared to the first two examples. Time point macros A time point specification can be explicit or based on the macros that make time point follow current time. Examples related to current time: 202002291336 -> Saturday 29 February 2020 13:36:00 DAY - Start of the current day in UTC+1 zone WEEK+2d+14h-10x - Is interpreted as start of this week (UTC+1) plus 2 days plus 14 hours minus 10 minutes Available base codes are YEAR, MONTH, WEEK, DAY, MIN15 and NOW. The function named @TIME_MASK is having some examples where the mask values are created from such macros. See the reference documentation for details. Basic time series operations Calculation functions and operator implementations must be able to cope with different time resolutions. In some cases there are functional requirements with regards to the time series arguments given to the function, but in general not. To cope with different resolutions, we operate with something called a functional value. It is basically a value from the time series outside the concrete points on the series. Example 1, add an 15 minute series and an hour series The first example shows the result of adding two time series, one with hour resolution and one with 15 minutes resolution. The light grey values on Ts1 are the \"functional value\" of this series on the time points not found on the time series. As we see, the understanding of a functional value is different whether the shape of series is defined to be stepwise or linear. The result of this addition will have a 15 minutes resolution and if one of the operands are linear, the result will also be defined as linear. Example 2, applying the MAX function on two time series arguments The second example contains two input time series and a result time series. The first series is a fixed resolution series of linear shape and the second is a breakpoint time series with a stepwise shape. The function applied (@MAX) is taking two arguments so the signature is \"MAX|tt\". To make the result more \"outstanding\" a constant value 2 is added to the result. PS! The result curve is added manually so it is probably not perfectly shaped, but good enough to see how the result is created from time points coming from one of the time series, as well as new time points coming from the functional values that represents crossing between them. These points are indicated by vertical dash-dot lines.","title":"General"},{"location":"mesh/calculations/calculations/#calculations-in-mesh-general-concepts","text":"This is an important and unique part of Mesh. It gives Volue and its customers the ability to define time series as expressions, rather than having a separate calculation carried out and let values be stored onto a time series then available for read. Many years ago Volue introduced the concept of virtual time series, which means the calculation is integrated as part of the read operation.","title":"Calculations in Mesh - general concepts"},{"location":"mesh/calculations/calculations/#calculation-expression-language","text":"The expression language has a proprietary syntax. It has been around since mid 90's and is widely adopted by the Volue customers to extend their collection of available time series. Some characteristics on the language: The expressions are vector based eliminating the need for complicated loops. References to time series are done by the Mesh search and the navigation language. See example. Standard operators and operator precedence are supported (+,-,*,/). There are built-in functions covering a wide range of operations.","title":"Calculation expression language"},{"location":"mesh/calculations/calculations/#example-1","text":"Assuming we have an expression on a Mesh object type HydroPlant that is bound to a time series attribute definition Income . On the HydroPlant type there is another time series attribute definition Production as well as a time dependent relation to_PriceArea to a PriceArea type object. On the PriceArea object type there is a time series attribute definition Price . The calculation of Income can be expressed like this: ## = @t('.Production') * @t('to_PriceArea.Price') Some details about this simple expression: We have two time series that are multiplied with each other to produce the result, here identified by the macro ## . In this example a reference function @t(searchSpec) is used. It is a function that returns the time series it finds by applying the search specification. The search specification has the \"current instance\", in this case an instance of the type HydroPlant , as its starting point. See the figure below showing a small physical model. In a search specification the dot (.) indicates local to the current object. Therefore '.Production' means a local attribute named Production. The search specification 'to_PriceArea.Price' means to navigate through a named relation (to_PriceArea) and then on the target object lookup the local attribute named Price. When values for a given time interval are requested for the Income series on a model object Brattset, a HydroPlant instance, the search and navigation will see the world from this instance. Navigating to_PriceArea in this case ends up in the PriceArea instance named NO3.","title":"Example 1"},{"location":"mesh/calculations/calculations/#functions","text":"Here are some general comments to functions used in expressions: A function is defined as @function_name(arguments) . The arguments may be empty or defined as a comma separated list. Mesh calculation supports six basic data types. This is: A number - represented by letter d A string - represented by letter s A time series - represented by letter t A vector of numbers - represented by letter D A vector of strings - represented by letter S A vector of time series - represented by letter T All functions are registered with an argument list definition and a return value type. For instance, the function t used in the example above has a signature @t(s) -> t . A signature suffix ttsd means 4 arguments: a time series, a time series, a string and a number. Another example: A function named SUM has multiple signatures: @SUM(T) -> t , @SUM(t) -> d and @SUM(D) -> d . The first version takes a vector of time series and returns the sum of these time series, the second version takes a time series and returns a number and the last version takes a vector of numbers and returns a single number. A function implementation will normally have to cope with the fact that time series given as arguments may have different resolutions. Ref. example above: the Production series may have values every 15 minutes and the Price series may have values every hour. The argument to a function can be the result of another function.","title":"Functions"},{"location":"mesh/calculations/calculations/#calculation-expression-definition","text":"The time series calculation definitions are in general associated with the Mesh model definition. This means that the calculations are defined as part of the domain description and expressed using types and attributes therein. Traditionally, before Mesh, expressions referred to explicit time series and in consequence they were less generic than Mesh based expressions. Mesh and mesh information modelling have created the foundation for generalized expressions, template calculation expressions. In cases where the general template based calculation expression definition does not \"fit\" very well it is possible to associate an override expression directly onto a time series attribute on an instance in the model. This gives a 1:1 definition which must be maintained separately, therefore should be used with caution.","title":"Calculation expression definition"},{"location":"mesh/calculations/calculations/#calculation-scope-with-respect-to-time","text":"The Mesh time series calculation definitions normally do not contain anything about which time period or time interval to apply. This is something that is defined as part of the read request, i.e. asking the time series to provide values for a given time interval. A time series result is provided by addressing a time series attribute on a Mesh instance, for instance the Income attribute on a HydroPlant instance (ref. previous example), and give it a time interval to get values for (the requested interval ). Usually, all the values are calculated on the requested interval. But there might be functions that will need other data input. Examples: @DELTA(@t('.Temperature')) @TS_GLIDING_AVERAGE(@t('.Temperature'), 7) @ACCUMULATE(@t('.Precipitation'), 'YEAR') @TS_OFFSET(@t('.Temperature'), 'DAY', 1) The need for extra data on these examples are commented below. Time interval is indicated by a line where equal sign is part of the requested interval, and dots indicate extra data needed.","title":"Calculation scope with respect to time"},{"location":"mesh/calculations/calculations/#first-example","text":"@DELTA(@t('.Temperature')) : Delta operation needs previous value, hence one extra value (represented by a dot) at the beginning of requested interval. .====================","title":"First example"},{"location":"mesh/calculations/calculations/#second-example","text":"@TS_GLIDING_AVERAGE(@t('.Temperature'), 7) : A time series gliding operation will use a value window to produce a center value. Hence it will need some extra data at the front and at the end to produce a consistent result. When the value is 7 this means 3 values in the front and 3 values at the end. ...====================...","title":"Second example"},{"location":"mesh/calculations/calculations/#third-example","text":"@ACCUMULATE(@t('.Precipitation'), 'YEAR') : A time series accumulate operation will need the data from a defined start, here start of year. ..............//........==================== The // indicates that this might be many dots, depending on the start of the requested interval.","title":"Third example"},{"location":"mesh/calculations/calculations/#fourth-example","text":"@TS_OFFSET(@t('.Temperature'), 'DAY', 1) : The function TS_OFFSET moves values from one time interval to another. In this example, the values are moved one day, i.e to the next day relative to the requested time interval. ......============ Here the dots represent 1 day and the requested time interval 2 days.","title":"Fourth example"},{"location":"mesh/calculations/calculations/#time-zones","text":"There are situations where other time zones are involved: Volue database, currently the owner of the time series data in Volue context, is using a concept of a database zone. In our European context this is UTC+1. Default time zone in calculation context is, due to backwards compatibility, the same as DB zone - UTC+1. Some calculation operations are explicitly related to time zones. For example, a transformation of a time series from higher resolution to lower resolution often needs to have a definition of the zone. A fixed interval hour series transformed to a day series needs to know which zone this day is related to. See discussion of a @TRANSFORM example below. In some cases, the function arguments are time point macros, they will also need a time zone context to have a precise meaning. See the separate chapter on time macros.","title":"Time Zones"},{"location":"mesh/calculations/calculations/#using-transform-calculation-functions","text":"This function comes in many different variants defined by the different argument signatures. Here, two of them are discussed: ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM') ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM', 'LT') ## = @TRANSFORM(@t('.Consumption'), 'DAY', 'SUM', 'UTC') All examples transform an input series from its source resolution, for example hour resolution, into a day resolution result series. Because the functions are using DB zone (UTC+1) as a basic zone (without DaylightSavingTime (DST)) the first result will contain values created from all hours in the UTC+1 day and night. The second example will do the same, but will use zone UTC+1 with DST as its definition. This means most values come from 24 source values but could also be based on 23 or 25 values due to DST season shift. The last example is referring to the UTC zone with no DST so values are shifted one hour compared to the first two examples.","title":"Using @TRANSFORM calculation functions"},{"location":"mesh/calculations/calculations/#time-point-macros","text":"A time point specification can be explicit or based on the macros that make time point follow current time. Examples related to current time: 202002291336 -> Saturday 29 February 2020 13:36:00 DAY - Start of the current day in UTC+1 zone WEEK+2d+14h-10x - Is interpreted as start of this week (UTC+1) plus 2 days plus 14 hours minus 10 minutes Available base codes are YEAR, MONTH, WEEK, DAY, MIN15 and NOW. The function named @TIME_MASK is having some examples where the mask values are created from such macros. See the reference documentation for details.","title":"Time point macros"},{"location":"mesh/calculations/calculations/#basic-time-series-operations","text":"Calculation functions and operator implementations must be able to cope with different time resolutions. In some cases there are functional requirements with regards to the time series arguments given to the function, but in general not. To cope with different resolutions, we operate with something called a functional value. It is basically a value from the time series outside the concrete points on the series.","title":"Basic time series operations"},{"location":"mesh/calculations/calculations/#example-1-add-an-15-minute-series-and-an-hour-series","text":"The first example shows the result of adding two time series, one with hour resolution and one with 15 minutes resolution. The light grey values on Ts1 are the \"functional value\" of this series on the time points not found on the time series. As we see, the understanding of a functional value is different whether the shape of series is defined to be stepwise or linear. The result of this addition will have a 15 minutes resolution and if one of the operands are linear, the result will also be defined as linear.","title":"Example 1, add an 15 minute series and an hour series"},{"location":"mesh/calculations/calculations/#example-2-applying-the-max-function-on-two-time-series-arguments","text":"The second example contains two input time series and a result time series. The first series is a fixed resolution series of linear shape and the second is a breakpoint time series with a stepwise shape. The function applied (@MAX) is taking two arguments so the signature is \"MAX|tt\". To make the result more \"outstanding\" a constant value 2 is added to the result. PS! The result curve is added manually so it is probably not perfectly shaped, but good enough to see how the result is created from time points coming from one of the time series, as well as new time points coming from the functional values that represents crossing between them. These points are indicated by vertical dash-dot lines.","title":"Example 2, applying the MAX function on two time series arguments"},{"location":"mesh/calculations/functions/abs/","text":"ABS About the function This function is used to determine the absolute value(s) for a time series. Syntax ABS(t) # Type Description 1 t Time series Example Temperature_hour_VV = @ABS(@t('Temperature_hour_raw')) In Time 14, the resulting absolute value of -5,00 is 5,00.","title":"ABS"},{"location":"mesh/calculations/functions/abs/#abs","text":"","title":"ABS"},{"location":"mesh/calculations/functions/abs/#about-the-function","text":"This function is used to determine the absolute value(s) for a time series.","title":"About the function"},{"location":"mesh/calculations/functions/abs/#syntax","text":"ABS(t) # Type Description 1 t Time series","title":"Syntax"},{"location":"mesh/calculations/functions/abs/#example","text":"Temperature_hour_VV = @ABS(@t('Temperature_hour_raw')) In Time 14, the resulting absolute value of -5,00 is 5,00.","title":"Example"},{"location":"mesh/calculations/functions/accumulate/","text":"ACCUMULATE Accumulates values for some periods for a time series. When entering a new sub period, the accumulation buffer is reset. Syntax 1 ACCUMULATE(d,s,t[,d,d]) Description # Type Description 1 d Initial value 2 s Start time specification. May be a macro definition or a fully specified time point on the YYYYMMDDhhmmssxxx format. A calendar name may be used as prefix on this specification. Default is current standard time (utc+1 in Norwegian setup). 3 t Input data series (fixed interval). 4 d Multiplication factor A. If omitted, value is 1.0. 5 d Offset factor B. If omitted, value is 0. Syntax 2 ACCUMULATE(t,[s],s) Description # Type Description 1 t Input time series (fixed interval). 2 s Optional. Accumulation from start or end of the interval given in the next argument. \u2019>\u2019 means from the start of the interval and forward. 3 s Accumulation interval. Eg. \u2018DAY\u2019, \u2018WEEK\u2019, \u2018MONTH, \u2018YEAR\u2019. You can set accumulation period to HYDYEAR, i.e. from 1. September until next 1. September (standard calendar). You can also use a prefix to overrule the standard time (utc+1 in Norwegian setup). Eg. \u2018UTCWEEK\u2019. Example 1 - accumulation syntax1 @ACCUMULATE(0.0, 'UTC20140101', @t('TsAccInput'), 1.0, 0.0) The example starts accumulation at 1. January (UTC calendar) with initial value 0.0 and value at next time point t is 0.0 + 1.0 * TsAccInput[t] + 0.0 or Result[t] = initialValue + Factor A * TsAccInput[t] + Factor B for the first value and Result[t] = Result[t-1] + Factor A * TsAccInput[t] + Factor B for the next values. Example 2 - accumulation syntax1 @ACCUMULATE(0.0, 'YEAR+10d', @t('TsAccInput')) The example starts accumulation 10th of January (UTC calendar) with initial value 0.0. No multiplication or offset factors are used. Example 3 - accumulation syntax2 ## = @ACCUMULATE(@t('Precipitation_hour_operative'),'>', 'HYDYEAR') Accumulates the precipitation for each hydrological year. Example 4 - accumulation syntax2 ## = @ACCUMULATE(@t('Precipitation_hour_operative'),'WEEK') Accumulates the precipitation for each week. Example 5 - accumulation of bucket precipitation using explicit extended periods The following example is a general expression for a year's accumulation of precipitation combined with the Time function and extended period functions: tstart = @Time('YEAR',@Time('SOP')) viewEndTime = @Time('EOP') @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') @PushExtPeriod('y', tstart, @Time('EOP')) Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') ## = @ACCUMULATE(DeltaClipped, '>','YEAR') In the following example from Nimbus, the function has accumulated the precipitation from the turn of the year. The start value (tstart), >0, is displayed in the blue curve: In the following example from Nimbus, the presentation starts later in the year than in the previous example. The start value (tsstar) is displayed in the blue chart: Description of the expressions in this example: Expression Description tstart = @Time('YEAR',@Time('SOP')) Finds the start time for the chart presentation. This example uses the YEAR macro (the start of the year), combined with a reference time indicating the report start. If the reference time is not included, the report displays the current year. See also description of the Time function. viewEndTime = @Time('EOP') The end time for the report. @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') Extend relevant calculation period with one hour before the relevant start year. This example shows a linear time arithmetic by using tstart with the length of an hour in internal time format. This gives necessary data to the DELTA function in the next block. Note! This example only gives a dummy calculation (multiplied with 1), but in reality you would calculate with MIX, validate and correct functions. @PushExtPeriod('y', tstart, @Time('EOP')) Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') Runs DELTA and removes large negative contributions on the required period. ## = @ACCUMULATE(DeltaClipped,'>', 'YEAR') Calculates the result. Syntax 3 ACCUMULATE(t,s,d) Description Type Description t Input data series (fixed interval). s Accumulation from start or end of the interval given in the next argument. \u2019>\u2019 means from the start of the interval and forward. \u2019<\u2019 means from the end of the interval and backwards. d Accumulation period given as number of points.","title":"ACCUMULATE"},{"location":"mesh/calculations/functions/accumulate/#accumulate","text":"Accumulates values for some periods for a time series. When entering a new sub period, the accumulation buffer is reset. Syntax 1 ACCUMULATE(d,s,t[,d,d]) Description # Type Description 1 d Initial value 2 s Start time specification. May be a macro definition or a fully specified time point on the YYYYMMDDhhmmssxxx format. A calendar name may be used as prefix on this specification. Default is current standard time (utc+1 in Norwegian setup). 3 t Input data series (fixed interval). 4 d Multiplication factor A. If omitted, value is 1.0. 5 d Offset factor B. If omitted, value is 0. Syntax 2 ACCUMULATE(t,[s],s) Description # Type Description 1 t Input time series (fixed interval). 2 s Optional. Accumulation from start or end of the interval given in the next argument. \u2019>\u2019 means from the start of the interval and forward. 3 s Accumulation interval. Eg. \u2018DAY\u2019, \u2018WEEK\u2019, \u2018MONTH, \u2018YEAR\u2019. You can set accumulation period to HYDYEAR, i.e. from 1. September until next 1. September (standard calendar). You can also use a prefix to overrule the standard time (utc+1 in Norwegian setup). Eg. \u2018UTCWEEK\u2019. Example 1 - accumulation syntax1 @ACCUMULATE(0.0, 'UTC20140101', @t('TsAccInput'), 1.0, 0.0) The example starts accumulation at 1. January (UTC calendar) with initial value 0.0 and value at next time point t is 0.0 + 1.0 * TsAccInput[t] + 0.0 or Result[t] = initialValue + Factor A * TsAccInput[t] + Factor B for the first value and Result[t] = Result[t-1] + Factor A * TsAccInput[t] + Factor B for the next values. Example 2 - accumulation syntax1 @ACCUMULATE(0.0, 'YEAR+10d', @t('TsAccInput')) The example starts accumulation 10th of January (UTC calendar) with initial value 0.0. No multiplication or offset factors are used. Example 3 - accumulation syntax2 ## = @ACCUMULATE(@t('Precipitation_hour_operative'),'>', 'HYDYEAR') Accumulates the precipitation for each hydrological year. Example 4 - accumulation syntax2 ## = @ACCUMULATE(@t('Precipitation_hour_operative'),'WEEK') Accumulates the precipitation for each week. Example 5 - accumulation of bucket precipitation using explicit extended periods The following example is a general expression for a year's accumulation of precipitation combined with the Time function and extended period functions: tstart = @Time('YEAR',@Time('SOP')) viewEndTime = @Time('EOP') @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') @PushExtPeriod('y', tstart, @Time('EOP')) Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') ## = @ACCUMULATE(DeltaClipped, '>','YEAR') In the following example from Nimbus, the function has accumulated the precipitation from the turn of the year. The start value (tstart), >0, is displayed in the blue curve: In the following example from Nimbus, the presentation starts later in the year than in the previous example. The start value (tsstar) is displayed in the blue chart: Description of the expressions in this example: Expression Description tstart = @Time('YEAR',@Time('SOP')) Finds the start time for the chart presentation. This example uses the YEAR macro (the start of the year), combined with a reference time indicating the report start. If the reference time is not included, the report displays the current year. See also description of the Time function. viewEndTime = @Time('EOP') The end time for the report. @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') Extend relevant calculation period with one hour before the relevant start year. This example shows a linear time arithmetic by using tstart with the length of an hour in internal time format. This gives necessary data to the DELTA function in the next block. Note! This example only gives a dummy calculation (multiplied with 1), but in reality you would calculate with MIX, validate and correct functions. @PushExtPeriod('y', tstart, @Time('EOP')) Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') Runs DELTA and removes large negative contributions on the required period. ## = @ACCUMULATE(DeltaClipped,'>', 'YEAR') Calculates the result. Syntax 3 ACCUMULATE(t,s,d)","title":"ACCUMULATE"},{"location":"mesh/calculations/functions/accumulate/#description","text":"Type Description t Input data series (fixed interval). s Accumulation from start or end of the interval given in the next argument. \u2019>\u2019 means from the start of the interval and forward. \u2019<\u2019 means from the end of the interval and backwards. d Accumulation period given as number of points.","title":"Description"},{"location":"mesh/calculations/functions/acos/","text":"ACOS About the function Arc cosinus to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as argument. Note! The values of the result are in radians. Syntax ACOS(t) # Type Description 1 t Time series","title":"ACOS"},{"location":"mesh/calculations/functions/acos/#acos","text":"About the function Arc cosinus to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as argument. Note! The values of the result are in radians. Syntax ACOS(t) # Type Description 1 t Time series","title":"ACOS"},{"location":"mesh/calculations/functions/allocate_reserves/","text":"AllocateReserves About the function This function can be used to distribute values on a reserves time series onto a set of target time series based on capacity and priority information. For example, distribute a total requested production onto production units. It is a \"centralized\" function that access multiple Mesh objects and put the results into target series on multiple Mesh objects, unlike the traditional calculation functions that returns the result to the caller that put it on the time series object associated with that attribute. The function is highly configurable and can be adapted to many different structures. It uses a search expression to define the scope of the operation and uses attribute names to inform where the input data is found. The priority time series is the basis for selecting which object that contribute with its capacity to fulfil the total request. Values on this priority series should be from 1 and upwards. 1 is highest priority. The values do not need to be a continuous sequence because the function does a floating point-based sorting to get the correct order at a specific time. If the priority value is 0, the associated unit does not contribute to reserves at all. If there are no time series connected to priority, it is given a priority value of 1000. Successive cases where this series is missing get s value 1001 etc. Syntax AllocateReserves(t,s,s,s,s) Description # Type Description 1 t A fixed interval time series with the requested total value to distribute onto result series found on participating Mesh objects 2 s A search expression that defines the set of Mesh objects that participates in the distribution of total value from argument 1. The search expression should end up in a Mesh \"node\" object, not a time series or another attribute directly. If the search expression has the prefix \"Model:\" it means the search is applied from root level of current Mesh model (Model: is of course then removed from search definition). 3 s The name of the attribute on the participating Mesh object that contains a time series with priority values. Can be a time series of any resolution, normally a break point series. 4 s The name of the attribute on the participating Mesh object that contains a time series with capacity values. Can be a time series of any resolution. 5 s The name of the attribute on the participating Mesh object that contains a time series to receive the result values. The resolution of this time series must be the same as the one in first argument. The AllocateReserves function normally returns a time series which is equal to the requested series (first argument). In case the function is failing, it returns a breakpoint series with a NaN value at the beginning of the requested time period. The function is logging info and potential error messages to the Mesh log. Example The figure below shows an example Mesh object structure with 3 hierarchical levels. On top level there is an object that have two time series attributes. TriggerAttribute is having a connection to an expression like this: ## = @AllocateReserves(@t('.TotalRequest'),'*[.Type=Unit]','Priority','Capacity','Allocated') From the expression we can observe the following: The first argument is bound to a time series attribute on the same object as the time series calculation attribute. The second argument is a simple search expression that find all instances of type Unit that are hierarchically related to the position where the calculation is defined. In this example it will be 6 Unit objects The next three arguments refer to time series attribute names on the Unit object type. This means that the definition of Mesh object type Unit must have these attribute names and they must be time series. The Priority series contains information that is used order the allocation sequence. The Capacity series contains information on how much this unit can contribute to absorb the total requested volume found on time series in first argument. The Allocated series will get the results from the AllocateReserves calculation.","title":"Allocate_Reserves"},{"location":"mesh/calculations/functions/allocate_reserves/#allocatereserves","text":"","title":"AllocateReserves"},{"location":"mesh/calculations/functions/allocate_reserves/#about-the-function","text":"This function can be used to distribute values on a reserves time series onto a set of target time series based on capacity and priority information. For example, distribute a total requested production onto production units. It is a \"centralized\" function that access multiple Mesh objects and put the results into target series on multiple Mesh objects, unlike the traditional calculation functions that returns the result to the caller that put it on the time series object associated with that attribute. The function is highly configurable and can be adapted to many different structures. It uses a search expression to define the scope of the operation and uses attribute names to inform where the input data is found. The priority time series is the basis for selecting which object that contribute with its capacity to fulfil the total request. Values on this priority series should be from 1 and upwards. 1 is highest priority. The values do not need to be a continuous sequence because the function does a floating point-based sorting to get the correct order at a specific time. If the priority value is 0, the associated unit does not contribute to reserves at all. If there are no time series connected to priority, it is given a priority value of 1000. Successive cases where this series is missing get s value 1001 etc.","title":"About the function"},{"location":"mesh/calculations/functions/allocate_reserves/#syntax","text":"AllocateReserves(t,s,s,s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/allocate_reserves/#description","text":"# Type Description 1 t A fixed interval time series with the requested total value to distribute onto result series found on participating Mesh objects 2 s A search expression that defines the set of Mesh objects that participates in the distribution of total value from argument 1. The search expression should end up in a Mesh \"node\" object, not a time series or another attribute directly. If the search expression has the prefix \"Model:\" it means the search is applied from root level of current Mesh model (Model: is of course then removed from search definition). 3 s The name of the attribute on the participating Mesh object that contains a time series with priority values. Can be a time series of any resolution, normally a break point series. 4 s The name of the attribute on the participating Mesh object that contains a time series with capacity values. Can be a time series of any resolution. 5 s The name of the attribute on the participating Mesh object that contains a time series to receive the result values. The resolution of this time series must be the same as the one in first argument. The AllocateReserves function normally returns a time series which is equal to the requested series (first argument). In case the function is failing, it returns a breakpoint series with a NaN value at the beginning of the requested time period. The function is logging info and potential error messages to the Mesh log.","title":"Description"},{"location":"mesh/calculations/functions/allocate_reserves/#example","text":"The figure below shows an example Mesh object structure with 3 hierarchical levels. On top level there is an object that have two time series attributes. TriggerAttribute is having a connection to an expression like this: ## = @AllocateReserves(@t('.TotalRequest'),'*[.Type=Unit]','Priority','Capacity','Allocated') From the expression we can observe the following: The first argument is bound to a time series attribute on the same object as the time series calculation attribute. The second argument is a simple search expression that find all instances of type Unit that are hierarchically related to the position where the calculation is defined. In this example it will be 6 Unit objects The next three arguments refer to time series attribute names on the Unit object type. This means that the definition of Mesh object type Unit must have these attribute names and they must be time series. The Priority series contains information that is used order the allocation sequence. The Capacity series contains information on how much this unit can contribute to absorb the total requested volume found on time series in first argument. The Allocated series will get the results from the AllocateReserves calculation.","title":"Example"},{"location":"mesh/calculations/functions/asin/","text":"ASIN About the function Arc sine to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as argument. Note! The values of the result are in radians. Syntax ASIN(t) # Type Description 1 t Time series","title":"ASIN"},{"location":"mesh/calculations/functions/asin/#asin","text":"About the function Arc sine to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as argument. Note! The values of the result are in radians. Syntax ASIN(t) # Type Description 1 t Time series","title":"ASIN"},{"location":"mesh/calculations/functions/at/","text":"AT About the function Retrieves an element from an object. Relevant object types are array of time series, numbers or time series. Syntax AT(T,d) AT(D,d) AT(t,s) Description # Type Description 1 T Array of time series. 1 t Time series. 1 D Array of floating-point numbers. 2 s Time argument. May be a macro expanded to time point. Examples: DAY+10h, UTC20141124 2 d Lookup index, the first value has index 0. The following variants exist: Variant Description @AT(T,d) Returns one of the time series in the input array, based on the lookup index in argument 2. Index 0, returns the first time series in the array, index 1 returns the second time series in the array, etc. @AT(D,d) Returns a single number from the array in argument 1, based on the lookup index in argument 2. @AT(t,s) Treats t as an array. Returns a single value (a double) from the time series, based on the lookup time in argument 2. The time argument may be a macro expanded to time point. Looking up an index outside [0,n-1], where n is the number of elements, returns NaN. Example DArray = {10,11,12,13,14} Res1 = @AT(DArray,0) Res2 = @AT(DArray,2) Result: Res1=10 and Res2=12, that is 0-based index lookup.","title":"AT"},{"location":"mesh/calculations/functions/at/#at","text":"","title":"AT"},{"location":"mesh/calculations/functions/at/#about-the-function","text":"Retrieves an element from an object. Relevant object types are array of time series, numbers or time series.","title":"About the function"},{"location":"mesh/calculations/functions/at/#syntax","text":"AT(T,d) AT(D,d) AT(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/at/#description","text":"# Type Description 1 T Array of time series. 1 t Time series. 1 D Array of floating-point numbers. 2 s Time argument. May be a macro expanded to time point. Examples: DAY+10h, UTC20141124 2 d Lookup index, the first value has index 0. The following variants exist: Variant Description @AT(T,d) Returns one of the time series in the input array, based on the lookup index in argument 2. Index 0, returns the first time series in the array, index 1 returns the second time series in the array, etc. @AT(D,d) Returns a single number from the array in argument 1, based on the lookup index in argument 2. @AT(t,s) Treats t as an array. Returns a single value (a double) from the time series, based on the lookup time in argument 2. The time argument may be a macro expanded to time point. Looking up an index outside [0,n-1], where n is the number of elements, returns NaN.","title":"Description"},{"location":"mesh/calculations/functions/at/#example","text":"DArray = {10,11,12,13,14} Res1 = @AT(DArray,0) Res2 = @AT(DArray,2) Result: Res1=10 and Res2=12, that is 0-based index lookup.","title":"Example"},{"location":"mesh/calculations/functions/atan/","text":"ATAN About the function Arc tangent to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as the argument. Note! The values of the result are in radians. Syntax ATAN(t) # Type Description 1 t Time series","title":"ATAN"},{"location":"mesh/calculations/functions/atan/#atan","text":"About the function Arc tangent to values on given time series. The function takes a time series as argument and returns the result as a time series with the same properties as the argument. Note! The values of the result are in radians. Syntax ATAN(t) # Type Description 1 t Time series","title":"ATAN"},{"location":"mesh/calculations/functions/bool/","text":"BOOL About the function This function converts expressions to purely logical values, i.e. 1 for true and 0 for false. In general, all the values in the input are converted to true (even zeroes), and only NaN is converted to false. However, the BOOL(t,d,s) variant allows to specify a numeric value which will also be converted to false if present in the input; this is normally set to 0. If the input is a time series, the output is a time series with the same resolution as the input time series. Syntax BOOL(t) BOOL(d) BOOL(t,d[,s]) # Type Description 1 t or d For BOOL(t), t is a time series. For BOOL(d), d is either a numerical value or NaN. 2 d For BOOL(t,d,s), d is a number which will be converted to false if present in t. 3 s If present in BOOL(t,d,s), it must be set to \"COMPRESS\". If the input is a break point time series, this causes consecutive equal values in the output to be removed. Examples Example 1: @BOOL(d) @BOOL(NaN) Returns 0. @BOOL(0) Returns 1. Only NaN is converted to false. Example 2: @BOOL(t) Temperature_hour_VV = @BOOL(@t('Temperature_hour_raw')) All values are set to true (1) except from NaN, which is false (0), e.g. Example 3: @BOOL(t,d) Temperature_hour_VV = @BOOL(@t('Temperature_hour_raw'),0) Returns a time series with values: 1 when the value in the input series exist and is different from 0. 0 when the value in the input series is 0 or missing (NaN). For example: Example 4: @BOOL(t,d,s) If we have the following input time series: TsBrp = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+40x','HOUR+50x'},{12,15,15,0,20},'VARINT') Using the following expression, we can convert the input to the time series below: Temperature_hour_VV = @BOOL(TsBrp,0,'COMPRESS')","title":"Bool"},{"location":"mesh/calculations/functions/bool/#bool","text":"","title":"BOOL"},{"location":"mesh/calculations/functions/bool/#about-the-function","text":"This function converts expressions to purely logical values, i.e. 1 for true and 0 for false. In general, all the values in the input are converted to true (even zeroes), and only NaN is converted to false. However, the BOOL(t,d,s) variant allows to specify a numeric value which will also be converted to false if present in the input; this is normally set to 0. If the input is a time series, the output is a time series with the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/bool/#syntax","text":"BOOL(t) BOOL(d) BOOL(t,d[,s]) # Type Description 1 t or d For BOOL(t), t is a time series. For BOOL(d), d is either a numerical value or NaN. 2 d For BOOL(t,d,s), d is a number which will be converted to false if present in t. 3 s If present in BOOL(t,d,s), it must be set to \"COMPRESS\". If the input is a break point time series, this causes consecutive equal values in the output to be removed.","title":"Syntax"},{"location":"mesh/calculations/functions/bool/#examples","text":"","title":"Examples"},{"location":"mesh/calculations/functions/bool/#example-1","text":"@BOOL(d) @BOOL(NaN) Returns 0. @BOOL(0) Returns 1. Only NaN is converted to false.","title":"Example 1:"},{"location":"mesh/calculations/functions/bool/#example-2-boolt","text":"Temperature_hour_VV = @BOOL(@t('Temperature_hour_raw')) All values are set to true (1) except from NaN, which is false (0), e.g.","title":"Example 2: @BOOL(t)"},{"location":"mesh/calculations/functions/bool/#example-3-booltd","text":"Temperature_hour_VV = @BOOL(@t('Temperature_hour_raw'),0) Returns a time series with values: 1 when the value in the input series exist and is different from 0. 0 when the value in the input series is 0 or missing (NaN). For example:","title":"Example 3: @BOOL(t,d)"},{"location":"mesh/calculations/functions/bool/#example-4-booltds","text":"If we have the following input time series: TsBrp = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+40x','HOUR+50x'},{12,15,15,0,20},'VARINT') Using the following expression, we can convert the input to the time series below: Temperature_hour_VV = @BOOL(TsBrp,0,'COMPRESS')","title":"Example 4: @BOOL(t,d,s)"},{"location":"mesh/calculations/functions/ceil/","text":"CEIL About the function This function rounds off values in a time series up to the nearest whole number. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number. Syntax CEIL(t) CEIL(d) Description # Type Description 1 t Time series 1 d Number Example Temperature corrected = @CEIL(@t('.Temperature_raw'))","title":"CEIL"},{"location":"mesh/calculations/functions/ceil/#ceil","text":"","title":"CEIL"},{"location":"mesh/calculations/functions/ceil/#about-the-function","text":"This function rounds off values in a time series up to the nearest whole number. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number.","title":"About the function"},{"location":"mesh/calculations/functions/ceil/#syntax","text":"CEIL(t) CEIL(d) Description # Type Description 1 t Time series 1 d Number","title":"Syntax"},{"location":"mesh/calculations/functions/ceil/#example","text":"Temperature corrected = @CEIL(@t('.Temperature_raw'))","title":"Example"},{"location":"mesh/calculations/functions/color/","text":"ColorARGB About the function The ColorARGB function converts a colour name into an ARGB value. It can be used to produce time series values referenced by the COLOR_VALUE attribute in Mesh template reports. Syntax d = ColorARGB(s) Returns an ARGB value.The argument (s) is a named colour according to this list . The colour name is case insensitive and must not contain space characters. Not accepted: Dark Green Accepted: DarkGreen darkgreen Each colour also has four different nuances, which can be specified by adding 1 to 4 as a suffix to the colour name. For instance : steelblue steelblue1 steelblue2 steelblue3 steelblue4 Example ## = @t('.Income') > 1000 ? @ColorARGB('orange') : @ColorARGB('magenta') Returns the ARGB value for the colour named orange or the colour named magenta , depending on the value of the income time series.","title":"ColorARGB"},{"location":"mesh/calculations/functions/color/#colorargb","text":"","title":"ColorARGB"},{"location":"mesh/calculations/functions/color/#about-the-function","text":"The ColorARGB function converts a colour name into an ARGB value. It can be used to produce time series values referenced by the COLOR_VALUE attribute in Mesh template reports.","title":"About the function"},{"location":"mesh/calculations/functions/color/#syntax","text":"d = ColorARGB(s) Returns an ARGB value.The argument (s) is a named colour according to this list . The colour name is case insensitive and must not contain space characters. Not accepted: Dark Green Accepted: DarkGreen darkgreen Each colour also has four different nuances, which can be specified by adding 1 to 4 as a suffix to the colour name. For instance : steelblue steelblue1 steelblue2 steelblue3 steelblue4","title":"Syntax"},{"location":"mesh/calculations/functions/color/#example","text":"## = @t('.Income') > 1000 ? @ColorARGB('orange') : @ColorARGB('magenta') Returns the ARGB value for the colour named orange or the colour named magenta , depending on the value of the income time series.","title":"Example"},{"location":"mesh/calculations/functions/compare/","text":"Compare About the function This function compares two strings. It returns 0 if they are identical, 1 otherwise. The function is case sensitive. Syntax Compare(s,s) Description # Type Description 1 s String to be compared. 2 s String to be compared. Example @Compare('Bajaboo', 'bajaboo') returns 1 @Compare('Bajaboo', 'Bajaboo') returns 0","title":"Compare"},{"location":"mesh/calculations/functions/compare/#compare","text":"","title":"Compare"},{"location":"mesh/calculations/functions/compare/#about-the-function","text":"This function compares two strings. It returns 0 if they are identical, 1 otherwise. The function is case sensitive.","title":"About the function"},{"location":"mesh/calculations/functions/compare/#syntax","text":"Compare(s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/compare/#description","text":"# Type Description 1 s String to be compared. 2 s String to be compared.","title":"Description"},{"location":"mesh/calculations/functions/compare/#example","text":"@Compare('Bajaboo', 'bajaboo') returns 1 @Compare('Bajaboo', 'Bajaboo') returns 0","title":"Example"},{"location":"mesh/calculations/functions/concatenate/","text":"Concatenate About the function Merge text arguments into a concatenated text. This is very useful when there is a need to create a reference from multiple parts, for example from other object attributes. Syntax Concatenate(s,s) Concatenate(S) Description # Type Description 1 s First text argument 2 s Second text argument Example ## = @t(@Concatenate(\u2018../..\u2019, @s(\u2018.TargetTimeseries\u2019)) The argument to @t is calculated based on the local text attribute TargetTimeseries and a static movement ../.. . If the value of TargetTimeseries is MyTsAttribute, the result is the time series addressed like this, ../\u2026MyTs . This means go to the parent of the parent and get the time series on the MyTsAttribute attribute. Description # Type Description 1 S An array of texts to concatenate into the resulting text Example ## = @t( @Concatenate( {'*[.Type=HydroPlant&&.Name=', @MeshID('NAME'),'].Production' }) If the name of current object is 'PlantX' then the Concatenate function will return this string: ''*[.Type=HydroPlant&&.Name=PlantX].Production'","title":"Concatenate"},{"location":"mesh/calculations/functions/concatenate/#concatenate","text":"","title":"Concatenate"},{"location":"mesh/calculations/functions/concatenate/#about-the-function","text":"Merge text arguments into a concatenated text. This is very useful when there is a need to create a reference from multiple parts, for example from other object attributes.","title":"About the function"},{"location":"mesh/calculations/functions/concatenate/#syntax","text":"Concatenate(s,s) Concatenate(S)","title":"Syntax"},{"location":"mesh/calculations/functions/concatenate/#description","text":"# Type Description 1 s First text argument 2 s Second text argument","title":"Description"},{"location":"mesh/calculations/functions/concatenate/#example","text":"## = @t(@Concatenate(\u2018../..\u2019, @s(\u2018.TargetTimeseries\u2019)) The argument to @t is calculated based on the local text attribute TargetTimeseries and a static movement ../.. . If the value of TargetTimeseries is MyTsAttribute, the result is the time series addressed like this, ../\u2026MyTs . This means go to the parent of the parent and get the time series on the MyTsAttribute attribute. Description # Type Description 1 S An array of texts to concatenate into the resulting text","title":"Example"},{"location":"mesh/calculations/functions/concatenate/#example_1","text":"## = @t( @Concatenate( {'*[.Type=HydroPlant&&.Name=', @MeshID('NAME'),'].Production' }) If the name of current object is 'PlantX' then the Concatenate function will return this string: ''*[.Type=HydroPlant&&.Name=PlantX].Production'","title":"Example"},{"location":"mesh/calculations/functions/convert_volume/","text":"CONVERT_VOLUME About the functions Converts a time series unit into a new unit. The result series has the same resolution as the input time series. Syntax CONVERT_VOLUME(t) Description # Type Description 1 t Time series with reservoir content. This function implicitly uses an XY table attribute which must be defined in Mesh Configurator and attached to the same object where the time series expression is defined. The XY table attribute must be set up with reference to an external attribute in sim models. The syntax for the Reservoir storage is: CONTEXT=XYSET;HYD_KEY=$LocalId;HYDFN_CODE=RsvElevStorage $LocalId is a reference to an attribute name with the HYD_KEY number specified for each reservoir. This attribute must also be defined in Mesh Configurator and attached to the same object. See help text in Mesh Configurator > Reference to external attributes in sim models.","title":"CONVERT_VOLUME"},{"location":"mesh/calculations/functions/convert_volume/#convert_volume","text":"About the functions Converts a time series unit into a new unit. The result series has the same resolution as the input time series.","title":"CONVERT_VOLUME"},{"location":"mesh/calculations/functions/convert_volume/#syntax","text":"CONVERT_VOLUME(t)","title":"Syntax"},{"location":"mesh/calculations/functions/convert_volume/#description","text":"# Type Description 1 t Time series with reservoir content. This function implicitly uses an XY table attribute which must be defined in Mesh Configurator and attached to the same object where the time series expression is defined. The XY table attribute must be set up with reference to an external attribute in sim models. The syntax for the Reservoir storage is: CONTEXT=XYSET;HYD_KEY=$LocalId;HYDFN_CODE=RsvElevStorage $LocalId is a reference to an attribute name with the HYD_KEY number specified for each reservoir. This attribute must also be defined in Mesh Configurator and attached to the same object. See help text in Mesh Configurator > Reference to external attributes in sim models.","title":"Description"},{"location":"mesh/calculations/functions/copy_ts/","text":"CopyTs This function copies values from a source location to a destination location within the Mesh model. This is a function where the \"side effects\" of the operation is the important part rather than the returned values. Syntax CopyTs(s,s,s) Description Type Description s Attribute name that determines the match between source and target series. It is assumed to be available at the object where the source series is found and where the target series is found. The built-in attribute called Name can also be used to decide match. s Search expression for getting source time series. s Search expression for getting target time series. The function returns 0 if success, else a negative error code. The search expression in the two last arguments are by default relative to the object where the @CopyTs() calculation is found. It is possible to make the search expression relative to model root by adding a prefix \"Model:\" to the search expression. This part is removed before applying the search. Example ## = @CopyTs('Ident', '*[.Type=TypeB].Ts1','Model:*[.Name=A1_3_New]/[.Type=TypeB].Ts1') The function uses the value on the attribute Ident as criterion for making source - target pairs. The second argument is defining a relative search operation that collects the Ts1 time series attribute for all children that is of type name TypeB . The third argument, the target search definition, is used to collect target time series. In this case the search is starting at the top of the model (prefix Model: ) and search for TypeB objects below an object with name A1_3. ## = @CopyTs('Name', '*[.Type=TypeB].Ts1','Model:*[.Name=A1_3_New]/[.Type=TypeB].Ts1') The function uses the name of the object as criterion for making source - target pairs. In both examples the target search is done with model as start point (prefix Model: ). The source series search is relative to the point in model where this calculation expression is found. The function will not do the copy operation if not all series identified by source search definition (argument 2) have a matching partner from the targets list.","title":"CopyTs"},{"location":"mesh/calculations/functions/copy_ts/#copyts","text":"This function copies values from a source location to a destination location within the Mesh model. This is a function where the \"side effects\" of the operation is the important part rather than the returned values.","title":"CopyTs"},{"location":"mesh/calculations/functions/copy_ts/#syntax","text":"CopyTs(s,s,s) Description Type Description s Attribute name that determines the match between source and target series. It is assumed to be available at the object where the source series is found and where the target series is found. The built-in attribute called Name can also be used to decide match. s Search expression for getting source time series. s Search expression for getting target time series. The function returns 0 if success, else a negative error code. The search expression in the two last arguments are by default relative to the object where the @CopyTs() calculation is found. It is possible to make the search expression relative to model root by adding a prefix \"Model:\" to the search expression. This part is removed before applying the search.","title":"Syntax"},{"location":"mesh/calculations/functions/copy_ts/#example","text":"## = @CopyTs('Ident', '*[.Type=TypeB].Ts1','Model:*[.Name=A1_3_New]/[.Type=TypeB].Ts1') The function uses the value on the attribute Ident as criterion for making source - target pairs. The second argument is defining a relative search operation that collects the Ts1 time series attribute for all children that is of type name TypeB . The third argument, the target search definition, is used to collect target time series. In this case the search is starting at the top of the model (prefix Model: ) and search for TypeB objects below an object with name A1_3. ## = @CopyTs('Name', '*[.Type=TypeB].Ts1','Model:*[.Name=A1_3_New]/[.Type=TypeB].Ts1') The function uses the name of the object as criterion for making source - target pairs. In both examples the target search is done with model as start point (prefix Model: ). The source series search is relative to the point in model where this calculation expression is found. The function will not do the copy operation if not all series identified by source search definition (argument 2) have a matching partner from the targets list.","title":"Example"},{"location":"mesh/calculations/functions/correct_average_value/","text":"CorrectAverageValue About the function The method replaces values marked as errors with the average value of other series for the same time. Values with correction using average value are set to corrected and marked with C05 , meaning correction method 5. You can see this code if you turn on value information in Nimbus. Syntax CorrectAverageValue(t,d,s,s,d,T,D,S) Description CorrectAverageValue(t,d,s,s,d,T,D,D,D,S) # Type Description 1 t Time series to be corrected. 2 d Value describing maximum total share (0-1) of the time series that can contain errors based on their respective weighting compared to the total weighting of time series used in the calculation. E.g factor 0,95 means it is accepted that only 5 % of the time series share can contribute to the corrected value. 3 s Symbol describing whether or not endpoint adaptation should be performed. This is specified as 'TRUE' or 'FALSE'. Use endpoint adaption if you want to scale the corrected values to fit the existing time series values at start and end of the correction period. 4 s Symbol describing whether or not time series are accumulated time series. This is specified as 'TRUE' or 'FALSE'. 5 d Value giving the limit for right endpoint adaptation. This value has no effect unless time series are accumulated time series. Limit for right attachment specifies threshold value for right end point attachment. E.g if the difference between previous OK value and next OK value is less than this value, right end point will not be attached which means a standard method operation is performed. 6 T An array of time series to be used in the correction. 7 D An array of weight values. Weighting is used if you want values from a particular series to have a greater effect on the average than other series. Each value included in the average value calculation is multiplied by its respective weighting before it is added to an accumulated value. You get the final value by dividing the accumulated value by the sum of the weighting for the series included in the average value calculation. 8 D An array with symbols describing whether or not corrected values can be used. This is specified as 'TRUE' or 'FALSE'. If you want to use a scale factor or an offset factor before combining the time series into the result time series, you can define these as attributes on the specific object and use them in the calculation of the input time series. Note! To avoid circular references in the calculation of the correction values using the method average value, the input time series used in the correction must not include the same function. E.g you might refer to a time series using only validation functions or other correction function that is not depending on other time series. This is caused by the virtual calculation in Mesh. Example Temperature_hour_VEE = @CorrectAverageValue(@t('ValidatedTimeSeries'),0.95,'TRUE','FALSE',1,@T('../NeighbourMetStations/Temperature_hour_avg'),@D('../NeighbourMetStations/Weight'),@S('../NeighbourMetStations/AcceptCorrected')) This example corrects the previously validated time series using the average from the time series with different weights. Endpoint adaptation is turned on and the limit for the right endpoint is not in use.","title":"CorrectAverageValue"},{"location":"mesh/calculations/functions/correct_average_value/#correctaveragevalue","text":"About the function The method replaces values marked as errors with the average value of other series for the same time. Values with correction using average value are set to corrected and marked with C05 , meaning correction method 5. You can see this code if you turn on value information in Nimbus. Syntax CorrectAverageValue(t,d,s,s,d,T,D,S) Description CorrectAverageValue(t,d,s,s,d,T,D,D,D,S) # Type Description 1 t Time series to be corrected. 2 d Value describing maximum total share (0-1) of the time series that can contain errors based on their respective weighting compared to the total weighting of time series used in the calculation. E.g factor 0,95 means it is accepted that only 5 % of the time series share can contribute to the corrected value. 3 s Symbol describing whether or not endpoint adaptation should be performed. This is specified as 'TRUE' or 'FALSE'. Use endpoint adaption if you want to scale the corrected values to fit the existing time series values at start and end of the correction period. 4 s Symbol describing whether or not time series are accumulated time series. This is specified as 'TRUE' or 'FALSE'. 5 d Value giving the limit for right endpoint adaptation. This value has no effect unless time series are accumulated time series. Limit for right attachment specifies threshold value for right end point attachment. E.g if the difference between previous OK value and next OK value is less than this value, right end point will not be attached which means a standard method operation is performed. 6 T An array of time series to be used in the correction. 7 D An array of weight values. Weighting is used if you want values from a particular series to have a greater effect on the average than other series. Each value included in the average value calculation is multiplied by its respective weighting before it is added to an accumulated value. You get the final value by dividing the accumulated value by the sum of the weighting for the series included in the average value calculation. 8 D An array with symbols describing whether or not corrected values can be used. This is specified as 'TRUE' or 'FALSE'. If you want to use a scale factor or an offset factor before combining the time series into the result time series, you can define these as attributes on the specific object and use them in the calculation of the input time series. Note! To avoid circular references in the calculation of the correction values using the method average value, the input time series used in the correction must not include the same function. E.g you might refer to a time series using only validation functions or other correction function that is not depending on other time series. This is caused by the virtual calculation in Mesh. Example Temperature_hour_VEE = @CorrectAverageValue(@t('ValidatedTimeSeries'),0.95,'TRUE','FALSE',1,@T('../NeighbourMetStations/Temperature_hour_avg'),@D('../NeighbourMetStations/Weight'),@S('../NeighbourMetStations/AcceptCorrected')) This example corrects the previously validated time series using the average from the time series with different weights. Endpoint adaptation is turned on and the limit for the right endpoint is not in use.","title":"CorrectAverageValue"},{"location":"mesh/calculations/functions/correct_constant_value/","text":"CorrectConstantValue About the function Corrects errors on a previously validated time series with a specified constant value. Values with correction using constant value are set to corrected and marked with C01 , meaning correction method 1. You can see this code if you turn on value information in Nimbus. Syntax CorrectConstantValue(t,d) Description # Type Description 1 t Time series to be corrected. 2 d Constant value to use when correcting. Example Waterlevel_hour_VEE = @CorrectConstantValue(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),208) This example validates the time series using absolute limits. Any errors found are replaced by 208.","title":"CorrectConstantValue"},{"location":"mesh/calculations/functions/correct_constant_value/#correctconstantvalue","text":"About the function Corrects errors on a previously validated time series with a specified constant value. Values with correction using constant value are set to corrected and marked with C01 , meaning correction method 1. You can see this code if you turn on value information in Nimbus. Syntax CorrectConstantValue(t,d)","title":"CorrectConstantValue"},{"location":"mesh/calculations/functions/correct_constant_value/#description","text":"# Type Description 1 t Time series to be corrected. 2 d Constant value to use when correcting. Example Waterlevel_hour_VEE = @CorrectConstantValue(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),208) This example validates the time series using absolute limits. Any errors found are replaced by 208.","title":"Description"},{"location":"mesh/calculations/functions/correct_copy_value/","text":"CorrectCopyValue About the function Corrects errors on a previously validated time series using a copy of the previous value. Values with correction using copy value are set to corrected and marked with C02 , meaning correction method 2. You can see this code if you turn on value information in Nimbus. Syntax CorrectCopyValue(t,d,s) Description # Type Description 1 t Time series to be corrected. 2 d Value describing the maximum number of allowed copies. 3 s Symbol describing whether or not corrected values can be used. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @CorrectCopyValue(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),3,'TRUE') This example validates the time series using absolute limits. Any errors found are replaced by a copy of the previous value. Maximum values that can be copied are set to 3 and corrected values can be used.","title":"CorrectCopyValue"},{"location":"mesh/calculations/functions/correct_copy_value/#correctcopyvalue","text":"About the function Corrects errors on a previously validated time series using a copy of the previous value. Values with correction using copy value are set to corrected and marked with C02 , meaning correction method 2. You can see this code if you turn on value information in Nimbus. Syntax CorrectCopyValue(t,d,s)","title":"CorrectCopyValue"},{"location":"mesh/calculations/functions/correct_copy_value/#description","text":"# Type Description 1 t Time series to be corrected. 2 d Value describing the maximum number of allowed copies. 3 s Symbol describing whether or not corrected values can be used. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @CorrectCopyValue(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),3,'TRUE') This example validates the time series using absolute limits. Any errors found are replaced by a copy of the previous value. Maximum values that can be copied are set to 3 and corrected values can be used.","title":"Description"},{"location":"mesh/calculations/functions/correct_extrapolate/","text":"CorrectExtrapolate About the function Corrects errors on a previously validated time series using extrapolation. Values with correction using extrapolation are set to corrected with remark C04, meaning correction method 4. You can see this code if you turn on value information in Nimbus. Syntax CorrectExtrapolate(t,d,s) Description # Type Description 1 t Time series to be corrected. 2 d Value describing maximum number of errors. When the maximum number of errors has been reached, no more correction will be done. 3 s Symbol describing if corrected values can be used when extrapolating. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @CorrectExtrapolate(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),2,'FALSE') This example validates the time series using absolute limits. Any errors found are corrected using extrapolated values. Maximum number of errors cannot exceed 2 and corrected values cannot be used when extrapolating.","title":"CorrectExtrapolate"},{"location":"mesh/calculations/functions/correct_extrapolate/#correctextrapolate","text":"About the function Corrects errors on a previously validated time series using extrapolation. Values with correction using extrapolation are set to corrected with remark C04, meaning correction method 4. You can see this code if you turn on value information in Nimbus. Syntax CorrectExtrapolate(t,d,s)","title":"CorrectExtrapolate"},{"location":"mesh/calculations/functions/correct_extrapolate/#description","text":"# Type Description 1 t Time series to be corrected. 2 d Value describing maximum number of errors. When the maximum number of errors has been reached, no more correction will be done. 3 s Symbol describing if corrected values can be used when extrapolating. This is specified as either 'TRUE' or 'FALSE'.","title":"Description"},{"location":"mesh/calculations/functions/correct_extrapolate/#example","text":"Waterlevel_hour_VEE = @CorrectExtrapolate(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),2,'FALSE') This example validates the time series using absolute limits. Any errors found are corrected using extrapolated values. Maximum number of errors cannot exceed 2 and corrected values cannot be used when extrapolating.","title":"Example"},{"location":"mesh/calculations/functions/correct_interpolate/","text":"CorrectInterpolate About the function Corrects errors on a previously validated time series using interpolation. Values with correction using interpolation are set to corrected and marked with C03 , meaning correction method 3. You can see this code if you turn on value information in Nimbus. Syntax CorrectInterpolate(t,d,s) Description # Type Description 1 t Time series to be corrected. 2 d Value describing maximum number of errors between first and last interpolated value (including the first and last value). 3 s Symbol describing whether or not corrected values can be used when interpolating. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @CorrectInterpolate(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),3,'FALSE') This example validates the time series using absolute limits. Any errors found are replaced by an interpolated value. Maximum number of values between first and last interpolated value cannot be more than 3 and corrected values cannot be used.","title":"CorrectInterpolate"},{"location":"mesh/calculations/functions/correct_interpolate/#correctinterpolate","text":"About the function Corrects errors on a previously validated time series using interpolation. Values with correction using interpolation are set to corrected and marked with C03 , meaning correction method 3. You can see this code if you turn on value information in Nimbus. Syntax CorrectInterpolate(t,d,s)","title":"CorrectInterpolate"},{"location":"mesh/calculations/functions/correct_interpolate/#description","text":"# Type Description 1 t Time series to be corrected. 2 d Value describing maximum number of errors between first and last interpolated value (including the first and last value). 3 s Symbol describing whether or not corrected values can be used when interpolating. This is specified as either 'TRUE' or 'FALSE'.","title":"Description"},{"location":"mesh/calculations/functions/correct_interpolate/#example","text":"Waterlevel_hour_VEE = @CorrectInterpolate(@ValidateAbsLimit(@t('Waterlevel_hour_raw'),207,210),3,'FALSE') This example validates the time series using absolute limits. Any errors found are replaced by an interpolated value. Maximum number of values between first and last interpolated value cannot be more than 3 and corrected values cannot be used.","title":"Example"},{"location":"mesh/calculations/functions/cos/","text":"COS About the function This function is used to calculate the cosine of a time series. Note! The values of the input are in radians. Syntax COS(t) # Type Description 1 t Time series Example Temperature_hour_VV = @COS(@t('Temperature_hour_raw'))","title":"COS"},{"location":"mesh/calculations/functions/cos/#cos","text":"","title":"COS"},{"location":"mesh/calculations/functions/cos/#about-the-function","text":"This function is used to calculate the cosine of a time series. Note! The values of the input are in radians.","title":"About the function"},{"location":"mesh/calculations/functions/cos/#syntax","text":"COS(t) # Type Description 1 t Time series","title":"Syntax"},{"location":"mesh/calculations/functions/cos/#example","text":"Temperature_hour_VV = @COS(@t('Temperature_hour_raw'))","title":"Example"},{"location":"mesh/calculations/functions/delta/","text":"DELTA About the function Finds the difference between the current value and the previous value in a time series. In other words, it calculates the change in a time series from one value to the next. If the offset parameter (argument 2) is set to a number different from 0, the function calculates the difference between the next value and the current value. The second argument can also be a time macro symbol The result series has the same resolution as the input time series. Syntax DELTA(t[,d|s]) Description # Type Description 1 t Time series, fixed interval series or breakpoint. Finds the difference between the current value and the previous value in the time series used in the argument. 2 d or s Optional. If argument 2 is set to a number different from 0, the value is calculated as the difference between the next value and the current value. Using the number 0, the calculation is equal to the default setting in argument 1. Optional. The second argument can also be a time macro symbol. The time macro must equal to or be coarser than the resolution of the input time series. Using a time macro > than 0, the function calculates the value as the difference between the next value representing the time macro step and the current value. Using a time macro The function can be described like this: DELTA(t): res(t) = y(t) \u2013 y(t-1) Second argument omitted or has value 0 DELTA(t,number\u22600): res(t) = y(t+1) \u2013 y(t) Second argument has value \u22600 DELTA(t,\u2019+2h\u2019): res(t) = y(t+2h) \u2013 y(t) Second argument has value \u2018+2h\u2019 DELTA(t,\u2019-2h\u2019): res(t) = y(t) \u2013 y(t -2h) Second argument has value \u2018-2h\u2019 The input time series might be a fixed interval series or a variable interval series. Example @DELTA(t) TemperatureForecast_delta = @DELTA(@t('AreaTemperature')) Values in the result time series are equal to the difference between the current value and the previous value in the input time series. An example of this is shown below. The value of the first row is based on the difference to the value 13,56 in a preceding point in time.","title":"Delta"},{"location":"mesh/calculations/functions/delta/#delta","text":"","title":"DELTA"},{"location":"mesh/calculations/functions/delta/#about-the-function","text":"Finds the difference between the current value and the previous value in a time series. In other words, it calculates the change in a time series from one value to the next. If the offset parameter (argument 2) is set to a number different from 0, the function calculates the difference between the next value and the current value. The second argument can also be a time macro symbol The result series has the same resolution as the input time series. Syntax DELTA(t[,d|s])","title":"About the function"},{"location":"mesh/calculations/functions/delta/#description","text":"# Type Description 1 t Time series, fixed interval series or breakpoint. Finds the difference between the current value and the previous value in the time series used in the argument. 2 d or s Optional. If argument 2 is set to a number different from 0, the value is calculated as the difference between the next value and the current value. Using the number 0, the calculation is equal to the default setting in argument 1. Optional. The second argument can also be a time macro symbol. The time macro must equal to or be coarser than the resolution of the input time series. Using a time macro > than 0, the function calculates the value as the difference between the next value representing the time macro step and the current value. Using a time macro The function can be described like this: DELTA(t): res(t) = y(t) \u2013 y(t-1) Second argument omitted or has value 0 DELTA(t,number\u22600): res(t) = y(t+1) \u2013 y(t) Second argument has value \u22600 DELTA(t,\u2019+2h\u2019): res(t) = y(t+2h) \u2013 y(t) Second argument has value \u2018+2h\u2019 DELTA(t,\u2019-2h\u2019): res(t) = y(t) \u2013 y(t -2h) Second argument has value \u2018-2h\u2019 The input time series might be a fixed interval series or a variable interval series.","title":"Description"},{"location":"mesh/calculations/functions/delta/#example","text":"@DELTA(t) TemperatureForecast_delta = @DELTA(@t('AreaTemperature')) Values in the result time series are equal to the difference between the current value and the previous value in the input time series. An example of this is shown below. The value of the first row is based on the difference to the value 13,56 in a preceding point in time.","title":"Example"},{"location":"mesh/calculations/functions/disable_cache/","text":"DisableCache The @DisableCache() function disables caching of calculation results for the calculation expression it is used in. This is useful when calculations used for their side effects, such as @CopyTs or @PDLOG , are referenced by another expression. When executing a calculation, Mesh may cache the result of the calculation to avoid re-calculation on future requests. For \"pure\" calculations \u2014 those without side effects \u2014 this is invisible to the user. However for calculations that involve a side effect, such as @PDLOG , caching is disabled to ensure that the side effect happens on each user request. Mesh does however not disable the cache automatically when a function with a side effect is referenced by a function without any direct side effects. For example a calculation attribute .a with contents @PDLOG(...) will not be cached, but the expression @t(\".a\") will be. Executing @t(\".a\") multiple times may therefore not execute @PDLOG(...) multiple times, even though it logically should. The @DisableCache() function can be used to explicitly disable caching for a calculation expression. So if we change the above example to the following we will see the desired behaviour of multiple executions calling @PDLOG multiple times. @DisableCache() @t(\".a\")","title":"DisableCache"},{"location":"mesh/calculations/functions/disable_cache/#disablecache","text":"The @DisableCache() function disables caching of calculation results for the calculation expression it is used in. This is useful when calculations used for their side effects, such as @CopyTs or @PDLOG , are referenced by another expression. When executing a calculation, Mesh may cache the result of the calculation to avoid re-calculation on future requests. For \"pure\" calculations \u2014 those without side effects \u2014 this is invisible to the user. However for calculations that involve a side effect, such as @PDLOG , caching is disabled to ensure that the side effect happens on each user request. Mesh does however not disable the cache automatically when a function with a side effect is referenced by a function without any direct side effects. For example a calculation attribute .a with contents @PDLOG(...) will not be cached, but the expression @t(\".a\") will be. Executing @t(\".a\") multiple times may therefore not execute @PDLOG(...) multiple times, even though it logically should. The @DisableCache() function can be used to explicitly disable caching for a calculation expression. So if we change the above example to the following we will see the desired behaviour of multiple executions calling @PDLOG multiple times. @DisableCache() @t(\".a\")","title":"DisableCache"},{"location":"mesh/calculations/functions/distribute/","text":"DISTRIBUTE This topic describes DISTRIBUTE variants ( R6 , R7 , Ra7 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Which functions can be used when? R6 About the function Converts a time series to a finer resolution. The resolution for the result is given by the resolution of the mask series defined in argument 2. The value from the series in argument 1 is distributed to the points of time in the mask series having logical true value (different from 0 and NaN). The function uses the SUM method as base for the distribution. Syntax DISTRIBUTE(t,t) Description TYPE Description t Input time series to be distributed. t Mask series representing the distributed time interval. Example MaskSeries = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15) ResultTimeSeries = @DISTRIBUTE(@t('Ts5'),MaskSeries) Mask time series in argument 2 is only used as a logical time series giving the distributed interval for the input value to be distributed within. The example gives hourly value divided into four. If you change the values in the mask series to NaN or 0 (false) for one or several of the time points, the result will distribute the hourly values divided into the number of true values, skipping the time point set to false. Note! The result will be a break point time series. MaskSeries = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,NaN,2},'MIN15') Result time series = @DISTRIBUTE(@t('Ts5'),MaskSeries) R7 About the function As function R6 , but with a third argument which is a profile series. This decides how the distribution of the values is done. Syntax DISTRIBUTE(t,t,t) Description Type Description t Input time series to be distributed. t Mask series representing the distributed time interval. Defines the resolution of the result time series. t Profile series representing the distribution of the values. Must have the same resolution as the mask series. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period Example MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 * 1 / 2 = 0,25 Ra7 About the function As function R7 , but with a scaling factor in argument 1. This DISTRIBUTE variant gives values on the result series also for the value 0 on the input data series (given that the profile series has different values in the period). Syntax DISTRIBUTE(d,t,t,t) Description Type Description d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R7. t Input time series to be distributed. t Mask series representing the distributed time interval. Defines the resolution of the result time series. t Profile series representing the distribution of the values. Must have the same resolution as the mask series. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R7 . Example 1 MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(1,@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 + 1 \u2219 (1 - 2) = -0,5 Example 2 MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(10,@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 + 10 \u2219 (1 - 2) = -9,5","title":"DISTRIBUTE"},{"location":"mesh/calculations/functions/distribute/#distribute","text":"This topic describes DISTRIBUTE variants ( R6 , R7 , Ra7 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Which functions can be used when?","title":"DISTRIBUTE"},{"location":"mesh/calculations/functions/distribute/#r6","text":"","title":"R6"},{"location":"mesh/calculations/functions/distribute/#about-the-function","text":"Converts a time series to a finer resolution. The resolution for the result is given by the resolution of the mask series defined in argument 2. The value from the series in argument 1 is distributed to the points of time in the mask series having logical true value (different from 0 and NaN). The function uses the SUM method as base for the distribution.","title":"About the function"},{"location":"mesh/calculations/functions/distribute/#syntax","text":"DISTRIBUTE(t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/distribute/#description","text":"TYPE Description t Input time series to be distributed. t Mask series representing the distributed time interval.","title":"Description"},{"location":"mesh/calculations/functions/distribute/#example","text":"MaskSeries = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15) ResultTimeSeries = @DISTRIBUTE(@t('Ts5'),MaskSeries) Mask time series in argument 2 is only used as a logical time series giving the distributed interval for the input value to be distributed within. The example gives hourly value divided into four. If you change the values in the mask series to NaN or 0 (false) for one or several of the time points, the result will distribute the hourly values divided into the number of true values, skipping the time point set to false. Note! The result will be a break point time series. MaskSeries = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,NaN,2},'MIN15') Result time series = @DISTRIBUTE(@t('Ts5'),MaskSeries)","title":"Example"},{"location":"mesh/calculations/functions/distribute/#r7","text":"","title":"R7"},{"location":"mesh/calculations/functions/distribute/#about-the-function_1","text":"As function R6 , but with a third argument which is a profile series. This decides how the distribution of the values is done.","title":"About the function"},{"location":"mesh/calculations/functions/distribute/#syntax_1","text":"DISTRIBUTE(t,t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/distribute/#description_1","text":"Type Description t Input time series to be distributed. t Mask series representing the distributed time interval. Defines the resolution of the result time series. t Profile series representing the distribution of the values. Must have the same resolution as the mask series. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period","title":"Description"},{"location":"mesh/calculations/functions/distribute/#example_1","text":"MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 * 1 / 2 = 0,25","title":"Example"},{"location":"mesh/calculations/functions/distribute/#ra7","text":"","title":"Ra7"},{"location":"mesh/calculations/functions/distribute/#about-the-function_2","text":"As function R7 , but with a scaling factor in argument 1. This DISTRIBUTE variant gives values on the result series also for the value 0 on the input data series (given that the profile series has different values in the period).","title":"About the function"},{"location":"mesh/calculations/functions/distribute/#syntax_2","text":"DISTRIBUTE(d,t,t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/distribute/#description_2","text":"Type Description d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R7. t Input time series to be distributed. t Mask series representing the distributed time interval. Defines the resolution of the result time series. t Profile series representing the distribution of the values. Must have the same resolution as the mask series. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R7 . Example 1 MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(1,@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 + 1 \u2219 (1 - 2) = -0,5 Example 2 MaskSeries/Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Argument 2 is a mask series (all time points contributes) Argument 3 gives the profile values (same as the mask series) Result time series = @DISTRIBUTE(10,@t('Ts5'),MaskSeries,Profile) Based on the equation, the first value of the distributed period is calculated like this: FirstValue = 2 / 4 + 10 \u2219 (1 - 2) = -9,5","title":"Description"},{"location":"mesh/calculations/functions/floor/","text":"FLOOR About the function Converts the number in a time series to an integer by cutting all decimals. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number. Syntax FLOOR(t) FLOOR(d) Description # Type Description 1 t Time series 1 d Number Example Temperature corrected = @FLOOR(@t('.Temperature_raw'))","title":"FLOOR"},{"location":"mesh/calculations/functions/floor/#floor","text":"","title":"FLOOR"},{"location":"mesh/calculations/functions/floor/#about-the-function","text":"Converts the number in a time series to an integer by cutting all decimals. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number.","title":"About the function"},{"location":"mesh/calculations/functions/floor/#syntax","text":"FLOOR(t) FLOOR(d) Description # Type Description 1 t Time series 1 d Number","title":"Syntax"},{"location":"mesh/calculations/functions/floor/#example","text":"Temperature corrected = @FLOOR(@t('.Temperature_raw'))","title":"Example"},{"location":"mesh/calculations/functions/get_all_forecasts/","text":"GetAllForecasts Note! You can only use this function in an expression argument returning only one time series, e.g. by using the @SUM or @Mean function in front of the argument. You can look at all the forecast time series in Nimbus ad hoc version.","title":"GetAllForecasts"},{"location":"mesh/calculations/functions/get_all_forecasts/#getallforecasts","text":"Note! You can only use this function in an expression argument returning only one time series, e.g. by using the @SUM or @Mean function in front of the argument. You can look at all the forecast time series in Nimbus ad hoc version.","title":"GetAllForecasts"},{"location":"mesh/calculations/functions/get_best_forecast/","text":"GetBestForecast","title":"GetBestForecast"},{"location":"mesh/calculations/functions/get_best_forecast/#getbestforecast","text":"","title":"GetBestForecast"},{"location":"mesh/calculations/functions/get_forecast/","text":"GetForecast Description GetForecast(t,d|s,d|s[,d|s]) # Type Description 1 t Time series reference identifying a forecast set. 2 d or s t0Min 3 d or s t0Max 4 d or s Optional. Condition for save time, tc The function uses t0Min and t0Max to find the relevant forecast instead of using the start of the requested period. It requires that the forecast series' t0 is less than or equal to t0Max and larger than t0Min. Argument 2 has an additional condition that the write time for the forecast series is less than or equal to the time the argument represents. If no forecast series has its start time within the given interval, the function returns a time series with NaN.","title":"GetForecast"},{"location":"mesh/calculations/functions/get_forecast/#getforecast","text":"Description GetForecast(t,d|s,d|s[,d|s]) # Type Description 1 t Time series reference identifying a forecast set. 2 d or s t0Min 3 d or s t0Max 4 d or s Optional. Condition for save time, tc The function uses t0Min and t0Max to find the relevant forecast instead of using the start of the requested period. It requires that the forecast series' t0 is less than or equal to t0Max and larger than t0Min. Argument 2 has an additional condition that the write time for the forecast series is less than or equal to the time the argument represents. If no forecast series has its start time within the given interval, the function returns a time series with NaN.","title":"GetForecast"},{"location":"mesh/calculations/functions/get_merged_forecast/","text":"GetMergedForecast","title":"GetMergedForecasts"},{"location":"mesh/calculations/functions/get_merged_forecast/#getmergedforecast","text":"","title":"GetMergedForecast"},{"location":"mesh/calculations/functions/get_ts_as_of_time/","text":"GetTsAsOfTime About the function Used to find values and status for a time series at a given historical time. Returns a time series or an array of time series, depending on the value of parameter number two. Note! If the historical time is earlier than the first write to the series (in the relevant period) then the function returns NaN values. S yntax GetTsAsOfTime(t,s[,s]) GetTsAsOfTime(t,d[,s]) GetTsAsOfTime(t,S[,s]) GetTsAsOfTime(t,D[,s]) Description # Type Description 1 t Time series. 2 s, d, S or D s: Date as symbol. d: Date as number (number of seconds since 1970). S: List of dates (symbol). D: List of dates (number of seconds since 1970). 3 s Optional. Possible values: 'Delta', \u2018DeltaNaNIsNaN\u2019, 'ExactTime'. For Delta codes the function returns the difference between the current time series values and historical time series values. For DeltaNaNIsNaN the delta value is NaN (Not a number / empty) when one of the values is empty. The code ExactTime returns only those values that were written at the specified time, normally used together with GetTsAuditTimes. Example Assumes a time series with historical time series values at various times: Time of writing Time series version Value time tx Value time tx+1 Value time tx+2 Value time tx+3 December 12th 2012 00:00:00 Ts_0 1 7 8 10 November 12th 2012 00:00:00 Ts_1 2 5 3 2 October 12th 2012 00:00:00 Ts_2 1 3 7 September 12th 2012 00:00:00 Ts_3 1 3 8 Example 1: GetTsAsOfTime(t,s) Res = GetTsAsOfTime(t0,'20121201000000000') Returns time series Ts_1 which was valid December 1st 2012. Example 2: GetTsAsOfTime(t,s,s) Res = GetTsAsOfTime(t0,'20121201000000000','Delta') Returns the difference between the values in Ts_0 and Ts_1: -1 2 5 8 Example 3: GetTsAsOfTime(t,S) Res = GetTsAsOfTime(t0,{'20121201000000000','20121101000000000','20121001000000000'}) Returns an array of time series for the relevant times. Example 4: GetTsAsOfTime(t,S,s) Res = GetTsAsOfTime(t0,{'20121201000000000','20121101000000000','20121001000000000'},'DELTA') Returns an array of the difference between the current time series and the time series at the relevant times.","title":"GetTsAsOfTime"},{"location":"mesh/calculations/functions/get_ts_as_of_time/#gettsasoftime","text":"","title":"GetTsAsOfTime"},{"location":"mesh/calculations/functions/get_ts_as_of_time/#about-the-function","text":"Used to find values and status for a time series at a given historical time. Returns a time series or an array of time series, depending on the value of parameter number two. Note! If the historical time is earlier than the first write to the series (in the relevant period) then the function returns NaN values. S yntax GetTsAsOfTime(t,s[,s]) GetTsAsOfTime(t,d[,s]) GetTsAsOfTime(t,S[,s]) GetTsAsOfTime(t,D[,s])","title":"About the function"},{"location":"mesh/calculations/functions/get_ts_as_of_time/#description","text":"# Type Description 1 t Time series. 2 s, d, S or D s: Date as symbol. d: Date as number (number of seconds since 1970). S: List of dates (symbol). D: List of dates (number of seconds since 1970). 3 s Optional. Possible values: 'Delta', \u2018DeltaNaNIsNaN\u2019, 'ExactTime'. For Delta codes the function returns the difference between the current time series values and historical time series values. For DeltaNaNIsNaN the delta value is NaN (Not a number / empty) when one of the values is empty. The code ExactTime returns only those values that were written at the specified time, normally used together with GetTsAuditTimes.","title":"Description"},{"location":"mesh/calculations/functions/get_ts_as_of_time/#example","text":"Assumes a time series with historical time series values at various times: Time of writing Time series version Value time tx Value time tx+1 Value time tx+2 Value time tx+3 December 12th 2012 00:00:00 Ts_0 1 7 8 10 November 12th 2012 00:00:00 Ts_1 2 5 3 2 October 12th 2012 00:00:00 Ts_2 1 3 7 September 12th 2012 00:00:00 Ts_3 1 3 8 Example 1: GetTsAsOfTime(t,s) Res = GetTsAsOfTime(t0,'20121201000000000') Returns time series Ts_1 which was valid December 1st 2012. Example 2: GetTsAsOfTime(t,s,s) Res = GetTsAsOfTime(t0,'20121201000000000','Delta') Returns the difference between the values in Ts_0 and Ts_1: -1 2 5 8 Example 3: GetTsAsOfTime(t,S) Res = GetTsAsOfTime(t0,{'20121201000000000','20121101000000000','20121001000000000'}) Returns an array of time series for the relevant times. Example 4: GetTsAsOfTime(t,S,s) Res = GetTsAsOfTime(t0,{'20121201000000000','20121101000000000','20121001000000000'},'DELTA') Returns an array of the difference between the current time series and the time series at the relevant times.","title":"Example"},{"location":"mesh/calculations/functions/get_ts_audit_times/","text":"GetTsAuditTimes About the function Returns an array of timepoints related to change events on given time series and restricted to a given maximum number. The function is often used together with GetTsAsOfTime in 'ExactTime' mode to extract explicitly what parts of the series that where changed at these times. Syntax GetTsAuditTimes(t,d) Description # Type ## Description 1 t Time series. 2 d Desired maximum number of audit times for the time series. Note! If the number of change events for given time series and period is less than the given number, then a reduced set is returned. Example GetTsAuditTimes (t0,3) returns the time points related to the last 3 changes made within requested period for time series t0. @GetTsAsOfTime( t0, @GetTsAuditTimes(t0,3), 'ExactTime') returns an array of 3 time series with changes related to each time returned from GetTsAuditTimes. Values not part of an explicit change is NaN","title":"GetTsAuditTimes"},{"location":"mesh/calculations/functions/get_ts_audit_times/#gettsaudittimes","text":"","title":"GetTsAuditTimes"},{"location":"mesh/calculations/functions/get_ts_audit_times/#about-the-function","text":"Returns an array of timepoints related to change events on given time series and restricted to a given maximum number. The function is often used together with GetTsAsOfTime in 'ExactTime' mode to extract explicitly what parts of the series that where changed at these times.","title":"About the function"},{"location":"mesh/calculations/functions/get_ts_audit_times/#syntax","text":"GetTsAuditTimes(t,d)","title":"Syntax"},{"location":"mesh/calculations/functions/get_ts_audit_times/#description","text":"# Type ## Description 1 t Time series. 2 d Desired maximum number of audit times for the time series. Note! If the number of change events for given time series and period is less than the given number, then a reduced set is returned.","title":"Description"},{"location":"mesh/calculations/functions/get_ts_audit_times/#example","text":"GetTsAuditTimes (t0,3) returns the time points related to the last 3 changes made within requested period for time series t0. @GetTsAsOfTime( t0, @GetTsAuditTimes(t0,3), 'ExactTime') returns an array of 3 time series with changes related to each time returned from GetTsAuditTimes. Values not part of an explicit change is NaN","title":"Example"},{"location":"mesh/calculations/functions/get_ts_historical_versions/","text":"GetTsHistoricalVersions About the function Returns an array of a given number of versions of a time series. Syntax GetTsHistoricalVersions(t,d) Description # Type Description 1 t Time series. 2 d Desired number of historical versions of a time series. Note! If you ask for more versions than there exists, the system returns only the versions which exist. That is, potentially fewer than the number given as input to the function. Example GetTsHistoricalVersions(ts,1) returns the last change made, i.e. the latest historical version that is different from the current time series. GetTsHistoricalVersions(ts,3) returns the three last changes. The first series displays the state before the last change, the second displays the state before the second last change, etc.","title":"GetTsHistoricalVersions"},{"location":"mesh/calculations/functions/get_ts_historical_versions/#gettshistoricalversions","text":"About the function Returns an array of a given number of versions of a time series.","title":"GetTsHistoricalVersions"},{"location":"mesh/calculations/functions/get_ts_historical_versions/#syntax","text":"GetTsHistoricalVersions(t,d)","title":"Syntax"},{"location":"mesh/calculations/functions/get_ts_historical_versions/#description","text":"# Type Description 1 t Time series. 2 d Desired number of historical versions of a time series. Note! If you ask for more versions than there exists, the system returns only the versions which exist. That is, potentially fewer than the number given as input to the function. Example GetTsHistoricalVersions(ts,1) returns the last change made, i.e. the latest historical version that is different from the current time series. GetTsHistoricalVersions(ts,3) returns the three last changes. The first series displays the state before the last change, the second displays the state before the second last change, etc.","title":"Description"},{"location":"mesh/calculations/functions/getyfx/","text":"GET_Y_FX About the function The function looks up in an xy-relation, defined as argument to the function, with values from a time series that also is an argument to the function. The result is the y-value from the xy-relation, possibly interpolated. See also information about how to handle input values outside the provided range . Syntax GET_Y_FX (t,D,D[,s]) Description # Type ## Description 1 t Series containing x-values used to lookup in the xy-relation to find the result value for current point of time. 2 D X-values, sorted increasingly. 3 D Y-values corresponding to the X-values given in the last argument. 4 s Can have the following values: INTERPOL - means that the y-value is interpolated, default is no interpolation NOHOLD - means that if you have a NaN on the X-series, the last calculated Y-value is not used. In default mode last calculated value is used. You may combine these two methods and separate them by using a comma. GET_Y_FX (t,D,D,[s]) corresponds to y=f(x) Example Example 1: GET_Y_FX (t,D,D,[s]) R1 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3} ) R2 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3}, 'INTERPOL') R3 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3}, 'INTERPOL,NOHOLD' ) This gives the following values for an X-series presented in the first column. The function is best explained by an illustration: You state a curve band, iso curves in the form of an array of time series. These are associated with an array of y-values. In the above illustration the y-values are -1, 20 and 40, and time series 1 is associated with value -1, time series 2 with 20 and time series 3 with 40. The thickest black curve represents values on the input data series. In the points where this crosses the iso curves, a new result value is generated, as the blue curve shows. Handle input values outside the provided range When an input is lower than the first value from the x range provided in the function call (-1 in the example below) the first value from the y range will be returned (1 in the example below). When an input is higher than the last value from the x range provided in the function call (40 in the example below) the last value from the y range will be returned (3 in the example below). Example ##=@GET_Y_FX(@t('t'), {-1,20,40}, {1,2,3}, 'INTERPOL,NOHOLD') input output -10 1 2 1.142 10 1.523 NaN NaN 30 2.5 NaN NaN 50 3","title":"GET_Y_FX"},{"location":"mesh/calculations/functions/getyfx/#get_y_fx","text":"About the function The function looks up in an xy-relation, defined as argument to the function, with values from a time series that also is an argument to the function. The result is the y-value from the xy-relation, possibly interpolated. See also information about how to handle input values outside the provided range .","title":"GET_Y_FX"},{"location":"mesh/calculations/functions/getyfx/#syntax","text":"GET_Y_FX (t,D,D[,s])","title":"Syntax"},{"location":"mesh/calculations/functions/getyfx/#description","text":"# Type ## Description 1 t Series containing x-values used to lookup in the xy-relation to find the result value for current point of time. 2 D X-values, sorted increasingly. 3 D Y-values corresponding to the X-values given in the last argument. 4 s Can have the following values: INTERPOL - means that the y-value is interpolated, default is no interpolation NOHOLD - means that if you have a NaN on the X-series, the last calculated Y-value is not used. In default mode last calculated value is used. You may combine these two methods and separate them by using a comma. GET_Y_FX (t,D,D,[s]) corresponds to y=f(x)","title":"Description"},{"location":"mesh/calculations/functions/getyfx/#example","text":"Example 1: GET_Y_FX (t,D,D,[s]) R1 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3} ) R2 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3}, 'INTERPOL') R3 = @GET_Y_FX(%'/X series',{-1,20,40}, {1,2,3}, 'INTERPOL,NOHOLD' ) This gives the following values for an X-series presented in the first column. The function is best explained by an illustration: You state a curve band, iso curves in the form of an array of time series. These are associated with an array of y-values. In the above illustration the y-values are -1, 20 and 40, and time series 1 is associated with value -1, time series 2 with 20 and time series 3 with 40. The thickest black curve represents values on the input data series. In the points where this crosses the iso curves, a new result value is generated, as the blue curve shows.","title":"Example"},{"location":"mesh/calculations/functions/getyfx/#handle-input-values-outside-the-provided-range","text":"When an input is lower than the first value from the x range provided in the function call (-1 in the example below) the first value from the y range will be returned (1 in the example below). When an input is higher than the last value from the x range provided in the function call (40 in the example below) the last value from the y range will be returned (3 in the example below). Example ##=@GET_Y_FX(@t('t'), {-1,20,40}, {1,2,3}, 'INTERPOL,NOHOLD') input output -10 1 2 1.142 10 1.523 NaN NaN 30 2.5 NaN NaN 50 3","title":"Handle input values outside the provided range"},{"location":"mesh/calculations/functions/gliding_trend_average/","text":"GLIDING_TREND_AVERAGE About the function Reduces major fluctuations in a time series by calculating the future value on the basis of previous values. The result series has the same resolution as the input time series. Syntax GLIDING_TREND_AVERAGE(t,d[,d|D]) Description # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. 3 d Optional. Numerical value. If the value is different from 0, there will not be calculated any trend values outside the end period of the time series. 3 D Optional. D is a weighted array where the user can define which value is the most important. Example Example 1: GLIDING_TREND_AVERAGE(t,d) Waterlevel_hour_operative = @GLIDING_TREND_AVERAGE(@t('Waterlevel_hour_raw'),3) This example takes the average values of a selected number of previous values, and gives the anticipated values on the basis of these. d represents the number of previous values from which average values are calculated. For instance, in the table the average of the three closest previous values to Time 3 (including the value in Time 3) (8+20+19)/3 = 15,67. Example 2: GLIDING_TREND_AVERAGE(t,d,D) Waterlevel_hour_operative = @GLIDING_TREND_AVERAGE(@t('Waterlevel_hour_raw'),3,{3,2,1}) This example gives a trend where the closest value counts three times as much, and the second closest values counts twice as much as the third closest value for the trend. The array must contain the same number as the value used in argument 2. The sum is divided on the total number of weight factors.","title":"GLIDING_TREND_AVERAGE"},{"location":"mesh/calculations/functions/gliding_trend_average/#gliding_trend_average","text":"","title":"GLIDING_TREND_AVERAGE"},{"location":"mesh/calculations/functions/gliding_trend_average/#about-the-function","text":"Reduces major fluctuations in a time series by calculating the future value on the basis of previous values. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/gliding_trend_average/#syntax","text":"GLIDING_TREND_AVERAGE(t,d[,d|D]) Description # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. 3 d Optional. Numerical value. If the value is different from 0, there will not be calculated any trend values outside the end period of the time series. 3 D Optional. D is a weighted array where the user can define which value is the most important.","title":"Syntax"},{"location":"mesh/calculations/functions/gliding_trend_average/#example","text":"Example 1: GLIDING_TREND_AVERAGE(t,d) Waterlevel_hour_operative = @GLIDING_TREND_AVERAGE(@t('Waterlevel_hour_raw'),3) This example takes the average values of a selected number of previous values, and gives the anticipated values on the basis of these. d represents the number of previous values from which average values are calculated. For instance, in the table the average of the three closest previous values to Time 3 (including the value in Time 3) (8+20+19)/3 = 15,67. Example 2: GLIDING_TREND_AVERAGE(t,d,D) Waterlevel_hour_operative = @GLIDING_TREND_AVERAGE(@t('Waterlevel_hour_raw'),3,{3,2,1}) This example gives a trend where the closest value counts three times as much, and the second closest values counts twice as much as the third closest value for the trend. The array must contain the same number as the value used in argument 2. The sum is divided on the total number of weight factors.","title":"Example"},{"location":"mesh/calculations/functions/history/","text":"History group functions About historical values Historical values means that previously saved values are not overwritten when saving new values. The figure below shows a time series having values with various write times. The Calculator returns the values indicated by red when you ask for the most recently written historical values written before tc.","title":"About"},{"location":"mesh/calculations/functions/history/#history-group-functions","text":"","title":"History group functions"},{"location":"mesh/calculations/functions/history/#about-historical-values","text":"Historical values means that previously saved values are not overwritten when saving new values. The figure below shows a time series having values with various write times. The Calculator returns the values indicated by red when you ask for the most recently written historical values written before tc.","title":"About historical values"},{"location":"mesh/calculations/functions/inside/","text":"INSIDE About the function Returns a logical time series by testing an expression towards an upper and a lower limit. The result series has the same resolution as the input time series. Syntax INSIDE(d,t,d[,s]) INSIDE(t,t,t[,s]) Description # Type Description 1 d or t Numerical value, lower limit or Time series of numerical values, lower limit. 2 t Current time series to be tested. 3 d or t Numerical value, upper limit or Time series of numerical values, upper limit. 4 s Optional. Default value (no code): min 'LOHI': min 'LOW': min 'HIGH': min @INSIDE(d,t,d) Temperature_hour_VV = @INSIDE(0,@t('Temperature_hour_raw'),12) Values in @t('Temperature_hour_raw') > 0 or @INSIDE(d,t,d,s) Temperature_hour_VV = @INSIDE(0, @t('Temperature_hour_raw'), 12, 'LOHI') Values in @t('Temperature_hour_raw') \u2265 0 and \u2264 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and the upper limit 12 are evaluated to true. Temperature_hour_VV = @INSIDE(0, @t('Temperature_hour_raw'), 12, 'LOW') Values in @t('Temperature_hour_raw') \u2265 0 and 0 and \u2264 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here, values on the lower limit 0 are evaluated to false, values on the upper limit 12 are evaluated to true.","title":"Inside"},{"location":"mesh/calculations/functions/inside/#inside","text":"","title":"INSIDE"},{"location":"mesh/calculations/functions/inside/#about-the-function","text":"Returns a logical time series by testing an expression towards an upper and a lower limit. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/inside/#syntax","text":"INSIDE(d,t,d[,s]) INSIDE(t,t,t[,s])","title":"Syntax"},{"location":"mesh/calculations/functions/inside/#description","text":"# Type Description 1 d or t Numerical value, lower limit or Time series of numerical values, lower limit. 2 t Current time series to be tested. 3 d or t Numerical value, upper limit or Time series of numerical values, upper limit. 4 s Optional. Default value (no code): min 'LOHI': min 'LOW': min 'HIGH': min @INSIDE(d,t,d) Temperature_hour_VV = @INSIDE(0,@t('Temperature_hour_raw'),12) Values in @t('Temperature_hour_raw') > 0 or @INSIDE(d,t,d,s) Temperature_hour_VV = @INSIDE(0, @t('Temperature_hour_raw'), 12, 'LOHI') Values in @t('Temperature_hour_raw') \u2265 0 and \u2264 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and the upper limit 12 are evaluated to true. Temperature_hour_VV = @INSIDE(0, @t('Temperature_hour_raw'), 12, 'LOW') Values in @t('Temperature_hour_raw') \u2265 0 and 0 and \u2264 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here, values on the lower limit 0 are evaluated to false, values on the upper limit 12 are evaluated to true.","title":"Description"},{"location":"mesh/calculations/functions/integer/","text":"INTEGER About the function Converts a number in a time series to an integer by cutting all decimals. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number. Syntax INTEGER(t) INTEGER(d) Description # Type Description 1 t Time series 1 d Number Example Temperature corrected = @INTEGER(@t('.Temperature_raw')) The values in the result time series are converted to integers.","title":"INTEGER"},{"location":"mesh/calculations/functions/integer/#integer","text":"","title":"INTEGER"},{"location":"mesh/calculations/functions/integer/#about-the-function","text":"Converts a number in a time series to an integer by cutting all decimals. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number.","title":"About the function"},{"location":"mesh/calculations/functions/integer/#syntax","text":"INTEGER(t) INTEGER(d) Description # Type Description 1 t Time series 1 d Number","title":"Syntax"},{"location":"mesh/calculations/functions/integer/#example","text":"Temperature corrected = @INTEGER(@t('.Temperature_raw')) The values in the result time series are converted to integers.","title":"Example"},{"location":"mesh/calculations/functions/introduction/","text":"Introduction to Mesh functions Mesh allows you to efficiently manage time series data used in several work processes. The solution lets you structure your data in your own logical hierarchy. The hierarchy is built from custom defined object types related to each other in an object model. Time series and property types are connected to the objects. For more details about object model concepts, see Mesh System Guide. Template calculations setup The object model is well suited for setting up time series calculations as template expressions. This means more efficient set up and maintenance and ensures consistent results thought out the system. To set up a calculation expression in SmG Calculator with Mesh as a foundation, you refer to time series types and property types from the object model, instead of physical time series and values (see Reference lookup for more details about these functions, e.g. @t(s)). This is specified as a navigation path or a model search from the target time series type, which holds the calculation result in the same way as for virtual time series in TSM. The function syntax in Mesh are the same as for TSM, but Mesh does not support all TSM functions and vice versa. One specific calculation method is used for all the time series of the same type by use of one template definition. This reduces maintenance work dramatically and ensures data consistency. If you have set up a template calculation referring to a time series that is not connected to any physical time series reference, the result view will be empty. Using extended periods Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value;calculating accumulated series from the start of the year needs all valuesfrom this point, even if the requested period is September that year.In Mesh calculations,the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database.","title":"Introduction"},{"location":"mesh/calculations/functions/introduction/#introduction-to-mesh-functions","text":"Mesh allows you to efficiently manage time series data used in several work processes. The solution lets you structure your data in your own logical hierarchy. The hierarchy is built from custom defined object types related to each other in an object model. Time series and property types are connected to the objects. For more details about object model concepts, see Mesh System Guide.","title":"Introduction to Mesh functions"},{"location":"mesh/calculations/functions/introduction/#template-calculations-setup","text":"The object model is well suited for setting up time series calculations as template expressions. This means more efficient set up and maintenance and ensures consistent results thought out the system. To set up a calculation expression in SmG Calculator with Mesh as a foundation, you refer to time series types and property types from the object model, instead of physical time series and values (see Reference lookup for more details about these functions, e.g. @t(s)). This is specified as a navigation path or a model search from the target time series type, which holds the calculation result in the same way as for virtual time series in TSM. The function syntax in Mesh are the same as for TSM, but Mesh does not support all TSM functions and vice versa. One specific calculation method is used for all the time series of the same type by use of one template definition. This reduces maintenance work dramatically and ensures data consistency. If you have set up a template calculation referring to a time series that is not connected to any physical time series reference, the result view will be empty.","title":"Template calculations setup"},{"location":"mesh/calculations/functions/introduction/#using-extended-periods","text":"Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value;calculating accumulated series from the start of the year needs all valuesfrom this point, even if the requested period is September that year.In Mesh calculations,the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database.","title":"Using extended periods"},{"location":"mesh/calculations/functions/is_resolution/","text":"Resolution About the function Syntax IsResolution (t,s) Description Type Description t s Example","title":"IsResolution"},{"location":"mesh/calculations/functions/is_resolution/#resolution","text":"","title":"Resolution"},{"location":"mesh/calculations/functions/is_resolution/#about-the-function","text":"","title":"About the function"},{"location":"mesh/calculations/functions/is_resolution/#syntax","text":"IsResolution (t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/is_resolution/#description","text":"Type Description t s","title":"Description"},{"location":"mesh/calculations/functions/is_resolution/#example","text":"","title":"Example"},{"location":"mesh/calculations/functions/is_time_valid/","text":"IsTimeValid About the function The function returns 1 or 0 (true or false) to whether the argument is a valid time point or not. Syntax IsTimeValid(d) Description Type Description d A time point represented as a number.","title":"IsTimeValid"},{"location":"mesh/calculations/functions/is_time_valid/#istimevalid","text":"","title":"IsTimeValid"},{"location":"mesh/calculations/functions/is_time_valid/#about-the-function","text":"The function returns 1 or 0 (true or false) to whether the argument is a valid time point or not.","title":"About the function"},{"location":"mesh/calculations/functions/is_time_valid/#syntax","text":"IsTimeValid(d)","title":"Syntax"},{"location":"mesh/calculations/functions/is_time_valid/#description","text":"Type Description d A time point represented as a number.","title":"Description"},{"location":"mesh/calculations/functions/isvalid/","text":"IsValid About the function A time series reference specified by @t(\u2018TheReference\u2019) may give no result. The reason for this may be one of the following: TheReference does not exist. There is no connection to a physical time series from the current context. In these cases the system displays a warning message in the Nimbus Object Structure log. The warning message informs it could not resolve TheReference for a given object. You may use either IsValid or Valid to handle these cases. Syntax IsValid(t) IsValid(s,s) Description IsValid(t) Type Description t >Source time series that is normally the result of a @t('TheReference') . The function returns 1 or 0 representing true or false. Description IsValid(s,s) Type Description s Expected type of target, i.e. the entity found from the search/navigation defined in the next argument. Valid target codes are 't', 'd', 's', 'T', 'D' or 'S'. The codes represents time series, numeric, string, time series array, numeric array and string array respectively. s TheReference - The search/navigation string which defines where to go to find the target entity. This variant checks if there is a target of specified type available from the calculation context. If the target of the expected type is found, then the function returns 1 (representing true), otherwise the function returns 0. The function does not produce any log events when lookup fails.","title":"IsValid"},{"location":"mesh/calculations/functions/isvalid/#isvalid","text":"","title":"IsValid"},{"location":"mesh/calculations/functions/isvalid/#about-the-function","text":"A time series reference specified by @t(\u2018TheReference\u2019) may give no result. The reason for this may be one of the following: TheReference does not exist. There is no connection to a physical time series from the current context. In these cases the system displays a warning message in the Nimbus Object Structure log. The warning message informs it could not resolve TheReference for a given object. You may use either IsValid or Valid to handle these cases.","title":"About the function"},{"location":"mesh/calculations/functions/isvalid/#syntax","text":"IsValid(t) IsValid(s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/isvalid/#description-isvalidt","text":"Type Description t >Source time series that is normally the result of a @t('TheReference') . The function returns 1 or 0 representing true or false.","title":"Description IsValid(t)"},{"location":"mesh/calculations/functions/isvalid/#description-isvalidss","text":"Type Description s Expected type of target, i.e. the entity found from the search/navigation defined in the next argument. Valid target codes are 't', 'd', 's', 'T', 'D' or 'S'. The codes represents time series, numeric, string, time series array, numeric array and string array respectively. s TheReference - The search/navigation string which defines where to go to find the target entity. This variant checks if there is a target of specified type available from the calculation context. If the target of the expected type is found, then the function returns 1 (representing true), otherwise the function returns 0. The function does not produce any log events when lookup fails.","title":"Description IsValid(s,s)"},{"location":"mesh/calculations/functions/linear/","text":"Linear About the function Sets the curve type of argument series to piecewise linear or staircase start of step. Syntax Linear(t,s) Description # Type Description 1 t Source time series to change curve type for. 2 s True or false, linear or staircase respectively","title":"Linear"},{"location":"mesh/calculations/functions/linear/#linear","text":"","title":"Linear"},{"location":"mesh/calculations/functions/linear/#about-the-function","text":"Sets the curve type of argument series to piecewise linear or staircase start of step.","title":"About the function"},{"location":"mesh/calculations/functions/linear/#syntax","text":"Linear(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/linear/#description","text":"# Type Description 1 t Source time series to change curve type for. 2 s True or false, linear or staircase respectively","title":"Description"},{"location":"mesh/calculations/functions/ln/","text":"LN About the function Finds the ln value of the values in a time series or of a number. Logarithms with base numbers that equal euler's number (e= 2,718281828\u2026) is called natural logarithms. The logarithm to a number x, is the exponent c, which the base number must be raised with to get the number x. ec = x -> ln xe = c The input value must be a positive, real number lager than 0, if not, the function returns an empty value. Syntax LN(t|d) Description # Type Description 1 t Time series 1 d Number Example Example 1: LN(t) Temperature_hour_VV = @LN(@t('Temperature_hour_raw')) Example 2: LN(d) ResultTs = @LN(1) Example 2 returns the number 0 for all rows.","title":"LN"},{"location":"mesh/calculations/functions/ln/#ln","text":"","title":"LN"},{"location":"mesh/calculations/functions/ln/#about-the-function","text":"Finds the ln value of the values in a time series or of a number. Logarithms with base numbers that equal euler's number (e= 2,718281828\u2026) is called natural logarithms. The logarithm to a number x, is the exponent c, which the base number must be raised with to get the number x. ec = x -> ln xe = c The input value must be a positive, real number lager than 0, if not, the function returns an empty value.","title":"About the function"},{"location":"mesh/calculations/functions/ln/#syntax","text":"LN(t|d)","title":"Syntax"},{"location":"mesh/calculations/functions/ln/#description","text":"# Type Description 1 t Time series 1 d Number","title":"Description"},{"location":"mesh/calculations/functions/ln/#example","text":"Example 1: LN(t) Temperature_hour_VV = @LN(@t('Temperature_hour_raw')) Example 2: LN(d) ResultTs = @LN(1) Example 2 returns the number 0 for all rows.","title":"Example"},{"location":"mesh/calculations/functions/log/","text":"LOG About the function This function is used to find the logarithm of values in a time series or a number. Briggs logarithms use the base number 10. The logarithm to a number x, is the exponent c, which the base number must be raised with to get the number x. 10c = x -> log x10 = c The input value must be a positive number larger than 0. If not, the function returns an empty value. S yntax LOG(t|d) # Type Description 1 t Time series 1 d Number Example Example 1: @LOG(t) Temperature_hour_VV = @LOG(@t('Temperature_hour_raw')) Example 2: @LOG(d) ResultTs = @LOG(1) Example 2 returns the number 0 for all rows.","title":"LOG"},{"location":"mesh/calculations/functions/log/#log","text":"","title":"LOG"},{"location":"mesh/calculations/functions/log/#about-the-function","text":"This function is used to find the logarithm of values in a time series or a number. Briggs logarithms use the base number 10. The logarithm to a number x, is the exponent c, which the base number must be raised with to get the number x. 10c = x -> log x10 = c The input value must be a positive number larger than 0. If not, the function returns an empty value. S yntax LOG(t|d) # Type Description 1 t Time series 1 d Number","title":"About the function"},{"location":"mesh/calculations/functions/log/#example","text":"Example 1: @LOG(t) Temperature_hour_VV = @LOG(@t('Temperature_hour_raw')) Example 2: @LOG(d) ResultTs = @LOG(1) Example 2 returns the number 0 for all rows.","title":"Example"},{"location":"mesh/calculations/functions/max/","text":"MAX About the functions Finds the highest values in time series, numbers, arrays or combinations of these. The result series has the same resolution as the input time series. Syntax MAX(T) MAX(d) MAX(D) MAX(t) MAX(t,t) MAX(T,t) MAX(t,T) MAX(t,d) MAX(d,d) MAX(T,T) # Type Description 1 t T d D Time series. Array of time series. Number. Array of numbers. 2 t d T Time series. Optional. Number. Optional. Array of time series. Optional. Example Example 1: @MAX(t) ResTs = @MAX(@t('Ts') Returns the highest value of the time series for the requested period. See similar example for the @MIN(t) function . Example 2: @MAX(t,t) ResTs = @MAX(@t('Ts1'),@t('Ts2')) Returns the highest value of time series 1 and 2 for every time step. See similar example for the @MIN(t,t) function . Example 3: @MAX(d,d) Res = @MAX(8,2.5) Res = 8 Returns the largest of the two values. Example 4: @MAX(D) Res = @MAX({1,5,8,2.5,11}) Res = 11 Returns the largest value of the array of numbers. Example 5: @MAX(T) ResTs = @MAX({@t('Ts1'),@t('Ts2'),@t('Ts3')}) {@t('Ts1'),@t('Ts2'),@t('Ts3')} is an array of time series. Returns the largest value of all the time series of the array for every time step.","title":"MAX"},{"location":"mesh/calculations/functions/max/#max","text":"About the functions Finds the highest values in time series, numbers, arrays or combinations of these. The result series has the same resolution as the input time series. Syntax MAX(T) MAX(d) MAX(D) MAX(t) MAX(t,t) MAX(T,t) MAX(t,T) MAX(t,d) MAX(d,d) MAX(T,T) # Type Description 1 t T d D Time series. Array of time series. Number. Array of numbers. 2 t d T Time series. Optional. Number. Optional. Array of time series. Optional.","title":"MAX"},{"location":"mesh/calculations/functions/max/#example","text":"","title":"Example"},{"location":"mesh/calculations/functions/max/#example-1-maxt","text":"ResTs = @MAX(@t('Ts') Returns the highest value of the time series for the requested period. See similar example for the @MIN(t) function .","title":"Example 1: @MAX(t)"},{"location":"mesh/calculations/functions/max/#example-2-maxtt","text":"ResTs = @MAX(@t('Ts1'),@t('Ts2')) Returns the highest value of time series 1 and 2 for every time step. See similar example for the @MIN(t,t) function .","title":"Example 2: @MAX(t,t)"},{"location":"mesh/calculations/functions/max/#example-3-maxdd","text":"Res = @MAX(8,2.5) Res = 8 Returns the largest of the two values.","title":"Example 3: @MAX(d,d)"},{"location":"mesh/calculations/functions/max/#example-4-maxd","text":"Res = @MAX({1,5,8,2.5,11}) Res = 11 Returns the largest value of the array of numbers.","title":"Example 4: @MAX(D)"},{"location":"mesh/calculations/functions/max/#example-5-maxt","text":"ResTs = @MAX({@t('Ts1'),@t('Ts2'),@t('Ts3')}) {@t('Ts1'),@t('Ts2'),@t('Ts3')} is an array of time series. Returns the largest value of all the time series of the array for every time step.","title":"Example 5: @MAX(T)"},{"location":"mesh/calculations/functions/mean/","text":"MEAN About the function Takes the average value of time series, arrays and number series. The result series has the same resolution as the input time series. Syntax MEAN(t|T|D) Description # TYPE DESCRIPTION 1 t or T or D Time series Array of time series Array of numbers Example Example 1: @MEAN(t) TempPercentiles = @MEAN(@t('Temperature_hour_raw')) The result values are the average value of the values in @t('Temperature_hour_raw') for the requested time period, repeated throughout the entire result series as a break point series. Tip! If you want to calculate the mean value for a period different from the requested time period, you can use the PushExtPeriod / PopExtPeriod function to explicitly define the input period to the function. Example 2: @MEAN(T) Temperature_hour_operative = @MEAN(@T('Temperature_hour')) The Temperature_hour_operative column gives the average value of all the time series in the array for every time step. For instance at 01:00: (-1,26+3,09+8,87)/3 = 3,57 Example 3: @MEAN(D) Res = @MEAN(1,5,8,2.5,11) Res = 5.5","title":"MEAN"},{"location":"mesh/calculations/functions/mean/#mean","text":"","title":"MEAN"},{"location":"mesh/calculations/functions/mean/#about-the-function","text":"Takes the average value of time series, arrays and number series. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/mean/#syntax","text":"MEAN(t|T|D)","title":"Syntax"},{"location":"mesh/calculations/functions/mean/#description","text":"# TYPE DESCRIPTION 1 t or T or D Time series Array of time series Array of numbers","title":"Description"},{"location":"mesh/calculations/functions/mean/#example","text":"Example 1: @MEAN(t) TempPercentiles = @MEAN(@t('Temperature_hour_raw')) The result values are the average value of the values in @t('Temperature_hour_raw') for the requested time period, repeated throughout the entire result series as a break point series. Tip! If you want to calculate the mean value for a period different from the requested time period, you can use the PushExtPeriod / PopExtPeriod function to explicitly define the input period to the function. Example 2: @MEAN(T) Temperature_hour_operative = @MEAN(@T('Temperature_hour')) The Temperature_hour_operative column gives the average value of all the time series in the array for every time step. For instance at 01:00: (-1,26+3,09+8,87)/3 = 3,57 Example 3: @MEAN(D) Res = @MEAN(1,5,8,2.5,11) Res = 5.5","title":"Example"},{"location":"mesh/calculations/functions/meshid/","text":"MeshID This function is used to get an identification of the Mesh object having a calculated time series where this function is used. It is also possible to get the identification from a related Mesh object by giving a search or navigation suffix to the function argument. Syntax MeshID(s) Description Type Description s What type of identification to get and if it contains two parts divided by a semicolon (;) it also defines where to get it from. Valid specification of what type of id to get can be one of: NAME, TYPE, GUID or WRAPPEDGUID. The second part (optional part coming after a semicolon) is a relative navigation or search definition. Relative to current Mesh object. The function returns a symbol (a string). Note! The navigation strings are model dependent. Example Ident = @MeshID(\u2018NAME\u2019) Returns the name of current object (the one owning this calculation) Ident = @MeshID(\u2018TYPE\u2019) Returns name of the type that current object is an instance of Ident = @MeshID(\u2018NAME;to_PriceArea\u2019) Returns the name of the object found on the other side of the navigation given by relation name to_PriceArea. Ident = @MeshID(\u2018NAME;to_PriceArea/..\u2019) Returns the name of the parent object of the object found on the other side of the navigation given by relation name to_PriceArea.","title":"MeshId"},{"location":"mesh/calculations/functions/meshid/#meshid","text":"This function is used to get an identification of the Mesh object having a calculated time series where this function is used. It is also possible to get the identification from a related Mesh object by giving a search or navigation suffix to the function argument.","title":"MeshID"},{"location":"mesh/calculations/functions/meshid/#syntax","text":"MeshID(s) Description Type Description s What type of identification to get and if it contains two parts divided by a semicolon (;) it also defines where to get it from. Valid specification of what type of id to get can be one of: NAME, TYPE, GUID or WRAPPEDGUID. The second part (optional part coming after a semicolon) is a relative navigation or search definition. Relative to current Mesh object. The function returns a symbol (a string). Note! The navigation strings are model dependent.","title":"Syntax"},{"location":"mesh/calculations/functions/meshid/#example","text":"Ident = @MeshID(\u2018NAME\u2019) Returns the name of current object (the one owning this calculation) Ident = @MeshID(\u2018TYPE\u2019) Returns name of the type that current object is an instance of Ident = @MeshID(\u2018NAME;to_PriceArea\u2019) Returns the name of the object found on the other side of the navigation given by relation name to_PriceArea. Ident = @MeshID(\u2018NAME;to_PriceArea/..\u2019) Returns the name of the parent object of the object found on the other side of the navigation given by relation name to_PriceArea.","title":"Example"},{"location":"mesh/calculations/functions/min/","text":"MIN About the function Finds the highest values in time series, numbers, arrays or combinations of these. The result series has the same resolution as the input time series. Syntax MIN(T) MIN(D) MIN(t) MIN(t,t) MIN(T,t) MIN(t,T) MIN(t,d) MIN(d,t) MIN(d,d) MIN(T,T) Description # Type Description 1 t T d D Time series Array of time series Number Array of numbers 2 t d T Time series Number Array of time series Example Example 1: @MIN(T) Temperature_hour_operative = @MIN(@T('Temperature_hour')) @T(\u2018Temperature_hour\u2019) is an array of time series. Returns the lowest value of all the time series in the array for each time step, e.g.: Example 2: @MIN(D) Result = @MIN({1, 5, 8, 2.5, 11}) Result = 1 Result returns the lowest value from the array of numbers. Example 3: @MIN(t) Returns the lowest values from the time series for the requested period. Temperature_hour_operative = @t('Temperature_hour_raw')/@MIN(@t('Temperature_hour_raw')) From the requested period, we can see that the minimum value is -5. Used in calculation the result values are divided on -5. Temperature_hour_operative = @t('Temperature_hour_raw')+@MIN(@t('Temperature_hour_raw')) From the requested period, we can see that the minimum value is -5. Used in calculation the result values are added by -5. Example 4: @MIN(t,t) Temperature_hour_operative = @MIN(@t('Temperature_hour_raw'),@t('TempManualCorrection')) It returns the lowest of the values for each time step in time series 1 and time series 2. Example 5: @MIN(T,t) Temperature_hour_operative = @MIN(@T('Temperature_hour'),@t('TempManualCorrection')) @T('Temperature_hour') is an array of three time series. @t('TempManualCorrection') is a single time series. Returns the lowest value of the time series in the array and the single time series for each time step, e.g.: Example 6: @MIN(t,d) Temperature_hour_operative = @MIN(@t('Temperature_hour_raw'),-0.5) Returns the lowest value of the time series and a selected number for each time step, e.g.: Example 7: @MIN(d,d) Res = @MIN(8,2.5) Res = 2.5 Returns the lowest value of the two numbers.","title":"MIN"},{"location":"mesh/calculations/functions/min/#min","text":"","title":"MIN"},{"location":"mesh/calculations/functions/min/#about-the-function","text":"Finds the highest values in time series, numbers, arrays or combinations of these. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/min/#syntax","text":"MIN(T) MIN(D) MIN(t) MIN(t,t) MIN(T,t) MIN(t,T) MIN(t,d) MIN(d,t) MIN(d,d) MIN(T,T)","title":"Syntax"},{"location":"mesh/calculations/functions/min/#description","text":"# Type Description 1 t T d D Time series Array of time series Number Array of numbers 2 t d T Time series Number Array of time series","title":"Description"},{"location":"mesh/calculations/functions/min/#example","text":"Example 1: @MIN(T) Temperature_hour_operative = @MIN(@T('Temperature_hour')) @T(\u2018Temperature_hour\u2019) is an array of time series. Returns the lowest value of all the time series in the array for each time step, e.g.: Example 2: @MIN(D) Result = @MIN({1, 5, 8, 2.5, 11}) Result = 1 Result returns the lowest value from the array of numbers. Example 3: @MIN(t) Returns the lowest values from the time series for the requested period. Temperature_hour_operative = @t('Temperature_hour_raw')/@MIN(@t('Temperature_hour_raw')) From the requested period, we can see that the minimum value is -5. Used in calculation the result values are divided on -5. Temperature_hour_operative = @t('Temperature_hour_raw')+@MIN(@t('Temperature_hour_raw')) From the requested period, we can see that the minimum value is -5. Used in calculation the result values are added by -5. Example 4: @MIN(t,t) Temperature_hour_operative = @MIN(@t('Temperature_hour_raw'),@t('TempManualCorrection')) It returns the lowest of the values for each time step in time series 1 and time series 2. Example 5: @MIN(T,t) Temperature_hour_operative = @MIN(@T('Temperature_hour'),@t('TempManualCorrection')) @T('Temperature_hour') is an array of three time series. @t('TempManualCorrection') is a single time series. Returns the lowest value of the time series in the array and the single time series for each time step, e.g.: Example 6: @MIN(t,d) Temperature_hour_operative = @MIN(@t('Temperature_hour_raw'),-0.5) Returns the lowest value of the time series and a selected number for each time step, e.g.: Example 7: @MIN(d,d) Res = @MIN(8,2.5) Res = 2.5 Returns the lowest value of the two numbers.","title":"Example"},{"location":"mesh/calculations/functions/mix/","text":"MIX About the function The variations of this function combine two series to form a new one by retrieving values from one or the other series according to specific rules. This function is a compact form of if-then-else operation. All of the time series included must have the same time resolution. The result series has the same time resolution as the input time series. Syntax MIX(t,t,[s|t]) The different variations of this function are described below. For MIX(t,T) and MIX(t,T,t), see MIX by selecting from time series array . Description MIX(t,t) and MIX(t,t,s) # Type Description 1 t Time series. 2 t Time series. 3 s Optional. Possible values are described in the table below. Value of symbol Description END The values on the result are retrieved from the first time series until defined end point of time for this time series. Time macro General syntax for stating point of time, normally relative to a start of hour, day, week, etc. The result retrieves values from the first time series until the point of time given by the time macro. Examples of valid time macros: HOUR Star of current hour HOUR-1h Start of last hour DAY Start of current 24-hour period DAY+1d Start of next 24-hour period WEEK+2d Start of Wednesday in current week MERGE Retrieves values to result series from the second time series if functional value on time series 1 at this point of time is NaN. That is values from the second time series are visible on result where time series 1 has gaps. MERGE_ADD Retrieves value from the second time series if this is a real value (not NaN). MERGE_POINTS As the MERGE version, but checks whether there is a point value for the point of time on the first time series. If no, the value from the second time series is used on this point of time. Will only have the intended effect if you have a breakpoint series. Example @MIX(tt) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@t('Temperature_hour_raw')) Values in the result time series return a value from the first time series if this exists, otherwise the value from the second time series is retrieved, as shown in the table. Description MIX(t,t,t) # Type Description 1 t The argument is used as a logical test series, in which the values are interpreted as TRUE or FALSE. All defined values which are not equal to 0 or NaN are considered to be TRUE values. 2 t The function gets its values from this time series if the first argument returns TRUE. 3 t Optional. The function gets its values from this time series if the first argument returns FALSE. Example @MIX(t,t,t) Temperature_hour_operative = @MIX(@t('Temperature_hour_raw'),@t('TempPercentiles'),@t('TempManualCorrection')) Tip! See also MIX0 .","title":"MIX"},{"location":"mesh/calculations/functions/mix/#mix","text":"","title":"MIX"},{"location":"mesh/calculations/functions/mix/#about-the-function","text":"The variations of this function combine two series to form a new one by retrieving values from one or the other series according to specific rules. This function is a compact form of if-then-else operation. All of the time series included must have the same time resolution. The result series has the same time resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/mix/#syntax","text":"MIX(t,t,[s|t]) The different variations of this function are described below. For MIX(t,T) and MIX(t,T,t), see MIX by selecting from time series array . Description MIX(t,t) and MIX(t,t,s) # Type Description 1 t Time series. 2 t Time series. 3 s Optional. Possible values are described in the table below. Value of symbol Description END The values on the result are retrieved from the first time series until defined end point of time for this time series. Time macro General syntax for stating point of time, normally relative to a start of hour, day, week, etc. The result retrieves values from the first time series until the point of time given by the time macro. Examples of valid time macros: HOUR Star of current hour HOUR-1h Start of last hour DAY Start of current 24-hour period DAY+1d Start of next 24-hour period WEEK+2d Start of Wednesday in current week MERGE Retrieves values to result series from the second time series if functional value on time series 1 at this point of time is NaN. That is values from the second time series are visible on result where time series 1 has gaps. MERGE_ADD Retrieves value from the second time series if this is a real value (not NaN). MERGE_POINTS As the MERGE version, but checks whether there is a point value for the point of time on the first time series. If no, the value from the second time series is used on this point of time. Will only have the intended effect if you have a breakpoint series.","title":"Syntax"},{"location":"mesh/calculations/functions/mix/#example","text":"@MIX(tt) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@t('Temperature_hour_raw')) Values in the result time series return a value from the first time series if this exists, otherwise the value from the second time series is retrieved, as shown in the table. Description MIX(t,t,t) # Type Description 1 t The argument is used as a logical test series, in which the values are interpreted as TRUE or FALSE. All defined values which are not equal to 0 or NaN are considered to be TRUE values. 2 t The function gets its values from this time series if the first argument returns TRUE. 3 t Optional. The function gets its values from this time series if the first argument returns FALSE.","title":"Example"},{"location":"mesh/calculations/functions/mix/#example_1","text":"@MIX(t,t,t) Temperature_hour_operative = @MIX(@t('Temperature_hour_raw'),@t('TempPercentiles'),@t('TempManualCorrection')) Tip! See also MIX0 .","title":"Example"},{"location":"mesh/calculations/functions/mix0/","text":"MIX0 About the function Returns values from the first series of the argument (time series or an array of time series) different from 0. If both/all series return the value 0, 0 is returned. If both/all series have a missing value, missing value is returned. Syntax MIX0(t,t) MIX0(T) The time series are fixed interval series, i.e. hour, day, week, etc. Example Example 1: @MIX0(t,t) Temperature_hour_operative = @MIX0(@t('TempManualCorrection'),@t('Temperature_hour_raw')) For each time step the MIX0 function returns values from the first time series if the value is different from 0, otherwise it uses values from the second time. If both series have value 0, 0 is returned. If both series have missing value, missing value is returned. Result is shown in the last column of the table. Example 2: @MIX0(T) Temperature_hour_operative = @MIX0(@T('Temperature_hour')) For each time step the MIX0 function returns values from the first series in the array different from 0. If all series have 0, 0 is returned. If all series have missing values, missing value is returned. Result is shown in the last column of the table.","title":"MIX0"},{"location":"mesh/calculations/functions/mix0/#mix0","text":"","title":"MIX0"},{"location":"mesh/calculations/functions/mix0/#about-the-function","text":"Returns values from the first series of the argument (time series or an array of time series) different from 0. If both/all series return the value 0, 0 is returned. If both/all series have a missing value, missing value is returned.","title":"About the function"},{"location":"mesh/calculations/functions/mix0/#syntax","text":"MIX0(t,t) MIX0(T) The time series are fixed interval series, i.e. hour, day, week, etc.","title":"Syntax"},{"location":"mesh/calculations/functions/mix0/#example","text":"Example 1: @MIX0(t,t) Temperature_hour_operative = @MIX0(@t('TempManualCorrection'),@t('Temperature_hour_raw')) For each time step the MIX0 function returns values from the first time series if the value is different from 0, otherwise it uses values from the second time. If both series have value 0, 0 is returned. If both series have missing value, missing value is returned. Result is shown in the last column of the table. Example 2: @MIX0(T) Temperature_hour_operative = @MIX0(@T('Temperature_hour')) For each time step the MIX0 function returns values from the first series in the array different from 0. If all series have 0, 0 is returned. If all series have missing values, missing value is returned. Result is shown in the last column of the table.","title":"Example"},{"location":"mesh/calculations/functions/mix_by_selecting_from_time_series_array/","text":"MIX by selecting from time series array About this function MIX is a function that calculates result series by mixing contribution from a set of input time series. A typical usage is to handle multiple 'if-elseif-else\u2019 constructions defined by index criteria. The main purpose of this function is to effectively set up and calculate multiple choice logic, typical defined by if \u2013 elseif \u2013 elseif \u2013 else constructs. Syntax MIX(t,T[,t]) Description # Type Description 1 t A time series with contribution index is used for lookup in an array of contributions defined by the next argument. The values are transformed to nearest integer before use. This argument might be a series with any resolution. 2 T The array of contribution series contains potential contributions to the result and is associated with the index found in the previous argument. The lookup index is defined from 1 to n where n is the number of series in the array. 3 t Optional. Default series. The function gets its values from this time series if argument 1 is false. The time series in the array can have different resolutions. The resolution of the result series is defined like this: Default series not defined: The result series has the same resolution as the highest resolution found. The result values are copied from first series in array for periods when contribution index found in argument 1 series is 1, from second series when contribution index is 2 etc. Default series defined: If contribution index is out of range, the corresponding result values are retrieved from default series. Example Example 1: @MIX(t,T) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@T('Temperature_hour')) TempManualCorrection contains index values. Temperature_hour 1,2 and 3 are time series in the array. In the case of an empty index or values outside of 1,2,3 an undefined value is returned. The result is shown in the second column of the table. Example 2: @MIX(t,T,t) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@T('Temperature_hour'),@t('TempPercentiles')) In the case of an empty index or values outside of 1,2,3 values from the time series in the 3.rd argument are used. The result is shown in the second column of the table. Example 3: @MIX(t,T,t) ## = @MIX(@t('TsSelector'),{@t('Ts1'),@t('Ts2'),@t('Ts1')*2.3,@t('Ts1')+@t('Ts2')},@t('TsDefault')) Array-members can be defined as an expression. These expressions can be more or less complicated as long as they return a single series. The example represents the following \"pseudocode\": if ( selection equals 1 ) then result = Ts1 else if ( selection equals 2 ) then result = Ts2 else if ( selection equals 3 ) then result = Ts1 * 2.3 else if ( selection equals 4 ) then result = Ts1+Ts2 else result = TsDefault In this case the series TsSelector Default with values 1,2,3,4 finds corresponding values from series found in an array. For TsSelector values less than 1 and larger than 4 the resulting values comes from the TsDefault-series, if defined. If not, the function assign the value NaN (Not a Number).","title":"MIX by selecting from time series array"},{"location":"mesh/calculations/functions/mix_by_selecting_from_time_series_array/#mix-by-selecting-from-time-series-array","text":"About this function MIX is a function that calculates result series by mixing contribution from a set of input time series. A typical usage is to handle multiple 'if-elseif-else\u2019 constructions defined by index criteria. The main purpose of this function is to effectively set up and calculate multiple choice logic, typical defined by if \u2013 elseif \u2013 elseif \u2013 else constructs.","title":"MIX by selecting from time series array"},{"location":"mesh/calculations/functions/mix_by_selecting_from_time_series_array/#syntax","text":"MIX(t,T[,t])","title":"Syntax"},{"location":"mesh/calculations/functions/mix_by_selecting_from_time_series_array/#description","text":"# Type Description 1 t A time series with contribution index is used for lookup in an array of contributions defined by the next argument. The values are transformed to nearest integer before use. This argument might be a series with any resolution. 2 T The array of contribution series contains potential contributions to the result and is associated with the index found in the previous argument. The lookup index is defined from 1 to n where n is the number of series in the array. 3 t Optional. Default series. The function gets its values from this time series if argument 1 is false. The time series in the array can have different resolutions. The resolution of the result series is defined like this: Default series not defined: The result series has the same resolution as the highest resolution found. The result values are copied from first series in array for periods when contribution index found in argument 1 series is 1, from second series when contribution index is 2 etc. Default series defined: If contribution index is out of range, the corresponding result values are retrieved from default series.","title":"Description"},{"location":"mesh/calculations/functions/mix_by_selecting_from_time_series_array/#example","text":"Example 1: @MIX(t,T) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@T('Temperature_hour')) TempManualCorrection contains index values. Temperature_hour 1,2 and 3 are time series in the array. In the case of an empty index or values outside of 1,2,3 an undefined value is returned. The result is shown in the second column of the table. Example 2: @MIX(t,T,t) Temperature_hour_operative = @MIX(@t('TempManualCorrection'),@T('Temperature_hour'),@t('TempPercentiles')) In the case of an empty index or values outside of 1,2,3 values from the time series in the 3.rd argument are used. The result is shown in the second column of the table. Example 3: @MIX(t,T,t) ## = @MIX(@t('TsSelector'),{@t('Ts1'),@t('Ts2'),@t('Ts1')*2.3,@t('Ts1')+@t('Ts2')},@t('TsDefault')) Array-members can be defined as an expression. These expressions can be more or less complicated as long as they return a single series. The example represents the following \"pseudocode\": if ( selection equals 1 ) then result = Ts1 else if ( selection equals 2 ) then result = Ts2 else if ( selection equals 3 ) then result = Ts1 * 2.3 else if ( selection equals 4 ) then result = Ts1+Ts2 else result = TsDefault In this case the series TsSelector Default with values 1,2,3,4 finds corresponding values from series found in an array. For TsSelector values less than 1 and larger than 4 the resulting values comes from the TsDefault-series, if defined. If not, the function assign the value NaN (Not a Number).","title":"Example"},{"location":"mesh/calculations/functions/negative/","text":"NEGATIVE About the function Picks the negative values from a time series. Zero is considered to be a positive number. Syntax NEGATIVE(t[,d[,s]]) # Type Description 1 t Input time series. Picks the negative values from the time series. 0 (zero) is by default considered as a positive number. 2 d Optional. Numerical value. Defines if 0 (zero) is considered as a positive or negative number. If 1 is set in argument 2, 0 is considered as a negative number. Use of other numbers in argument 2, or if argument 2 is omitted, it means 0 (zero) is considered as a positive number. 3 s Optional. VALUE \u2013 Default behavior. Gives the result of the function as a normal time series. If argument 3 is omitted, this is the default behavior. BOOL - Converts the result into a logical time series (values 1 and 0). BOOL_COMPRESS \u2013 Converts the result into a logical time series (values 1 and 0) with compressing of equal numbers. The resolution is a breakpoint time series. Example @NEGATIVE(t) From the table, we can see that only negative numbers are returned. Positive numbers and NaN return empty rows.","title":"Negative"},{"location":"mesh/calculations/functions/negative/#negative","text":"","title":"NEGATIVE"},{"location":"mesh/calculations/functions/negative/#about-the-function","text":"Picks the negative values from a time series. Zero is considered to be a positive number.","title":"About the function"},{"location":"mesh/calculations/functions/negative/#syntax","text":"NEGATIVE(t[,d[,s]]) # Type Description 1 t Input time series. Picks the negative values from the time series. 0 (zero) is by default considered as a positive number. 2 d Optional. Numerical value. Defines if 0 (zero) is considered as a positive or negative number. If 1 is set in argument 2, 0 is considered as a negative number. Use of other numbers in argument 2, or if argument 2 is omitted, it means 0 (zero) is considered as a positive number. 3 s Optional. VALUE \u2013 Default behavior. Gives the result of the function as a normal time series. If argument 3 is omitted, this is the default behavior. BOOL - Converts the result into a logical time series (values 1 and 0). BOOL_COMPRESS \u2013 Converts the result into a logical time series (values 1 and 0) with compressing of equal numbers. The resolution is a breakpoint time series.","title":"Syntax"},{"location":"mesh/calculations/functions/negative/#example","text":"@NEGATIVE(t) From the table, we can see that only negative numbers are returned. Positive numbers and NaN return empty rows.","title":"Example"},{"location":"mesh/calculations/functions/normal/","text":"Normal About the function Calculates various normal series for input series with respect to a defined history period given as from and until year. Syntax Normal(t,d,d,s,s,d) Description # Type Description Example 1 t Source time series to create percentile from. 2 d Start year 1990 3 d Until year 2000 4 s The normal type to be calculated. Available types are: MIN, MAX, AVERAGE and MEDIAN. AVERAGE 5 s The smoothing method to apply prior to calculating the normal. Available types are: NONE, AVERAGE, MEDIAN, GAUSS, MEDIAN_GAUSS Implicitly applies the corresponding TS_GLIDING_* function. AVERAGE 6 d Size of the smoothing value window. Zero means no smoothing. Must be an odd number. If input is an even number greater than 0, it is incremented by one. Example syntax Normal_temperature = @Normal(@t('Temperature_hour_operative'),2000,2013,'Max','MEDIAN_GAUSS',3)","title":"Normal"},{"location":"mesh/calculations/functions/normal/#normal","text":"About the function Calculates various normal series for input series with respect to a defined history period given as from and until year.","title":"Normal"},{"location":"mesh/calculations/functions/normal/#syntax","text":"Normal(t,d,d,s,s,d)","title":"Syntax"},{"location":"mesh/calculations/functions/normal/#description","text":"# Type Description Example 1 t Source time series to create percentile from. 2 d Start year 1990 3 d Until year 2000 4 s The normal type to be calculated. Available types are: MIN, MAX, AVERAGE and MEDIAN. AVERAGE 5 s The smoothing method to apply prior to calculating the normal. Available types are: NONE, AVERAGE, MEDIAN, GAUSS, MEDIAN_GAUSS Implicitly applies the corresponding TS_GLIDING_* function. AVERAGE 6 d Size of the smoothing value window. Zero means no smoothing. Must be an odd number. If input is an even number greater than 0, it is incremented by one. Example syntax Normal_temperature = @Normal(@t('Temperature_hour_operative'),2000,2013,'Max','MEDIAN_GAUSS',3)","title":"Description"},{"location":"mesh/calculations/functions/not/","text":"NOT About the function Checks the content of a time series for values 0 or NaN. The result series has Boolean values and has the same resolution as the input time series. Syntax NOT(t) Description The resulting value is 1 if the value found is 0 or NaN. Otherwise, the result is 0. Example Temperature_hour_VV =@NOT(@t('Temperature_hour_raw') In row 2 the result is 1, as the value of Temperature_hour_raw is 0 or NaN.","title":"Not"},{"location":"mesh/calculations/functions/not/#not","text":"","title":"NOT"},{"location":"mesh/calculations/functions/not/#about-the-function","text":"Checks the content of a time series for values 0 or NaN. The result series has Boolean values and has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/not/#syntax","text":"NOT(t)","title":"Syntax"},{"location":"mesh/calculations/functions/not/#description","text":"The resulting value is 1 if the value found is 0 or NaN. Otherwise, the result is 0.","title":"Description"},{"location":"mesh/calculations/functions/not/#example","text":"Temperature_hour_VV =@NOT(@t('Temperature_hour_raw') In row 2 the result is 1, as the value of Temperature_hour_raw is 0 or NaN.","title":"Example"},{"location":"mesh/calculations/functions/outside/","text":"OUTSIDE About the function Returns a logical time series by testing an expression towards an upper and a lower limit. The result series has the same resolution as the input time series. Syntax OUTSIDE(d,t,d[,s]) OUTSIDE(t,t,t[,s]) Description # Type Description 1 d or t Numerical value, lower limit or Time series of numerical values, lower limit. 2 t Current time series to be tested. 3 d or t Numerical value, upper limit or Time series of numerical values, upper limit. 4 s Optional. Default value (no code): min > expression or expression > max 'LOHI': min >= expression or expression >= max 'LOW': min >= expression or expression > max 'HIGH': min > expression or expression >= max Example Example 1: @OUTSIDE(d,t,d) Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12) Values in @t('Temperature_hour_raw') 12 are evaluated to true (1). Other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and upper limit 12 are evaluated to false. Example 2: @OUTSIDE(d,t,d,s) Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'LOHI') Values in @t('Temperature_hour_raw') \u22640 and \u226512 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and upper limit 12 are evaluated to true. Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'LOW') Values in @t('Temperature_hour_raw') \u22640 and > 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on the lower limit 0 are evaluated to true and values on the upper limit 12 are evaluated to false. Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'HIGH') Values in @t('Temperature_hour_raw') < 0 and \u2265 12 are evaluate to true (1), other values and NaN are evaluated to false (0). Here values on the lower limit 0 are evaluated to false and values on the upper limit 12 are evaluated to true.","title":"Outside"},{"location":"mesh/calculations/functions/outside/#outside","text":"","title":"OUTSIDE"},{"location":"mesh/calculations/functions/outside/#about-the-function","text":"Returns a logical time series by testing an expression towards an upper and a lower limit. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/outside/#syntax","text":"OUTSIDE(d,t,d[,s]) OUTSIDE(t,t,t[,s])","title":"Syntax"},{"location":"mesh/calculations/functions/outside/#description","text":"# Type Description 1 d or t Numerical value, lower limit or Time series of numerical values, lower limit. 2 t Current time series to be tested. 3 d or t Numerical value, upper limit or Time series of numerical values, upper limit. 4 s Optional. Default value (no code): min > expression or expression > max 'LOHI': min >= expression or expression >= max 'LOW': min >= expression or expression > max 'HIGH': min > expression or expression >= max","title":"Description"},{"location":"mesh/calculations/functions/outside/#example","text":"Example 1: @OUTSIDE(d,t,d) Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12) Values in @t('Temperature_hour_raw') 12 are evaluated to true (1). Other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and upper limit 12 are evaluated to false. Example 2: @OUTSIDE(d,t,d,s) Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'LOHI') Values in @t('Temperature_hour_raw') \u22640 and \u226512 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on both the lower limit 0 and upper limit 12 are evaluated to true. Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'LOW') Values in @t('Temperature_hour_raw') \u22640 and > 12 are evaluated to true (1), other values and NaN are evaluated to false (0). Here values on the lower limit 0 are evaluated to true and values on the upper limit 12 are evaluated to false. Temperature_hour_VV = @OUTSIDE(0, @t('Temperature_hour_raw'), 12, 'HIGH') Values in @t('Temperature_hour_raw') < 0 and \u2265 12 are evaluate to true (1), other values and NaN are evaluated to false (0). Here values on the lower limit 0 are evaluated to false and values on the upper limit 12 are evaluated to true.","title":"Example"},{"location":"mesh/calculations/functions/parameter/","text":"Parameter About the function This allows you to change parameter values used in a function to analyse scenarios differently than the default parameter definition. You can change these default parameter values from Nimbus (see screen example below). The changes are done in memory in your Nimbus session. When you close the Nimbus session or reset the calculation parameters, the values return to the default parameter definition. Syntax Parameter(sd) Parameter(st) Parameter(ss) Description # Type Description 1 s Parameter name. 2 d Default value. Double or integer. 2 t Default time series 2 s Default text string Note! References to attributes for objects do not work as default parameters. If the @Parameter calculation expression contains a time point or time macro, you need to convert the value as a text string in the calculator function. Example @TimeToString(@Time(@Parameter('Start time', '20150102'))) @TimeToString(@Time(@Parameter('Start time', 'YEAR+1m'))) In a time series template calculation expression, you can use the @Parameter function to define the parameters you want to expose for change in a Nimbus process. The use of the parameter function is generic and can be used in all functions and accessed from any Nimbus time series view.","title":"Parameter"},{"location":"mesh/calculations/functions/parameter/#parameter","text":"","title":"Parameter"},{"location":"mesh/calculations/functions/parameter/#about-the-function","text":"This allows you to change parameter values used in a function to analyse scenarios differently than the default parameter definition. You can change these default parameter values from Nimbus (see screen example below). The changes are done in memory in your Nimbus session. When you close the Nimbus session or reset the calculation parameters, the values return to the default parameter definition.","title":"About the function"},{"location":"mesh/calculations/functions/parameter/#syntax","text":"Parameter(sd) Parameter(st) Parameter(ss)","title":"Syntax"},{"location":"mesh/calculations/functions/parameter/#description","text":"# Type Description 1 s Parameter name. 2 d Default value. Double or integer. 2 t Default time series 2 s Default text string Note! References to attributes for objects do not work as default parameters. If the @Parameter calculation expression contains a time point or time macro, you need to convert the value as a text string in the calculator function.","title":"Description"},{"location":"mesh/calculations/functions/parameter/#example","text":"@TimeToString(@Time(@Parameter('Start time', '20150102'))) @TimeToString(@Time(@Parameter('Start time', 'YEAR+1m'))) In a time series template calculation expression, you can use the @Parameter function to define the parameters you want to expose for change in a Nimbus process. The use of the parameter function is generic and can be used in all functions and accessed from any Nimbus time series view.","title":"Example"},{"location":"mesh/calculations/functions/pdlog/","text":"PDLOG About this function The PDLOG function is used to give messages to SmG Event Log based on events occurring in SmG Calculator. Syntax PDLOG(d,s[,t]) PDLOG(d,s,t,d) # Type Description 1 d Type of message to Event Log: 1010 = Information, 1011 = Warning, 1012 = Error. 2 s Message to be written to Event Log. The string may contain several macros to give the general message a more specific content. The macros are: $start: Start of calculation period. $end: End of calculation period. $nvalues: Number of values being TRUE (value = 1) in time series. $first: Point of time for first value being TRUE in time series. $last: Point of time for last value being TRUE in time series. $path: Full object path. 3 t Time series in the log message. 4 d Number of values to be written to Event Log from the time series. Example 1 Difference =@MEAN(@T('To_MetSensor.Temperature_operative'))- @MEAN(@T('To_NeighbourMetStation.Temperature_used')) Deviation = @ABS(Difference) > 4 IF (@SUM(Deviation)) THEN @PDLOG(1011,'Temperature deviates, $nvalues, first time $first, last time $last',Deviation) ENDIF ## = Difference This image shows the result of the Difference time series in the calculation expression. The calculation of the temporary time series called Deviation gives the following result: This gives the following message in the Event Log: It is also possible to verify the result by using the built-in filtering function in Mesh: Example 2 Compares an inflow accumulated time series with a historical version of the same time series. If the accumulated end value change exeeds 10% absolute value a message is created in SmG Event Log: InflowSource = @t('.Inflow') TransformHour = @TRANSFORM(InflowSource,'HOUR','AVG') InflowAccumulated = @ACCUMULATE(0, '+0h'),TransformHour)* (3600/1000000) AccumulatedDeviation= (@MAX(InflowAccumulated)-@MAX(@t('.Inflow_accumulated_version')))/@MAX(InflowAccumulated) IF @ABS(AccumulatedDeviation) > 0.1 THEN @PDLOG(1010,'Inflow forecast deviates on time series,$path, period start $start, period end $end ', InflowSource) ENDIF ## = InflowAccumulated The following message in written in Event Log: 12:23:15 Inflow forecast deviates on time series, Model/MeshTEK/Cases.has_OptimisationCases/Morre_Long_Opt.has_cAreas/Norge.has_cHydroProduction/Vannkraft.has_cWaterCourses/M\u00f8rre.has_cProdriskAreas/M\u00f8rre.has_cProdriskModules/Storvatnet.has_cProdriskScenarios/1960.Inflow_accumulated/Inflow_accumulated, period start 10/25/2020 11:00:00 PM UTC, period end 2/27/2022 11:00:00 PM UTC","title":"PDLOG"},{"location":"mesh/calculations/functions/pdlog/#pdlog","text":"About this function The PDLOG function is used to give messages to SmG Event Log based on events occurring in SmG Calculator.","title":"PDLOG"},{"location":"mesh/calculations/functions/pdlog/#syntax","text":"PDLOG(d,s[,t]) PDLOG(d,s,t,d) # Type Description 1 d Type of message to Event Log: 1010 = Information, 1011 = Warning, 1012 = Error. 2 s Message to be written to Event Log. The string may contain several macros to give the general message a more specific content. The macros are: $start: Start of calculation period. $end: End of calculation period. $nvalues: Number of values being TRUE (value = 1) in time series. $first: Point of time for first value being TRUE in time series. $last: Point of time for last value being TRUE in time series. $path: Full object path. 3 t Time series in the log message. 4 d Number of values to be written to Event Log from the time series.","title":"Syntax"},{"location":"mesh/calculations/functions/pdlog/#example-1","text":"Difference =@MEAN(@T('To_MetSensor.Temperature_operative'))- @MEAN(@T('To_NeighbourMetStation.Temperature_used')) Deviation = @ABS(Difference) > 4 IF (@SUM(Deviation)) THEN @PDLOG(1011,'Temperature deviates, $nvalues, first time $first, last time $last',Deviation) ENDIF ## = Difference This image shows the result of the Difference time series in the calculation expression. The calculation of the temporary time series called Deviation gives the following result: This gives the following message in the Event Log: It is also possible to verify the result by using the built-in filtering function in Mesh:","title":"Example 1"},{"location":"mesh/calculations/functions/pdlog/#example-2","text":"Compares an inflow accumulated time series with a historical version of the same time series. If the accumulated end value change exeeds 10% absolute value a message is created in SmG Event Log: InflowSource = @t('.Inflow') TransformHour = @TRANSFORM(InflowSource,'HOUR','AVG') InflowAccumulated = @ACCUMULATE(0, '+0h'),TransformHour)* (3600/1000000) AccumulatedDeviation= (@MAX(InflowAccumulated)-@MAX(@t('.Inflow_accumulated_version')))/@MAX(InflowAccumulated) IF @ABS(AccumulatedDeviation) > 0.1 THEN @PDLOG(1010,'Inflow forecast deviates on time series,$path, period start $start, period end $end ', InflowSource) ENDIF ## = InflowAccumulated The following message in written in Event Log: 12:23:15 Inflow forecast deviates on time series, Model/MeshTEK/Cases.has_OptimisationCases/Morre_Long_Opt.has_cAreas/Norge.has_cHydroProduction/Vannkraft.has_cWaterCourses/M\u00f8rre.has_cProdriskAreas/M\u00f8rre.has_cProdriskModules/Storvatnet.has_cProdriskScenarios/1960.Inflow_accumulated/Inflow_accumulated, period start 10/25/2020 11:00:00 PM UTC, period end 2/27/2022 11:00:00 PM UTC","title":"Example 2"},{"location":"mesh/calculations/functions/percentile/","text":"PERCENTILE About the function Calculates percentiles based on one time series or an array of time series. Syntax1 PERCENTILE(t,d,d,d[,s,[,s]]) It takes one series as argument and history from year and to year as second and third argument. Description # Type Description Example 1 t Source time series to create percentile from. 2 d Start year 1990 3 d To year 2000 4 d The percentile to be calculated. Value between 1 and 100. 5 s Optional parameter. Method specification. Possible values are BY_SUM, SCALED_MEAN_BY_SUM or SCALED_BY_SUM. See description below. 6 s Period definition for the function. Note! Remember + before the first element, comma as separator and period length without +. '+3d' Three days after the end time. '-3d' Three days before the starting time. '+3d,5d' Three days after the starting time with a period length of five days. Method BY_SUM: Sums each single time series included in the function and finds the percentile index based on the established sums. As a consequence, this method always returns a result equal to one of the series defined in the input data with percentile index \u2264 the required percentile in the function. The percentile index is found by sorting the sum values from lowest to highest, giving the index (100/n-1) where n is number of input time series included in the function. Method SCALED_MEAN_BY_SUM: Calculates a starting point using the method BY_SUM to find the time series with the percentile index \u2264 the required percentile in the function. Calculates the mean value for each single time series included in the function (IndexTimeSeriesMean) Calculates the mean of all the time series included in the function (SumMean). The result equals to the time series found in the BY_SUM calculation multiplied by the factor SumMean/IndexTimeSeriesMean. Method SCALED_BY_SUM: Calculates the percentile index by using the method BY_SUM. Calculates the sum for the required percentile in the function based on the percentile index sums using standard percentile method for each time step, i.e. the percentile sum may be interpolated (Sum1). Calculates the required percentile value for each time step using standard percentile method. i.e. the values may be interpolated. Calculates the sum for the percentile time series (Sum2). The percentile time series is a scaled with the factor (Sum1/Sum2). Example 1 ## = @PERCENTILE (@t('Temperature_hour_operative'),2000,2010,100) If the number of observations (time series) do not correspond to the required percentile, the percentile is calculated by linearization between previous and following percentiles. In this example we ask for the 100% percentile. This takes the max value for each time step for the period from year 2000 to year 2010 (the year 2010 is not included in the calculation). If we want to calculate the 50% percentile based on 10 years of data, we will have the fixed percentile of P0, P10, P20, P30, P40, P50, P60, P70, P80, P90 and P100. The result takes the P50 values for each time step from year 2000 to year 2010. If we ask for the 75% percentile, the function interpolates between the values for P70 and P80. Syntax2 PERCENTILE(T,d[,s[,s]]) It takes an array of time series as an argument. Type Description Example T Array of time series to create percentile from. d The percentile to be calculated. Value between 1 and 100. s Optional parameter. Method specification. Possible values are BY_SUM, SCALED_MEAN_BY_SUM or SCALED_BY_SUM. See description below. s Period definition for the function. Note! Remember + before the first element, comma as separator and period length without +. '+3d' Three days after the end time. '-3d' Three days before the starting time. '+3d,5d' Three days after the starting time with a period length of five days. Example 2 ## = @PERCENTILE(@T('AreaTemperature'),100,'BY_SUM') The result will be equal to the time series with the highest sum for the requested period, i.e. Ensemble03 (P100). Example 3 ## = @PERCENTILE(@T('AreaTemperature'),100,'SCALED_MEAN_BY_SUM') The result will be equal to the time series with the highest sum for the requested period, i.e. Ensemble03 (P100). This is scaled by the factor SumMean/IndexTimeSeriesMean. Example 4 ## = @PERCENTILE(@T('AreaTemperature'),100,'SCALED_BY_SUM') The result will be equal to the max value for each time step scaled with a factor. The factor is found by taking the sum for the time series with percentile index P100, divided by the sum for the max value time series.","title":"PERCENTILE"},{"location":"mesh/calculations/functions/percentile/#percentile","text":"About the function Calculates percentiles based on one time series or an array of time series. Syntax1 PERCENTILE(t,d,d,d[,s,[,s]]) It takes one series as argument and history from year and to year as second and third argument.","title":"PERCENTILE"},{"location":"mesh/calculations/functions/percentile/#description","text":"# Type Description Example 1 t Source time series to create percentile from. 2 d Start year 1990 3 d To year 2000 4 d The percentile to be calculated. Value between 1 and 100. 5 s Optional parameter. Method specification. Possible values are BY_SUM, SCALED_MEAN_BY_SUM or SCALED_BY_SUM. See description below. 6 s Period definition for the function. Note! Remember + before the first element, comma as separator and period length without +. '+3d' Three days after the end time. '-3d' Three days before the starting time. '+3d,5d' Three days after the starting time with a period length of five days. Method BY_SUM: Sums each single time series included in the function and finds the percentile index based on the established sums. As a consequence, this method always returns a result equal to one of the series defined in the input data with percentile index \u2264 the required percentile in the function. The percentile index is found by sorting the sum values from lowest to highest, giving the index (100/n-1) where n is number of input time series included in the function. Method SCALED_MEAN_BY_SUM: Calculates a starting point using the method BY_SUM to find the time series with the percentile index \u2264 the required percentile in the function. Calculates the mean value for each single time series included in the function (IndexTimeSeriesMean) Calculates the mean of all the time series included in the function (SumMean). The result equals to the time series found in the BY_SUM calculation multiplied by the factor SumMean/IndexTimeSeriesMean. Method SCALED_BY_SUM: Calculates the percentile index by using the method BY_SUM. Calculates the sum for the required percentile in the function based on the percentile index sums using standard percentile method for each time step, i.e. the percentile sum may be interpolated (Sum1). Calculates the required percentile value for each time step using standard percentile method. i.e. the values may be interpolated. Calculates the sum for the percentile time series (Sum2). The percentile time series is a scaled with the factor (Sum1/Sum2). Example 1 ## = @PERCENTILE (@t('Temperature_hour_operative'),2000,2010,100) If the number of observations (time series) do not correspond to the required percentile, the percentile is calculated by linearization between previous and following percentiles. In this example we ask for the 100% percentile. This takes the max value for each time step for the period from year 2000 to year 2010 (the year 2010 is not included in the calculation). If we want to calculate the 50% percentile based on 10 years of data, we will have the fixed percentile of P0, P10, P20, P30, P40, P50, P60, P70, P80, P90 and P100. The result takes the P50 values for each time step from year 2000 to year 2010. If we ask for the 75% percentile, the function interpolates between the values for P70 and P80. Syntax2 PERCENTILE(T,d[,s[,s]]) It takes an array of time series as an argument. Type Description Example T Array of time series to create percentile from. d The percentile to be calculated. Value between 1 and 100. s Optional parameter. Method specification. Possible values are BY_SUM, SCALED_MEAN_BY_SUM or SCALED_BY_SUM. See description below. s Period definition for the function. Note! Remember + before the first element, comma as separator and period length without +. '+3d' Three days after the end time. '-3d' Three days before the starting time. '+3d,5d' Three days after the starting time with a period length of five days. Example 2 ## = @PERCENTILE(@T('AreaTemperature'),100,'BY_SUM') The result will be equal to the time series with the highest sum for the requested period, i.e. Ensemble03 (P100). Example 3 ## = @PERCENTILE(@T('AreaTemperature'),100,'SCALED_MEAN_BY_SUM') The result will be equal to the time series with the highest sum for the requested period, i.e. Ensemble03 (P100). This is scaled by the factor SumMean/IndexTimeSeriesMean. Example 4 ## = @PERCENTILE(@T('AreaTemperature'),100,'SCALED_BY_SUM') The result will be equal to the max value for each time step scaled with a factor. The factor is found by taking the sum for the time series with percentile index P100, divided by the sum for the max value time series.","title":"Description"},{"location":"mesh/calculations/functions/pop_ext_period/","text":"PopExtPeriod Using extended periods Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value; calculating accumulated series from the start of the year needs all values from this point, even if the requested period is September that year. In Mesh calculations, the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database. About the function This function removes the extended calculation period created by PushExtPeriod. The function must always be used after PushExtPeriod . Syntax PopExtPeriod(s) Description Type Description s Logic name of the period. It is the same as used in the corresponding PushExtPeriod. Note! The first argument name can be associated with a positional column time series name in a Time series report. Such names are 'A', 'B', 'C' --> 'AA', 'AB' etc. Thus, we recommend using a lower case letter in the first argument to PushExtPeriod and corresponding PopExtPeriod. Example The following two examples illustrate a period extension using both the Push and Pop functions. In both cases, this is handled implicitly in Mesh by the DELTA and PERCENTILE functions: @PushExtPeriod( \u2018X\u2019, \u2018-1h\u2019, \u20180h\u2019) Tmp1 = 10 * @t( \u2018TimeSeries\u2019 ) @PopExtPeriod(\u2018X\u2019) ## = @DELTA(Tmp1) Uses relative period extension to get an extra hour at start so that DELTA gets what it needs to calculate the first value in the requested period. @PushExtPeriod('P','20000101000000000','20100101000000000') Corrected = @CorrectInterpolate(@ValidateAbsLimit( @RESET_STATUS (@t('Temperature')),-25,25), 10, 'TRUE') @PopExtPeriod('P') ## = @PERCENTILE(Corrected, 2000,2010,75) Uses fixed period extension in line with the arguments to the PERCENTILE function on the last line.","title":"PopExtPeriod"},{"location":"mesh/calculations/functions/pop_ext_period/#popextperiod","text":"","title":"PopExtPeriod"},{"location":"mesh/calculations/functions/pop_ext_period/#using-extended-periods","text":"Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value; calculating accumulated series from the start of the year needs all values from this point, even if the requested period is September that year. In Mesh calculations, the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database.","title":"Using extended periods"},{"location":"mesh/calculations/functions/pop_ext_period/#about-the-function","text":"This function removes the extended calculation period created by PushExtPeriod. The function must always be used after PushExtPeriod .","title":"About the function"},{"location":"mesh/calculations/functions/pop_ext_period/#syntax","text":"PopExtPeriod(s)","title":"Syntax"},{"location":"mesh/calculations/functions/pop_ext_period/#description","text":"Type Description s Logic name of the period. It is the same as used in the corresponding PushExtPeriod. Note! The first argument name can be associated with a positional column time series name in a Time series report. Such names are 'A', 'B', 'C' --> 'AA', 'AB' etc. Thus, we recommend using a lower case letter in the first argument to PushExtPeriod and corresponding PopExtPeriod.","title":"Description"},{"location":"mesh/calculations/functions/pop_ext_period/#example","text":"The following two examples illustrate a period extension using both the Push and Pop functions. In both cases, this is handled implicitly in Mesh by the DELTA and PERCENTILE functions: @PushExtPeriod( \u2018X\u2019, \u2018-1h\u2019, \u20180h\u2019) Tmp1 = 10 * @t( \u2018TimeSeries\u2019 ) @PopExtPeriod(\u2018X\u2019) ## = @DELTA(Tmp1) Uses relative period extension to get an extra hour at start so that DELTA gets what it needs to calculate the first value in the requested period. @PushExtPeriod('P','20000101000000000','20100101000000000') Corrected = @CorrectInterpolate(@ValidateAbsLimit( @RESET_STATUS (@t('Temperature')),-25,25), 10, 'TRUE') @PopExtPeriod('P') ## = @PERCENTILE(Corrected, 2000,2010,75) Uses fixed period extension in line with the arguments to the PERCENTILE function on the last line.","title":"Example"},{"location":"mesh/calculations/functions/positive/","text":"POSITIVE About the function Picks the positive values from a time series. Zero is considered to be a positive number. Syntax POSITIVE(t[,d[,s]]) # Type Description 1 t Input time series. Picks the positive values from the time series. 0 (zero) is by default considered as a positive number. 2 d Optional. Numerical value. Defines if 0 (zero) is considered as a positive or negative number. If 0 is set in argument 2, 0 is considered as a negative number. Use of other numbers in argument 2, or if argument 2 is omitted, it means 0 (zero) is considered as a positive number. 3 s Optional. VALUE \u2013 Default behavior. Gives the result of the function as a normal time series. If argument 3 is omitted, this is the default behavior. BOOL - Converts the result into a logical time series (values 1 and 0). BOOL_COMPRESS \u2013 Converts the result into a logical time series (values 1 and 0) with compressing of equal numbers. The resolution is a breakpoint time series. Example @POSITIVE(t) From the table, we see that only positive numbers are returned. Negative numbers and NaN return empty rows.","title":"Positive"},{"location":"mesh/calculations/functions/positive/#positive","text":"","title":"POSITIVE"},{"location":"mesh/calculations/functions/positive/#about-the-function","text":"Picks the positive values from a time series. Zero is considered to be a positive number.","title":"About the function"},{"location":"mesh/calculations/functions/positive/#syntax","text":"POSITIVE(t[,d[,s]]) # Type Description 1 t Input time series. Picks the positive values from the time series. 0 (zero) is by default considered as a positive number. 2 d Optional. Numerical value. Defines if 0 (zero) is considered as a positive or negative number. If 0 is set in argument 2, 0 is considered as a negative number. Use of other numbers in argument 2, or if argument 2 is omitted, it means 0 (zero) is considered as a positive number. 3 s Optional. VALUE \u2013 Default behavior. Gives the result of the function as a normal time series. If argument 3 is omitted, this is the default behavior. BOOL - Converts the result into a logical time series (values 1 and 0). BOOL_COMPRESS \u2013 Converts the result into a logical time series (values 1 and 0) with compressing of equal numbers. The resolution is a breakpoint time series.","title":"Syntax"},{"location":"mesh/calculations/functions/positive/#example","text":"@POSITIVE(t) From the table, we see that only positive numbers are returned. Negative numbers and NaN return empty rows.","title":"Example"},{"location":"mesh/calculations/functions/power/","text":"POWER About the function Returns the result of a time series or number raised to a power. The function uses the equation y=xn. x and n can be a time series or a number. The result series has the same resolution as the input time series. Syntax POWER(d|t,d|t) Description # Type Description 1 d Numerical value used for the number x in the equation. 1 t Time series used for the number x in the equation. 2 d Numerical value used for the exponential factor n in the equation. 2 t Time series used for the exponential factor n in the equation. Example Example 1: @POWER(t,d) Waterlevel_hour_operative = @POWER(@t('Waterlevel_hour_raw'),2) Example 2: @POWER(d,t) Waterlevel_hour_operative = @POWER(2,@t('Waterlevel_hour_raw')) Example 3: @POWER(t,t) Waterlevel_hour_operative = @POWER(@t('Waterlevel_hour_raw'),@t('Waterlevel_hour_raw'),) Example 4: @POWER(d,d) RS4 = @POWER(4,2) Example 4 returns the number 16 (4 to the power of 2).","title":"POWER"},{"location":"mesh/calculations/functions/power/#power","text":"","title":"POWER"},{"location":"mesh/calculations/functions/power/#about-the-function","text":"Returns the result of a time series or number raised to a power. The function uses the equation y=xn. x and n can be a time series or a number. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/power/#syntax","text":"POWER(d|t,d|t)","title":"Syntax"},{"location":"mesh/calculations/functions/power/#description","text":"# Type Description 1 d Numerical value used for the number x in the equation. 1 t Time series used for the number x in the equation. 2 d Numerical value used for the exponential factor n in the equation. 2 t Time series used for the exponential factor n in the equation.","title":"Description"},{"location":"mesh/calculations/functions/power/#example","text":"Example 1: @POWER(t,d) Waterlevel_hour_operative = @POWER(@t('Waterlevel_hour_raw'),2) Example 2: @POWER(d,t) Waterlevel_hour_operative = @POWER(2,@t('Waterlevel_hour_raw')) Example 3: @POWER(t,t) Waterlevel_hour_operative = @POWER(@t('Waterlevel_hour_raw'),@t('Waterlevel_hour_raw'),) Example 4: @POWER(d,d) RS4 = @POWER(4,2) Example 4 returns the number 16 (4 to the power of 2).","title":"Example"},{"location":"mesh/calculations/functions/profile/","text":"PROFILE This topic describes a PROFILE variant ( R12 ) for transforming from one time resolution to another. To get an overview of all the variants of the function, see: Which functions can be used when? R12 About the function PROFILE lets you create values on a series in periods where values do not exist based on the length of the input time series. The length of the profile series must be equal to a calendar unit, for example year. Syntax PROFILE(t) Description # Type Definition 1 t Time series. The function analyzes input data time series and checks whether this is defined in the current profile period, like a day or a week. If yes, these values are perceived as a profile and placed in the requested period and repeated if necessary. The function returns a time series with the same resolution as the input series with values created by repetition of the values found on the input series. Example @PROFILE(t) Result time series = @PROFILE(@t('TSPH')) The figure shows the profile series defined with data for a 24-hour period at September 21st 2014. The result of @PROFILE(@t('TSPH')) for any other requested day will give the same values. Note! The values in the summer time are shifted one hour, related to the defined profile. The PROFILE function has no argument for defining which calendar the profile should show. It implicitly uses the calendar defined for the database.","title":"PROFILE"},{"location":"mesh/calculations/functions/profile/#profile","text":"This topic describes a PROFILE variant ( R12 ) for transforming from one time resolution to another. To get an overview of all the variants of the function, see: Which functions can be used when?","title":"PROFILE"},{"location":"mesh/calculations/functions/profile/#r12","text":"","title":"R12"},{"location":"mesh/calculations/functions/profile/#about-the-function","text":"PROFILE lets you create values on a series in periods where values do not exist based on the length of the input time series. The length of the profile series must be equal to a calendar unit, for example year.","title":"About the function"},{"location":"mesh/calculations/functions/profile/#syntax","text":"PROFILE(t)","title":"Syntax"},{"location":"mesh/calculations/functions/profile/#description","text":"# Type Definition 1 t Time series. The function analyzes input data time series and checks whether this is defined in the current profile period, like a day or a week. If yes, these values are perceived as a profile and placed in the requested period and repeated if necessary. The function returns a time series with the same resolution as the input series with values created by repetition of the values found on the input series.","title":"Description"},{"location":"mesh/calculations/functions/profile/#example","text":"@PROFILE(t) Result time series = @PROFILE(@t('TSPH')) The figure shows the profile series defined with data for a 24-hour period at September 21st 2014. The result of @PROFILE(@t('TSPH')) for any other requested day will give the same values. Note! The values in the summer time are shifted one hour, related to the defined profile. The PROFILE function has no argument for defining which calendar the profile should show. It implicitly uses the calendar defined for the database.","title":"Example"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/","text":"PROFILE with explicit frequency This topic describes a PROFILE variant ( R13 ) for transforming from one time resolution to another. To get an overview of all the variants of the function, see: Which functions can be used when? R13 About the function This is a function that calculates a time series by doing repeating an input series segment to cover requested time period. Values found on input series are moved into requested calculation period on a calendar based manner, i.e. values from a Tuesday in a weekly repetition are found on Tuesdays in requested time frame. The input series must have finer resolution than the repetition frequency indicates. This function is closely related to R12 , which only takes one argument; the input time series. In this case the function derives a repetition frequency from physical value period found on source series. Syntax PROFILE(t,s) D escription # Type Definition 1 t Time series. 2 s Repeat frequency. Result time series = @PROFILE(@t('TSPH'),\u2019DAY\u2019) The input time series for this function contains the values used as basis for repeat to create the result series. The result will have the same resolution as this series. The repetition frequency is an argument, a time unit symbol like 'HOUR', 'DAY', 'WEEK' and 'YEAR'. It defines how often values from input series are repeated. The values are picked from a trimmed start point relative to physical start of input series. If frequency indicates a span that is narrower than time span on input series, then values from first segment are repeated into requested time span. Example Some examples are cited below: Result1 = @PROFILE(@t(\u2018TsInputBrP\u2019),'WEEK') Result2 = @PROFILE(@t(\u2018TsInput2\u2019),'DAY') Result3 = @PROFILE(@t(\u2018TsInput3\u2019),'YEAR') In example 1 the input series could be a breakpoint series with values located in first week of 2007 (which happens to start at 1.of January). A calculation request for week 7 to week 10 in 2007 will repeat source values three times. In example 2 the input series could be an hour resolution series that have values located in first week of 2007. A calculation request for period 20-02-2007 12:00 to 23-02-2007 00:00 will get values found on source series for 01-01-2007, and repeat these 2.5 times; and starts with last half of this day. In example 3 the input series could be a day resolution series that have values that cover the year 2007. A calculation request for period 19-02-2004 to 22-02-2004 will get three values from source series starting with value from 19-02-2007. This generates a pseudorandom number.","title":"PROFILE with explicit frequency"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/#profile-with-explicit-frequency","text":"This topic describes a PROFILE variant ( R13 ) for transforming from one time resolution to another. To get an overview of all the variants of the function, see: Which functions can be used when?","title":"PROFILE with explicit frequency"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/#r13","text":"","title":"R13"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/#about-the-function","text":"This is a function that calculates a time series by doing repeating an input series segment to cover requested time period. Values found on input series are moved into requested calculation period on a calendar based manner, i.e. values from a Tuesday in a weekly repetition are found on Tuesdays in requested time frame. The input series must have finer resolution than the repetition frequency indicates. This function is closely related to R12 , which only takes one argument; the input time series. In this case the function derives a repetition frequency from physical value period found on source series.","title":"About the function"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/#syntax","text":"PROFILE(t,s) D escription # Type Definition 1 t Time series. 2 s Repeat frequency. Result time series = @PROFILE(@t('TSPH'),\u2019DAY\u2019) The input time series for this function contains the values used as basis for repeat to create the result series. The result will have the same resolution as this series. The repetition frequency is an argument, a time unit symbol like 'HOUR', 'DAY', 'WEEK' and 'YEAR'. It defines how often values from input series are repeated. The values are picked from a trimmed start point relative to physical start of input series. If frequency indicates a span that is narrower than time span on input series, then values from first segment are repeated into requested time span.","title":"Syntax"},{"location":"mesh/calculations/functions/profile_with_explicit_frequency/#example","text":"Some examples are cited below: Result1 = @PROFILE(@t(\u2018TsInputBrP\u2019),'WEEK') Result2 = @PROFILE(@t(\u2018TsInput2\u2019),'DAY') Result3 = @PROFILE(@t(\u2018TsInput3\u2019),'YEAR') In example 1 the input series could be a breakpoint series with values located in first week of 2007 (which happens to start at 1.of January). A calculation request for week 7 to week 10 in 2007 will repeat source values three times. In example 2 the input series could be an hour resolution series that have values located in first week of 2007. A calculation request for period 20-02-2007 12:00 to 23-02-2007 00:00 will get values found on source series for 01-01-2007, and repeat these 2.5 times; and starts with last half of this day. In example 3 the input series could be a day resolution series that have values that cover the year 2007. A calculation request for period 19-02-2004 to 22-02-2004 will get three values from source series starting with value from 19-02-2007. This generates a pseudorandom number.","title":"Example"},{"location":"mesh/calculations/functions/push_ext_period/","text":"PushExtPeriod Using extended periods Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value; calculating accumulated series from the start of the year needs all values from this point, even if the requested period is September that year. In Mesh calculations, the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database. About the function The current period may effect calculations and the purpose of the function is to control this in order to achieve the correct result. PushExtPeriod must always be accompanied by PopExtPeriod after completing the part of the calculation which requires a specific period. The function returns the number of seconds the period is extended by. The return value is normally not used, as the main purpose of the function is the side effect: Change the actual calculation period directly. Need for extended periods in calculations are handled implicitly when using Mesh as a foundation. Syntax PushExtPeriod(s,s,s) PushExtPeriod(s,d,d) Description # Type Description 1 s Logic name of the period. 2 s or d Start time (from and including). May be a time macro, including a relative specification, e.g. -1d which extends the period with one day before the calculation period, or a time point as a number. 3 s or d End time (to and including). May be a time macro, including a relative specification, e.g. +1d which extends the period with one day after the calculation period, or a time point as a number. The function establishes a time period based on start time and end time. The timestamp is defined as symbol/text or number produced by a Time function. Argument 2 and 3 must be of the same type and not a mix of a time macro and a number. Note! For the symbol version, the rules of the TIME-function apply with one exception: The reference for the time macro is the current calculation period and not the current time as in Time. If the start time is invalid the report start time is used. The same logic applies for the end time. The new period is the active calculation period and is used until calling the function PopExtPeriod. The system then continues using the calculation period that was active before calling PushExtPeriod. If the given period is invalid, the current calculation period is used. This is done because a PopExtPeriod call is expected later in the expression. Note! The first argument name can be associated with a positional column time series name in a Time series report. Such names are 'A', 'B', 'C' --> 'AA', 'AB' etc. Thus, we recommend using a lower case letter in the first argument to PushExtPeriod and corresponding PopExtPeriod. Example The following two examples illustrate a period extension using both the Push and Pop functions. In both cases, this is handled implicitly in Mesh by the DELTA and PERCENTILE functions: @PushExtPeriod( \u2018X\u2019, \u2018-1h\u2019, \u20180h\u2019) Tmp1 = 10 * @t( \u2018TimeSeries\u2019 ) @PopExtPeriod(\u2018X\u2019) ## = @DELTA(Tmp1) Uses relative period extension to get an extra hour at start so that DELTA gets what it needs to calculate the first value in the requested period. @PushExtPeriod('P','20000101000000000','20100101000000000') Corrected = @CorrectInterpolate(@ValidateAbsLimit( @RESET_STATUS (@t('Temperature')),-25,25), 10, 'TRUE') @PopExtPeriod('P') ## = @PERCENTILE(Corrected, 2000,2010,75) Uses fixed period extension in line with the arguments to the PERCENTILE function on the last line.","title":"PushExtPeriod"},{"location":"mesh/calculations/functions/push_ext_period/#pushextperiod","text":"","title":"PushExtPeriod"},{"location":"mesh/calculations/functions/push_ext_period/#using-extended-periods","text":"Some calculations need an extended period to produce correct and consistent results. For example, calculating a delta series needs the previous value; calculating accumulated series from the start of the year needs all values from this point, even if the requested period is September that year. In Mesh calculations, the functions that inherently need extended periods, are handled implicitly when creating the calculation expressions. Still, there may be situations where you explicitly want to define extended periods. To do this you can use the PushExtPeriod and PopExtPeriod functions to ensure correct behavior. The ground rules for applying the Push/Pop mechanism are: The expression uses data outside the requested period to produce correct results. The time series that need to be extended has no direct database connection, i.e. it cannot be extended by reading more data from the database.","title":"Using extended periods"},{"location":"mesh/calculations/functions/push_ext_period/#about-the-function","text":"The current period may effect calculations and the purpose of the function is to control this in order to achieve the correct result. PushExtPeriod must always be accompanied by PopExtPeriod after completing the part of the calculation which requires a specific period. The function returns the number of seconds the period is extended by. The return value is normally not used, as the main purpose of the function is the side effect: Change the actual calculation period directly. Need for extended periods in calculations are handled implicitly when using Mesh as a foundation.","title":"About the function"},{"location":"mesh/calculations/functions/push_ext_period/#syntax","text":"PushExtPeriod(s,s,s) PushExtPeriod(s,d,d)","title":"Syntax"},{"location":"mesh/calculations/functions/push_ext_period/#description","text":"# Type Description 1 s Logic name of the period. 2 s or d Start time (from and including). May be a time macro, including a relative specification, e.g. -1d which extends the period with one day before the calculation period, or a time point as a number. 3 s or d End time (to and including). May be a time macro, including a relative specification, e.g. +1d which extends the period with one day after the calculation period, or a time point as a number. The function establishes a time period based on start time and end time. The timestamp is defined as symbol/text or number produced by a Time function. Argument 2 and 3 must be of the same type and not a mix of a time macro and a number. Note! For the symbol version, the rules of the TIME-function apply with one exception: The reference for the time macro is the current calculation period and not the current time as in Time. If the start time is invalid the report start time is used. The same logic applies for the end time. The new period is the active calculation period and is used until calling the function PopExtPeriod. The system then continues using the calculation period that was active before calling PushExtPeriod. If the given period is invalid, the current calculation period is used. This is done because a PopExtPeriod call is expected later in the expression. Note! The first argument name can be associated with a positional column time series name in a Time series report. Such names are 'A', 'B', 'C' --> 'AA', 'AB' etc. Thus, we recommend using a lower case letter in the first argument to PushExtPeriod and corresponding PopExtPeriod.","title":"Description"},{"location":"mesh/calculations/functions/push_ext_period/#example","text":"The following two examples illustrate a period extension using both the Push and Pop functions. In both cases, this is handled implicitly in Mesh by the DELTA and PERCENTILE functions: @PushExtPeriod( \u2018X\u2019, \u2018-1h\u2019, \u20180h\u2019) Tmp1 = 10 * @t( \u2018TimeSeries\u2019 ) @PopExtPeriod(\u2018X\u2019) ## = @DELTA(Tmp1) Uses relative period extension to get an extra hour at start so that DELTA gets what it needs to calculate the first value in the requested period. @PushExtPeriod('P','20000101000000000','20100101000000000') Corrected = @CorrectInterpolate(@ValidateAbsLimit( @RESET_STATUS (@t('Temperature')),-25,25), 10, 'TRUE') @PopExtPeriod('P') ## = @PERCENTILE(Corrected, 2000,2010,75) Uses fixed period extension in line with the arguments to the PERCENTILE function on the last line.","title":"Example"},{"location":"mesh/calculations/functions/rating_curve/","text":"RatingCurve About the function The function is used to lookup values from a complex rating curve description to convert water level measurements in rivers to discharge unit. The function parameters a, b and c are determined to best fit the measured discharge for different elevations in the river and could be divided into several elevation segments. Because of changes in the river in time due to erosion and sedimentation, the validity of a rating curve description could be periodized. Q = ai (h+bi)^ci hi \u2264 h i+1 hi+1 \u2264 h n+2 The description gives factors a, b and for different value segments i for elevation h. Each definition may be valid for a given time interval. S yntax RatingCurve(t) Description Type Description t Source time series for water level measurements in rivers. It is used as lookup series on the rating curve definition found on the same object.","title":"RatingCurve"},{"location":"mesh/calculations/functions/rating_curve/#ratingcurve","text":"About the function The function is used to lookup values from a complex rating curve description to convert water level measurements in rivers to discharge unit. The function parameters a, b and c are determined to best fit the measured discharge for different elevations in the river and could be divided into several elevation segments. Because of changes in the river in time due to erosion and sedimentation, the validity of a rating curve description could be periodized. Q = ai (h+bi)^ci hi \u2264 h i+1 hi+1 \u2264 h n+2 The description gives factors a, b and for different value segments i for elevation h. Each definition may be valid for a given time interval. S yntax RatingCurve(t)","title":"RatingCurve"},{"location":"mesh/calculations/functions/rating_curve/#description","text":"Type Description t Source time series for water level measurements in rivers. It is used as lookup series on the rating curve definition found on the same object.","title":"Description"},{"location":"mesh/calculations/functions/reference_lookup/","text":"Reference lookup The lookup functions have their name from the target type. The variant with a single argument produces a warning message in Nimbus (Mesh log), if the lookup fails and return system defined default value, like empty series (defined as breakpoint series with a single NaN point at start of requested time period). The variant with two arguments does not complain by sending messages to the log if lookup fails. If lookup fails, the default value found in the second argument is applied. The default value related to arrays (i.e. using @T(), @D() or @S()) must be minimum one value. Note! The default value is only used if Mesh cannot find the attribute, so an empty value on the found attribute does not imply use of a default value. Function Description @t(s) Looks up a time series from search/navigate string given as argument. If the target is not found, a log message a log message informs that the system failed to resolve the target. @t(s,t) Basically the same as @t(s), but in case the lookup fails it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument most likely is another @t function call. @T(s) Looks up a time series array from search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @T(s,T) Basically, this is the same as @T(s). However, in case the lookup fails, it returns the default time series array given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be another @T function call or an expression like {@TS(\u2018VARINT\u2019)} given an array of one breakpoint series with a NaN value. @d(s) Looks up a numeric value from search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @d(s,d) Basically, this is the same as @d(s). However, in case the lookup fails, it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be a constant values or another @d function call. @D(s) Looks up a numeric array from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @D(s,D) Basically, this is the same as @D(s). However, in case the lookup fails, it returns the default numeric array given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be an explicit array (like {1,2,3}), or another @D function call. The explicit version must have at least one member in the array. @s(s) Looks up a string value from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve target. @s(s,s) Basically, this is the same as @s(s). However, in case the lookup fails, it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be a constant values or another @s function call. @(S,s) Looks up a string array from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @S(s,S) Basically, this is the same as @S(s). However, in case the lookup fails, it returns the default array of strings given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be an explicit value (like {\u2018None\u2019}) or another @S function call.","title":"Reference Lookup"},{"location":"mesh/calculations/functions/reference_lookup/#reference-lookup","text":"The lookup functions have their name from the target type. The variant with a single argument produces a warning message in Nimbus (Mesh log), if the lookup fails and return system defined default value, like empty series (defined as breakpoint series with a single NaN point at start of requested time period). The variant with two arguments does not complain by sending messages to the log if lookup fails. If lookup fails, the default value found in the second argument is applied. The default value related to arrays (i.e. using @T(), @D() or @S()) must be minimum one value. Note! The default value is only used if Mesh cannot find the attribute, so an empty value on the found attribute does not imply use of a default value. Function Description @t(s) Looks up a time series from search/navigate string given as argument. If the target is not found, a log message a log message informs that the system failed to resolve the target. @t(s,t) Basically the same as @t(s), but in case the lookup fails it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument most likely is another @t function call. @T(s) Looks up a time series array from search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @T(s,T) Basically, this is the same as @T(s). However, in case the lookup fails, it returns the default time series array given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be another @T function call or an expression like {@TS(\u2018VARINT\u2019)} given an array of one breakpoint series with a NaN value. @d(s) Looks up a numeric value from search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @d(s,d) Basically, this is the same as @d(s). However, in case the lookup fails, it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be a constant values or another @d function call. @D(s) Looks up a numeric array from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @D(s,D) Basically, this is the same as @D(s). However, in case the lookup fails, it returns the default numeric array given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be an explicit array (like {1,2,3}), or another @D function call. The explicit version must have at least one member in the array. @s(s) Looks up a string value from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve target. @s(s,s) Basically, this is the same as @s(s). However, in case the lookup fails, it returns the default time series given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be a constant values or another @s function call. @(S,s) Looks up a string array from the search/navigate string given as argument. If the target is not found, a log message informs that the system failed to resolve the target. @S(s,S) Basically, this is the same as @S(s). However, in case the lookup fails, it returns the default array of strings given as the second argument. The function remains silent even if the returned value comes from the default argument. Note! The default argument may be an explicit value (like {\u2018None\u2019}) or another @S function call.","title":"Reference lookup"},{"location":"mesh/calculations/functions/reset_status/","text":"RESET_STATUS About the function This function is used to make changes on the status of time series . The result series has the same resolution as the input time series. Syntax RESET_STATUS(t[,d|s]) Description # Type Description 1 t Time series. Zeroes out all status information for the time series. 2 d or s Optional. Zeroes out all status specified in argument 2. Symbols can be combined by adding Status mask (case sensitive): ARGUMENT Definition novalue No value notok Not ok suspect Value with status supect manual Includes both manually changed and estimated values MANUAL Only manually changed estimated Only manually estimated validated Validated corrected Corrected locked Locked accepted Accepted default Default Validation methods: V01 means validation method 1. You can see this code if you turn on value information in Nimbus. Available validation methods are as follows: ARGUMENT METHOD V01 Abs limit V02 Delta limit V03 Delta limit extreme V04 Repeated value Correction methods: C01 means correction method 1. You can see this code if you turn on value information in Nimbus. Available correction methods are as follows: ARGUMENT METHOD C01 Constant value C02 Copy value C03 Interpolate C04 Extrapolate C05 Average value Example Example 1: @RESET_STATUS(t) ResultTs = @RESET_STATUS(@t(\u2018Ts1\u2019)) Zeroes out all status information for the time series. Example 2: @RESET_STATUS(t,s) Temperature_hour_VEE = @RESET_STATUS(@t('Temperature_hour_VV'),'notok') In the following example, the first column is the series original status. In the second column the status sign/exclamation mark, ! (Not ok), is removed.","title":"RESET_STATUS"},{"location":"mesh/calculations/functions/reset_status/#reset_status","text":"","title":"RESET_STATUS"},{"location":"mesh/calculations/functions/reset_status/#about-the-function","text":"This function is used to make changes on the status of time series . The result series has the same resolution as the input time series. Syntax RESET_STATUS(t[,d|s])","title":"About the function"},{"location":"mesh/calculations/functions/reset_status/#description","text":"# Type Description 1 t Time series. Zeroes out all status information for the time series. 2 d or s Optional. Zeroes out all status specified in argument 2. Symbols can be combined by adding Status mask (case sensitive): ARGUMENT Definition novalue No value notok Not ok suspect Value with status supect manual Includes both manually changed and estimated values MANUAL Only manually changed estimated Only manually estimated validated Validated corrected Corrected locked Locked accepted Accepted default Default Validation methods: V01 means validation method 1. You can see this code if you turn on value information in Nimbus. Available validation methods are as follows: ARGUMENT METHOD V01 Abs limit V02 Delta limit V03 Delta limit extreme V04 Repeated value Correction methods: C01 means correction method 1. You can see this code if you turn on value information in Nimbus. Available correction methods are as follows: ARGUMENT METHOD C01 Constant value C02 Copy value C03 Interpolate C04 Extrapolate C05 Average value","title":"Description"},{"location":"mesh/calculations/functions/reset_status/#example","text":"Example 1: @RESET_STATUS(t) ResultTs = @RESET_STATUS(@t(\u2018Ts1\u2019)) Zeroes out all status information for the time series. Example 2: @RESET_STATUS(t,s) Temperature_hour_VEE = @RESET_STATUS(@t('Temperature_hour_VV'),'notok') In the following example, the first column is the series original status. In the second column the status sign/exclamation mark, ! (Not ok), is removed.","title":"Example"},{"location":"mesh/calculations/functions/resolution/","text":"Resolution About the function Syntax IsResolution (t) Description Type Description t Example","title":"Resolution"},{"location":"mesh/calculations/functions/resolution/#resolution","text":"","title":"Resolution"},{"location":"mesh/calculations/functions/resolution/#about-the-function","text":"","title":"About the function"},{"location":"mesh/calculations/functions/resolution/#syntax","text":"IsResolution (t)","title":"Syntax"},{"location":"mesh/calculations/functions/resolution/#description","text":"Type Description t","title":"Description"},{"location":"mesh/calculations/functions/resolution/#example","text":"","title":"Example"},{"location":"mesh/calculations/functions/restriction/","text":"Restriction About the function This function generates a time series from the Restriction events associated with this element, filtered on Category and Status. The value at a given time will be chosen from the relevant event(s), using a strategy decided by the user. When there are no events, the value will be a default value provided by the user. For more information about generating time series from restrictions/revisions, see the help for the Smart Power Apps module Availability Planner .** Note! ** The generated time series will per default be a breakpoint time series, unless an explicit transformation to a fixed interval is specified in the time series calculation. Syntax Restriction(s, s, [d/t], s, (s)) Description # Type Description 1 s Category. Only events with this category will be used. Possible categories in the table at the bottom of this page. 2 s Status filter. Names of one or more statuses, or the keyword 'All'. When using more than one status, separate the names using ' 3 d/t Default value. If there are no active events, this value will be used. 4 s Merge Function. This parameter describes which value to be used if there are more than one active event with the same status at a given time. Available Merge Functions are described in the table below. 5 s (Optional) Search string to an object in ' '. Must return exactly one object. The time series will be generated based on the Restriction events related to this object. Merge functions Function Description Minimum Selects the smallest numerical value from the active events. Maximum Selects the largest numerical value from the active events. BooleanAnd If all the active events have value 1, this returns 1. Otherwise, it returns 0. BooleanOr If one or more of the active events has value 1, this returns 1. Otherwise, it returns 0. Sum Sums the values of all the active events. Average Finds the average value of all the active events. Examples ``@Restriction('DischargeMin[m3/s]', 'Licensed', @d('.DischargeDefault'),'Maximum') Finds events with Category = 'DischargeMin[m3/s]', and Status = 'Licensed'. Uses these events to generate a time series. If there are more than one event at a time with the same status, the maximum value will be used. If there are no events, the value found in the attribute '.DischargeDefault' will be used. @Restriction('DischargeMin[m3/s]', 'All', @t('.SomeTimeseriesAttribute'),'Average') Will generate a time series based on all events with Category = 'DischargeMin[m3/s]', regardless of statuses. If there are no events at a given time, the value from the '.SomeTimeseriesAttribute' will be used. If there are more than one event at a given time, the average value from those events will be used. @MIX(@Restriction('DischargeMin[m3/s]', 'SelfImposed',NaN, 'Maximum'),@Restriction('DischargeMin[m3/s]', 'Licensed', @d('.DischargeDefault'),'Maximum', 'to_HydroPlant') Generates a time series which uses values from events with status SelfImposed if such exist, otherwise it uses events from the licensed status. If there are no events, the value found in the attribute '.DischargeDefault' is used. Note! The events are found on the object using the link relations to_HydroPlant. Possible statuses This is a list of the possible statuses that can be used: Licensed (used as the main restriction) SelfImposed (used as the exception of the main restriction) Possible categories This is a list of the possible categories: DischargeMin[m3/s] DischargeMax[m3/s] DischargeMaxAverage[m3/s] DischargeMinAverage[m3/s] DischargeMaxVariationUp[m3/s] DischargeMaxVariationDown[m3/s] DischargeBlockFlow[m3/s] ProductionMin[MW] ProductionMax[MW] ProductionMaxRegulations ProductionRampingUp[MW] ProductionRampingDown[MW] ProductionBlockGeneration[MW] RampingFlag ReservoirLevelMin[m] ReservoirLevelMax[m] ReservoirLevelRampingUp[m] ReservoirLevelRampingDown[m] PumpHeightDownstreamReservoir[m] PumpHeightUpstreamReservoir[m] PressureHeightRestriction[m] Priority ReservoirTacticalLevelMin[m] ReservoirTacticalLevelMax[m]","title":"Restriction"},{"location":"mesh/calculations/functions/restriction/#restriction","text":"","title":"Restriction"},{"location":"mesh/calculations/functions/restriction/#about-the-function","text":"This function generates a time series from the Restriction events associated with this element, filtered on Category and Status. The value at a given time will be chosen from the relevant event(s), using a strategy decided by the user. When there are no events, the value will be a default value provided by the user. For more information about generating time series from restrictions/revisions, see the help for the Smart Power Apps module Availability Planner .** Note! ** The generated time series will per default be a breakpoint time series, unless an explicit transformation to a fixed interval is specified in the time series calculation.","title":"About the function"},{"location":"mesh/calculations/functions/restriction/#syntax","text":"Restriction(s, s, [d/t], s, (s))","title":"Syntax"},{"location":"mesh/calculations/functions/restriction/#description","text":"# Type Description 1 s Category. Only events with this category will be used. Possible categories in the table at the bottom of this page. 2 s Status filter. Names of one or more statuses, or the keyword 'All'. When using more than one status, separate the names using ' 3 d/t Default value. If there are no active events, this value will be used. 4 s Merge Function. This parameter describes which value to be used if there are more than one active event with the same status at a given time. Available Merge Functions are described in the table below. 5 s (Optional) Search string to an object in ' '. Must return exactly one object. The time series will be generated based on the Restriction events related to this object. Merge functions Function Description Minimum Selects the smallest numerical value from the active events. Maximum Selects the largest numerical value from the active events. BooleanAnd If all the active events have value 1, this returns 1. Otherwise, it returns 0. BooleanOr If one or more of the active events has value 1, this returns 1. Otherwise, it returns 0. Sum Sums the values of all the active events. Average Finds the average value of all the active events.","title":"Description"},{"location":"mesh/calculations/functions/restriction/#examples","text":"``@Restriction('DischargeMin[m3/s]', 'Licensed', @d('.DischargeDefault'),'Maximum') Finds events with Category = 'DischargeMin[m3/s]', and Status = 'Licensed'. Uses these events to generate a time series. If there are more than one event at a time with the same status, the maximum value will be used. If there are no events, the value found in the attribute '.DischargeDefault' will be used. @Restriction('DischargeMin[m3/s]', 'All', @t('.SomeTimeseriesAttribute'),'Average') Will generate a time series based on all events with Category = 'DischargeMin[m3/s]', regardless of statuses. If there are no events at a given time, the value from the '.SomeTimeseriesAttribute' will be used. If there are more than one event at a given time, the average value from those events will be used. @MIX(@Restriction('DischargeMin[m3/s]', 'SelfImposed',NaN, 'Maximum'),@Restriction('DischargeMin[m3/s]', 'Licensed', @d('.DischargeDefault'),'Maximum', 'to_HydroPlant') Generates a time series which uses values from events with status SelfImposed if such exist, otherwise it uses events from the licensed status. If there are no events, the value found in the attribute '.DischargeDefault' is used. Note! The events are found on the object using the link relations to_HydroPlant.","title":"Examples"},{"location":"mesh/calculations/functions/restriction/#possible-statuses","text":"This is a list of the possible statuses that can be used: Licensed (used as the main restriction) SelfImposed (used as the exception of the main restriction)","title":"Possible statuses"},{"location":"mesh/calculations/functions/restriction/#possible-categories","text":"This is a list of the possible categories: DischargeMin[m3/s] DischargeMax[m3/s] DischargeMaxAverage[m3/s] DischargeMinAverage[m3/s] DischargeMaxVariationUp[m3/s] DischargeMaxVariationDown[m3/s] DischargeBlockFlow[m3/s] ProductionMin[MW] ProductionMax[MW] ProductionMaxRegulations ProductionRampingUp[MW] ProductionRampingDown[MW] ProductionBlockGeneration[MW] RampingFlag ReservoirLevelMin[m] ReservoirLevelMax[m] ReservoirLevelRampingUp[m] ReservoirLevelRampingDown[m] PumpHeightDownstreamReservoir[m] PumpHeightUpstreamReservoir[m] PressureHeightRestriction[m] Priority ReservoirTacticalLevelMin[m] ReservoirTacticalLevelMax[m]","title":"Possible categories"},{"location":"mesh/calculations/functions/revision/","text":"Revision About the function This function generates a time series from the Revision events associated with this element, filtered on Status. The value will be 1 at the times where there is an event, and 0 otherwise. For more information about generating time series from restrictions/revisions, see the help for the Smart Power Apps module Availability Planner .** Note! ** The generated time series will per default be a breakpoint time series, unless an explicit transformation to a fixed interval is specified in the time series calculation. Syntax Revision(s) Revision(ss) Description # Type Description 1 s Status filter. Names of one or more statuses, or the keyword 'All'. When using more than one status, separate the names using ' 2 s (Optional) Search string to an object in ' '. Has to return exactly one object. The time series will be generated based on the Revision events related to this object. Examples @Revision('Proposed') generates a timeseries based on the Revision events with status 'Proposed'. @Revision('Proposed|Recommended') returns a timeseries generated from the Revision events which has Status 'Proposed' or 'Recommended'. @Revision('All') returns a timeseries generated from all valid Revision events associated with this element. @Revision('Proposed|Recommended', '..') returns a timeseries generated from the Revision events on the parent object, which has Status 'Proposed' or 'Recommended'. Possible statuses This is a list of the possible statuses that can be used: Proposed Recommended Suspended AppliedByTso ApprovedByTso RejectedByTso Planned Unplanned","title":"Revision"},{"location":"mesh/calculations/functions/revision/#revision","text":"","title":"Revision"},{"location":"mesh/calculations/functions/revision/#about-the-function","text":"This function generates a time series from the Revision events associated with this element, filtered on Status. The value will be 1 at the times where there is an event, and 0 otherwise. For more information about generating time series from restrictions/revisions, see the help for the Smart Power Apps module Availability Planner .** Note! ** The generated time series will per default be a breakpoint time series, unless an explicit transformation to a fixed interval is specified in the time series calculation.","title":"About the function"},{"location":"mesh/calculations/functions/revision/#syntax","text":"Revision(s) Revision(ss)","title":"Syntax"},{"location":"mesh/calculations/functions/revision/#description","text":"# Type Description 1 s Status filter. Names of one or more statuses, or the keyword 'All'. When using more than one status, separate the names using ' 2 s (Optional) Search string to an object in ' '. Has to return exactly one object. The time series will be generated based on the Revision events related to this object.","title":"Description"},{"location":"mesh/calculations/functions/revision/#examples","text":"@Revision('Proposed') generates a timeseries based on the Revision events with status 'Proposed'. @Revision('Proposed|Recommended') returns a timeseries generated from the Revision events which has Status 'Proposed' or 'Recommended'. @Revision('All') returns a timeseries generated from all valid Revision events associated with this element. @Revision('Proposed|Recommended', '..') returns a timeseries generated from the Revision events on the parent object, which has Status 'Proposed' or 'Recommended'.","title":"Examples"},{"location":"mesh/calculations/functions/revision/#possible-statuses","text":"This is a list of the possible statuses that can be used: Proposed Recommended Suspended AppliedByTso ApprovedByTso RejectedByTso Planned Unplanned","title":"Possible statuses"},{"location":"mesh/calculations/functions/round/","text":"ROUND About the function Rounds the numbers of a time series. To make rounding to for instance two decimals, you must multiply with 100, do ROUND operation and then divide by 100. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number. Syntax ROUND(t) ROUND(d) Description # Type Description 1 t Time series 1 d Number Example Temperature corrected = @ROUND(@t('.Temperature_raw')*10)/10 This result is rounded to one decimal. Temperature corrected = @ROUND(@t('.Temperature_raw')) This result is rounded to zero decimals.","title":"ROUND"},{"location":"mesh/calculations/functions/round/#round","text":"","title":"ROUND"},{"location":"mesh/calculations/functions/round/#about-the-function","text":"Rounds the numbers of a time series. To make rounding to for instance two decimals, you must multiply with 100, do ROUND operation and then divide by 100. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number.","title":"About the function"},{"location":"mesh/calculations/functions/round/#syntax","text":"ROUND(t) ROUND(d) Description # Type Description 1 t Time series 1 d Number","title":"Syntax"},{"location":"mesh/calculations/functions/round/#example","text":"Temperature corrected = @ROUND(@t('.Temperature_raw')*10)/10 This result is rounded to one decimal. Temperature corrected = @ROUND(@t('.Temperature_raw')) This result is rounded to zero decimals.","title":"Example"},{"location":"mesh/calculations/functions/round_integer/","text":"ROUND_INTEGER About the function This function rounds values in a time series to the nearest whole number. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number. Syntax ROUND_INTEGER(t) ROUND_INTEGER(d) Description # Type Description 1 t Time series 1 d Number Example Temperature corrected = @ROUND_INTEGER(@t('.Temperature_raw'))","title":"ROUND_INTEGER"},{"location":"mesh/calculations/functions/round_integer/#round_integer","text":"","title":"ROUND_INTEGER"},{"location":"mesh/calculations/functions/round_integer/#about-the-function","text":"This function rounds values in a time series to the nearest whole number. The result series has the same resolution as the time series/argument series. The function can also be applied to a single number.","title":"About the function"},{"location":"mesh/calculations/functions/round_integer/#syntax","text":"ROUND_INTEGER(t) ROUND_INTEGER(d) Description # Type Description 1 t Time series 1 d Number","title":"Syntax"},{"location":"mesh/calculations/functions/round_integer/#example","text":"Temperature corrected = @ROUND_INTEGER(@t('.Temperature_raw'))","title":"Example"},{"location":"mesh/calculations/functions/set_ts_val_unit/","text":"SET_TS_VALUNIT About the function This function is used to change the unit of a time series. Especially calculated series may contain several multiplied time series and result in different unit than the input time series. Syntax SET_TS_VALUNIT(t,d) SET_TS_VALUNIT(t,s) Description # Type Description 1 t Time series. 2 d or s Unit code number or text. See Unit codes for SET_TS_VALUNIT . Note! The text for unit code is language dependent. If in doubt, open the Time series application search window. Look in the Unit drop down menu to check if you are using the correct language for the code. Example Example 1: @SET_TS_VALUNIT(t,d) To change the unit of a result series to meters/second, the unit code is 120: @SET_TS_VALUNIT(timeseries1,120) Example 2: @SET_TS_VALUNIT(t,s) To change the unit of a result series to meters/second using text: @SET_TS_VALUNIT(timeseries1,'m/sec') This gives the same result as example 1.","title":"Set_Ts_Valunit"},{"location":"mesh/calculations/functions/set_ts_val_unit/#set_ts_valunit","text":"","title":"SET_TS_VALUNIT"},{"location":"mesh/calculations/functions/set_ts_val_unit/#about-the-function","text":"This function is used to change the unit of a time series. Especially calculated series may contain several multiplied time series and result in different unit than the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/set_ts_val_unit/#syntax","text":"SET_TS_VALUNIT(t,d) SET_TS_VALUNIT(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/set_ts_val_unit/#description","text":"# Type Description 1 t Time series. 2 d or s Unit code number or text. See Unit codes for SET_TS_VALUNIT . Note! The text for unit code is language dependent. If in doubt, open the Time series application search window. Look in the Unit drop down menu to check if you are using the correct language for the code.","title":"Description"},{"location":"mesh/calculations/functions/set_ts_val_unit/#example","text":"Example 1: @SET_TS_VALUNIT(t,d) To change the unit of a result series to meters/second, the unit code is 120: @SET_TS_VALUNIT(timeseries1,120) Example 2: @SET_TS_VALUNIT(t,s) To change the unit of a result series to meters/second using text: @SET_TS_VALUNIT(timeseries1,'m/sec') This gives the same result as example 1.","title":"Example"},{"location":"mesh/calculations/functions/sin/","text":"SIN About the function Calculates the sine of a time series. Note! The values of the input are in radians. Syntax SIN(t) # Type Description 1 t Time series Example Temperature_hour_VV = @SIN(@t('Temperature_hour_raw'))","title":"SIN"},{"location":"mesh/calculations/functions/sin/#sin","text":"","title":"SIN"},{"location":"mesh/calculations/functions/sin/#about-the-function","text":"Calculates the sine of a time series. Note! The values of the input are in radians.","title":"About the function"},{"location":"mesh/calculations/functions/sin/#syntax","text":"SIN(t) # Type Description 1 t Time series","title":"Syntax"},{"location":"mesh/calculations/functions/sin/#example","text":"Temperature_hour_VV = @SIN(@t('Temperature_hour_raw'))","title":"Example"},{"location":"mesh/calculations/functions/size/","text":"Size About the function This function returns the number of elements in the array given as argument. Syntax Size(T) Size(D) Size(S) Description Type Description T or D or S Array of time series or array of numeric values or array of string (symbols).","title":"Size"},{"location":"mesh/calculations/functions/size/#size","text":"","title":"Size"},{"location":"mesh/calculations/functions/size/#about-the-function","text":"This function returns the number of elements in the array given as argument.","title":"About the function"},{"location":"mesh/calculations/functions/size/#syntax","text":"Size(T) Size(D) Size(S)","title":"Syntax"},{"location":"mesh/calculations/functions/size/#description","text":"Type Description T or D or S Array of time series or array of numeric values or array of string (symbols).","title":"Description"},{"location":"mesh/calculations/functions/status/","text":"Status group functions Functions in the status group are used to make changes on the status of time series. This is done in the following way: When performing time series calculations the operation is divided into a sequence of binary operations. For example, evaluating \"TS1 + TS2\" for a time period of 24 hours is divided into 24 operations in case the time series has hourly resolution. The binary operation combines two operands and an operator, for example value at time t:Ts1(t) + Ts2(t). A value in this context is a numeric value and a status flag. The status flag is bit based, which means it can hold different independent statuses. When the calculator engine is processing such binary operations, the following rules are applied to both the numeric part and the status part: 2 + 10 = 12 with status suspect NOT set NaN + 10 = 10 with status suspect set (because one of the operands is missing value) 10 \u2013 NaN = 10 with status suspect set 10 * NaN = NaN with status suspect and missing set 10 / NaN = NaN with status notok and missing set An example where you may see a suspect value from a higher level calculation is when there is a SUM calculation applied for a group of time series. If some of the series are missing a value at a given time point, the result will be marked as suspect for this time point.","title":"About"},{"location":"mesh/calculations/functions/status/#status-group-functions","text":"Functions in the status group are used to make changes on the status of time series. This is done in the following way: When performing time series calculations the operation is divided into a sequence of binary operations. For example, evaluating \"TS1 + TS2\" for a time period of 24 hours is divided into 24 operations in case the time series has hourly resolution. The binary operation combines two operands and an operator, for example value at time t:Ts1(t) + Ts2(t). A value in this context is a numeric value and a status flag. The status flag is bit based, which means it can hold different independent statuses. When the calculator engine is processing such binary operations, the following rules are applied to both the numeric part and the status part: 2 + 10 = 12 with status suspect NOT set NaN + 10 = 10 with status suspect set (because one of the operands is missing value) 10 \u2013 NaN = 10 with status suspect set 10 * NaN = NaN with status suspect and missing set 10 / NaN = NaN with status notok and missing set An example where you may see a suspect value from a higher level calculation is when there is a SUM calculation applied for a group of time series. If some of the series are missing a value at a given time point, the result will be marked as suspect for this time point.","title":"Status group functions"},{"location":"mesh/calculations/functions/status_count/","text":"STATUS_COUNT About this function The STATUS_COUNT function takes one or more time series and returns a count of the number of points which match a given criterion ( status ). E.g. it can be used to count the number of 'missing' or 'notok' values. If one time series is provided, STATUS_COUNT will return a number. If more than one time series is provided, STATUS_COUNT will count the number of values for each point in time and make a time series out of those. The time series must have the same resolution. Example 1 NumberOfMissingOrManualPoints = @STATUS_COUNT(@t('.Temperature_hour_raw'), 'missing|MANUAL') Which will return the number of points in Temperature_hour_raw that are flagged as missing or manual. Example 2 NotOkPoints = @STATUS_COUNT({@t('.Timeseries1'), @t('.Timeseries2'), @t('.Timeseries3')}, 'notok') This will return a time series where each time series point is the number of points in Timeseries1/2/3 which are flagged as not OK at that time. Syntax STATUS_COUNT(g,s) STATUS_COUNT(T,s) STATUS_COUNT(t,s) The second argument uses the same syntax as the logical argument in STATUS_MASK . Description # Type ## Description 1 g Reference to a time series group. 2 s Symbol. # Type ## Description 1 t Reference to a time series. 2 s Symbol.","title":"STATUS_COUNT"},{"location":"mesh/calculations/functions/status_count/#status_count","text":"","title":"STATUS_COUNT"},{"location":"mesh/calculations/functions/status_count/#about-this-function","text":"The STATUS_COUNT function takes one or more time series and returns a count of the number of points which match a given criterion ( status ). E.g. it can be used to count the number of 'missing' or 'notok' values. If one time series is provided, STATUS_COUNT will return a number. If more than one time series is provided, STATUS_COUNT will count the number of values for each point in time and make a time series out of those. The time series must have the same resolution.","title":"About this function"},{"location":"mesh/calculations/functions/status_count/#example-1","text":"NumberOfMissingOrManualPoints = @STATUS_COUNT(@t('.Temperature_hour_raw'), 'missing|MANUAL') Which will return the number of points in Temperature_hour_raw that are flagged as missing or manual.","title":"Example 1"},{"location":"mesh/calculations/functions/status_count/#example-2","text":"NotOkPoints = @STATUS_COUNT({@t('.Timeseries1'), @t('.Timeseries2'), @t('.Timeseries3')}, 'notok') This will return a time series where each time series point is the number of points in Timeseries1/2/3 which are flagged as not OK at that time.","title":"Example 2"},{"location":"mesh/calculations/functions/status_count/#syntax","text":"STATUS_COUNT(g,s) STATUS_COUNT(T,s) STATUS_COUNT(t,s) The second argument uses the same syntax as the logical argument in STATUS_MASK .","title":"Syntax"},{"location":"mesh/calculations/functions/status_count/#description","text":"# Type ## Description 1 g Reference to a time series group. 2 s Symbol. # Type ## Description 1 t Reference to a time series. 2 s Symbol.","title":"Description"},{"location":"mesh/calculations/functions/status_mask/","text":"STATUS_MASK About the function Makes it possible to execute operations on time series based on the status code associated with the values. Syntax STATUS_MASK(t,s,s) Description # Type Description 1 t Time series, fixed interval or breakpoint series. 2 s Status mask consisting of one or several symbols. Symbols can be combined by adding 3 s Logical argument. See table below with valid logical arguments (BOOL etc.). Status mask (# 2): This argument is case sensitive. argument Description novalue No value notok Not ok missing Missing value suspect Value with suspect status manual Includes both manually changed and estimated values MANUAL Only manually changed estimated Only manually estimated validated Validated corrected Corrected locked Locked accepted Accepted default Default Validation methods (# 2): V01 means validation method 1. You can see this code if you turn on value information in Nimbus. Available validation methods are as follows: ARGUMENT Method V01 Abs limit V02 Delta limit V03 Delta limit extreme V04 Repeated value Correction methods (# 2): ARGUMENT Method C01 Constant value C02 Copy value C03 Interpolate C04 Extrapolate C05 Average value Logical arguments (# 3): This argument is case insensitive ARGUMENT Definition BOOL The result is a logical time series which returns values 0 for the status mask specified in argument 2, other statues are set to 1. BOOLINV The result is a logical time series which returns value 1 for the status mask specified in argument 2, other statuses are set to 0. REMOVE Removes all values on the time series for the status mask specified in argument 2. The result time series is always a break point series. BLANK Sets all the values, which matches the status mask specified in argument 2, to NaN. Example Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'missing|MANUAL','BOOL') The result sets all the missing and manually changed values to 0. Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'missing|MANUAL','BOOLINV') The result sets all the missing and manually changed values to 1. Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'MANUAL','BLANK') The result sets all the manually changed values to NaN.","title":"STATUS_MASK"},{"location":"mesh/calculations/functions/status_mask/#status_mask","text":"","title":"STATUS_MASK"},{"location":"mesh/calculations/functions/status_mask/#about-the-function","text":"Makes it possible to execute operations on time series based on the status code associated with the values. Syntax STATUS_MASK(t,s,s)","title":"About the function"},{"location":"mesh/calculations/functions/status_mask/#description","text":"# Type Description 1 t Time series, fixed interval or breakpoint series. 2 s Status mask consisting of one or several symbols. Symbols can be combined by adding 3 s Logical argument. See table below with valid logical arguments (BOOL etc.). Status mask (# 2): This argument is case sensitive. argument Description novalue No value notok Not ok missing Missing value suspect Value with suspect status manual Includes both manually changed and estimated values MANUAL Only manually changed estimated Only manually estimated validated Validated corrected Corrected locked Locked accepted Accepted default Default Validation methods (# 2): V01 means validation method 1. You can see this code if you turn on value information in Nimbus. Available validation methods are as follows: ARGUMENT Method V01 Abs limit V02 Delta limit V03 Delta limit extreme V04 Repeated value Correction methods (# 2): ARGUMENT Method C01 Constant value C02 Copy value C03 Interpolate C04 Extrapolate C05 Average value Logical arguments (# 3): This argument is case insensitive ARGUMENT Definition BOOL The result is a logical time series which returns values 0 for the status mask specified in argument 2, other statues are set to 1. BOOLINV The result is a logical time series which returns value 1 for the status mask specified in argument 2, other statuses are set to 0. REMOVE Removes all values on the time series for the status mask specified in argument 2. The result time series is always a break point series. BLANK Sets all the values, which matches the status mask specified in argument 2, to NaN.","title":"Description"},{"location":"mesh/calculations/functions/status_mask/#example","text":"Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'missing|MANUAL','BOOL') The result sets all the missing and manually changed values to 0. Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'missing|MANUAL','BOOLINV') The result sets all the missing and manually changed values to 1. Temperature_hour_operative = @STATUS_MASK(@t('Temperature_hour_raw'),'MANUAL','BLANK') The result sets all the manually changed values to NaN.","title":"Example"},{"location":"mesh/calculations/functions/sum/","text":"SUM About the function This function calculates the sum of all of the values of a time series, or all of the series in an array of time series. Syntax SUM(t) SUM(T) Description # Type Description 1 t or T Source time series to create sum from. Array of time series to create sum from. Example Example 1: @SUM(t) Result = @SUM(@t(\u2019Ts1\u2019)) The function returns the sum of the values of the time series for the required period. It returns a number. Example 2: @SUM(T) AreaTemperature = @SUM(@T('Weighted/Weighted_temperature')) sums an array of time series. The function returns the sum of the values of the expressions received for processing. The resulting time series is equal to the sum of the values for each time interval in the expression. For instance, in the first row, the result is 0,79 + -0,30 = 0,49 as shown in the last column.","title":"SUM"},{"location":"mesh/calculations/functions/sum/#sum","text":"","title":"SUM"},{"location":"mesh/calculations/functions/sum/#about-the-function","text":"This function calculates the sum of all of the values of a time series, or all of the series in an array of time series.","title":"About the function"},{"location":"mesh/calculations/functions/sum/#syntax","text":"SUM(t) SUM(T)","title":"Syntax"},{"location":"mesh/calculations/functions/sum/#description","text":"# Type Description 1 t or T Source time series to create sum from. Array of time series to create sum from.","title":"Description"},{"location":"mesh/calculations/functions/sum/#example","text":"","title":"Example"},{"location":"mesh/calculations/functions/sum/#example-1-sumt","text":"Result = @SUM(@t(\u2019Ts1\u2019)) The function returns the sum of the values of the time series for the required period. It returns a number.","title":"Example 1: @SUM(t)"},{"location":"mesh/calculations/functions/sum/#example-2-sumt","text":"AreaTemperature = @SUM(@T('Weighted/Weighted_temperature')) sums an array of time series. The function returns the sum of the values of the expressions received for processing. The resulting time series is equal to the sum of the values for each time interval in the expression. For instance, in the first row, the result is 0,79 + -0,30 = 0,49 as shown in the last column.","title":"Example 2: @SUM(T)"},{"location":"mesh/calculations/functions/tan/","text":"TAN About the function This function is used to calculate the tangent of a time series. Note! The values of the input are in radians. Syntax TAN(t) # Type Description 1 t Time series Example Temperature_hour_VV = @TAN(@t('Temperature_hour_raw'))","title":"TAN"},{"location":"mesh/calculations/functions/tan/#tan","text":"","title":"TAN"},{"location":"mesh/calculations/functions/tan/#about-the-function","text":"This function is used to calculate the tangent of a time series. Note! The values of the input are in radians.","title":"About the function"},{"location":"mesh/calculations/functions/tan/#syntax","text":"TAN(t) # Type Description 1 t Time series","title":"Syntax"},{"location":"mesh/calculations/functions/tan/#example","text":"Temperature_hour_VV = @TAN(@t('Temperature_hour_raw'))","title":"Example"},{"location":"mesh/calculations/functions/time/","text":"Time About the function Interprets a time specification given as a symbol (a character string) and returns a time point. The time point is defined as a number. The number is ticks as defined in Microsoft .Net. Syntax Time(s) Time(s,d) Description # Type Description 1 s Time specification. Accepted values: Start of the requested period/StartOfPeriod: SOP End of the requested period/EndOfPeriod: EOP Specific time: 20120326000000000 Time macro: YEAR+1d, +1h , UTC20150222 . 2 d A reference time used when parsing the first argument, if this is appropriate. Typically used if the first argument is not fully specified like the third definition example above. The function returns a time point that can be used to calculate another time point combined with the result of the TimeSpan function. It can also be used as argument to functions accepting a time point as number. You can convert a time point back to a time specification string by using the TimeToString function. Example using both Time and TimeSpan functions TimeWindow = @TimeSpan('HOUR') * @d('GlidingInterval') @PushExtPeriod('X', @Time('SOP')-TimeWindow, @Time('EOP')+ TimeWindow) Source = @t('Waterlevel_hour_ManualCorrection') @PopExtPeriod('X') ## = @TS_GLIDING_MEDIAN_GAUSS(Source,@d('GlidingInterval'))","title":"Time"},{"location":"mesh/calculations/functions/time/#time","text":"","title":"Time"},{"location":"mesh/calculations/functions/time/#about-the-function","text":"Interprets a time specification given as a symbol (a character string) and returns a time point. The time point is defined as a number. The number is ticks as defined in Microsoft .Net.","title":"About the function"},{"location":"mesh/calculations/functions/time/#syntax","text":"Time(s) Time(s,d)","title":"Syntax"},{"location":"mesh/calculations/functions/time/#description","text":"# Type Description 1 s Time specification. Accepted values: Start of the requested period/StartOfPeriod: SOP End of the requested period/EndOfPeriod: EOP Specific time: 20120326000000000 Time macro: YEAR+1d, +1h , UTC20150222 . 2 d A reference time used when parsing the first argument, if this is appropriate. Typically used if the first argument is not fully specified like the third definition example above. The function returns a time point that can be used to calculate another time point combined with the result of the TimeSpan function. It can also be used as argument to functions accepting a time point as number. You can convert a time point back to a time specification string by using the TimeToString function. Example using both Time and TimeSpan functions TimeWindow = @TimeSpan('HOUR') * @d('GlidingInterval') @PushExtPeriod('X', @Time('SOP')-TimeWindow, @Time('EOP')+ TimeWindow) Source = @t('Waterlevel_hour_ManualCorrection') @PopExtPeriod('X') ## = @TS_GLIDING_MEDIAN_GAUSS(Source,@d('GlidingInterval'))","title":"Description"},{"location":"mesh/calculations/functions/time_delayed/","text":"TimeDelayed About this function The function uses an XYZ table to calculate a value-dependent delayed output based on an input series. The XYZ table is identified by a symbol referring to the Mesh attribute that holds the table. The table contains the following information, using a typical delayed water flow case as example: Z value defines the flow level where this XY vector definition is applied, i.e. a valid from definition. X value defines the delay given as offset value with respect to actual resolution of the input times series. If resolution is 1 hour, value 3 means 3 hours output delay. Y value gives the percentage of value from input series that is added as the time delayed contribution to time point defined by value time + offset given by X value. Example table Example DelayedFlow = @TimeDelayed (@t('.FlowSeries'), 'FlowDelayTableAttributeName') If the value in the input series is exactly 20 at time t , this value is distributed like this: At t+4h, value = 20*0,02 At t+5h, value = 20*0,5 Etc. If the value is close to 30, like 29, then the multiplication factor is approximately 0,15 and 0,67 etc., because the factor is found as a linearisation between the current segment and the next segment. Syntax TimeDelayed(t,s) Description # Type ## Description 1 t Reference to a fixed interval time series. 2 s Attribute name that holds the XYZ table.","title":"TimeDelayed"},{"location":"mesh/calculations/functions/time_delayed/#timedelayed","text":"","title":"TimeDelayed"},{"location":"mesh/calculations/functions/time_delayed/#about-this-function","text":"The function uses an XYZ table to calculate a value-dependent delayed output based on an input series. The XYZ table is identified by a symbol referring to the Mesh attribute that holds the table. The table contains the following information, using a typical delayed water flow case as example: Z value defines the flow level where this XY vector definition is applied, i.e. a valid from definition. X value defines the delay given as offset value with respect to actual resolution of the input times series. If resolution is 1 hour, value 3 means 3 hours output delay. Y value gives the percentage of value from input series that is added as the time delayed contribution to time point defined by value time + offset given by X value.","title":"About this function"},{"location":"mesh/calculations/functions/time_delayed/#example-table","text":"","title":"Example table"},{"location":"mesh/calculations/functions/time_delayed/#example","text":"DelayedFlow = @TimeDelayed (@t('.FlowSeries'), 'FlowDelayTableAttributeName') If the value in the input series is exactly 20 at time t , this value is distributed like this: At t+4h, value = 20*0,02 At t+5h, value = 20*0,5 Etc. If the value is close to 30, like 29, then the multiplication factor is approximately 0,15 and 0,67 etc., because the factor is found as a linearisation between the current segment and the next segment.","title":"Example"},{"location":"mesh/calculations/functions/time_delayed/#syntax","text":"TimeDelayed(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/time_delayed/#description","text":"# Type ## Description 1 t Reference to a fixed interval time series. 2 s Attribute name that holds the XYZ table.","title":"Description"},{"location":"mesh/calculations/functions/time_examples/","text":"Time examples This topic provides examples of how to use some of the Time related functions. An expression: Expression Description tstart = @Time('YEAR',@Time('SOP')) Start of the year where requested time interval starts viewEndTime = @Time('EOP') End of requested time interval @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Change execution time interval to one hour before tstart and keep the same end Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') Unregister the temporary execution time interval @PushExtPeriod('y', tstart, @Time('EOP')) Register another time interval Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') Unregister ## = @ACCUMULATE(DeltaClipped,'>', 'YEAR') Accumulate from start of year The system aims at handling the extended time intervals automatically, but this manual example illustrates the usage of some of the Time functions. Instead of the last statement, you could enter as follows: ## = @ACCUMULATE(0.0, @TimeToString(tstart), DeltaClipped, 1, 0) I.e. accumulate values continuously from tstart to requested time interval end.","title":"Time Examples"},{"location":"mesh/calculations/functions/time_examples/#time-examples","text":"This topic provides examples of how to use some of the Time related functions. An expression: Expression Description tstart = @Time('YEAR',@Time('SOP')) Start of the year where requested time interval starts viewEndTime = @Time('EOP') End of requested time interval @PushExtPeriod('x', tstart - @TimeSpan('HOUR'), viewEndTime) Change execution time interval to one hour before tstart and keep the same end Precip = @t('PrecipBucket') * 1.0 @PopExtPeriod('x') Unregister the temporary execution time interval @PushExtPeriod('y', tstart, @Time('EOP')) Register another time interval Delta = @DELTA(Precip) DeltaClipped = Delta >= -2 ? Delta : 0 @PopExtPeriod('y') Unregister ## = @ACCUMULATE(DeltaClipped,'>', 'YEAR') Accumulate from start of year The system aims at handling the extended time intervals automatically, but this manual example illustrates the usage of some of the Time functions. Instead of the last statement, you could enter as follows: ## = @ACCUMULATE(0.0, @TimeToString(tstart), DeltaClipped, 1, 0) I.e. accumulate values continuously from tstart to requested time interval end.","title":"Time examples"},{"location":"mesh/calculations/functions/time_mask/","text":"TIME_MASK About the function This function creates time series from its arguments, normally used as time masks (a series with 1 or 0 as value), but not limited to only this type. Syntax There two main variants of this function. The general variant: TIME_MASK(s,S,D,s) TIME_MAS(s,S,D) TIME_MASK(S,D) A special variant using a holiday file: TIME_MASK(s) TIME_MASK(s,s) TIME_MASK(s,S,D,s) and TIME_MASK(s,S,D) The principle for the function is that you specify a repeat frequency, an array of time points and a corresponding array of function values. The time points are repeated at the frequency given as the first argument. The last argument allows you to specify the resolution for the result series. # Type Description 1 s Repeat frequency. For values, see Repeat frequency. 2 S Time point description array in any format. See Time point description array. 3 D Array of values which apply to the time points given in the preceding argument. 4 s Result series resolution. For values, see Resolution. Repeat frequency This argument consists of a time span code in addition to some options. The time span code can be one of the following calendar codes: Symbol Definition WEEKDAY Weekdays at daytime. Gives the value 1 at time steps within 'workhours'. WEEKEND Night and weekend - the opposite of WEEKDAY for all days except WEEKEND. HOLIDAY Night, weekends and holidays - the opposite of 'NORMALDAY'. NORMALDAY Weekday at daytime, except for holidays - same as 'WEEKDAY', but holidays are excluded ('holiday' and 'mholidays'). The following frequency codes can be used: Symbol Definition MIN15 Quarter of an hour HOUR Hour DAY 24-hour period WEEK Week MONTH Month YEAR Year NONE Absolute time points, no repetition frequency The options to frequency code are defined in <> brackets. Symbol Definition The result series gets linear curve type. Local DST calendar used when moving time points with given frequency. Database configured calendar used when moving time points with given frequency. UTC calendar used when moving time points with given frequency. Tip! You may incorporate calendar options into frequency codes as a prefix code. Valid calendar prefix codes are LOCAL, STANDARD, UTC and DB. For example frequency code LOCALDAY is the same as DAY Time point description array You can use the following special codes instead of a list of definitions. Symbol Definition MONTHLY Transformed to 12 time points representing start of each month, starting with January WEEKLY Transformed to 52 time points representing start of each week DAILY Transformed to 7 time points representing start of Monday, Tuesday etc HOURLY Transformed to 24 time points representing, from hour 0 to 23 QUARTERLY Transformed to 4 time points If you use one of these codes, you must still supply the correct number of values in the next argument. Resolution Symbol Definition MIN15 Quarter of an hour HOUR Hour DAY 24-hour period WEEK Week MONTH Month YEAR Year VARINT Breakpoint Example Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'HOUR') This gives a time series with daily repeat frequency and hourly time resolution. The presentation of data values is step wise. The table shows the result from a day on winter time (normal time). The definition of the expression has no reference to a defined time zone and uses the time zone of the database. Note! If the same expressions are run for a day in summer time, the values are shifted to one hour later. Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'HOUR') This gives a time series with daily repeat frequency and hourly time resolution. The presentation of data values is linear. Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'VARINT') This gives a time series with daily repeat frequency and breakpoint time resolution. The presentation of data values is step wise. TIME_MASK(S,D) This syntax variant has no repeat frequency, the given points in time are absolute. Gives the same effect as using TIME_MASK(s,S,D) with repeat frequency 'NONE'. TIME_MASK(s) and TIME_MASK(s,s) These variants let you define a logical time series from criteria given in by parameters in a text file. TIME_MASK(s) references the default calendar file holidays.txt. TIME_MASK(s,s) uses a user-defined file. Several user-defined files can be used in the same report. The default resolution is hours. If the resolution is 15-minute periods (TIMESTEP {MIN 15,1}) the result series while have this resolution. As an example, the function can be used to find the power usage in specific periods of the day, for instance in connection with low load, peak load etc. Example @TIME_MASK(s,s) The MyHolidayfile.txt is a user defined calendar file: # Filename: MyHolidayfile.txt # Tariff template: time definitions workhours 06:00 22:00 weekend 6 7 # Fixed holidays (date in American format, year/month/day) holiday 1/1 1/6 4/30 5/1 12/24 12/25 12/26 12/31 1997/6/20 1997/08/22 mholiday es-3 es-2 es+1 es+39 es+40 es+50 seasons 12/1 4/1 6/1 9/1 lseason 4/1 11/1 The function returns the following according to the calendar file definition: Expression Result mask @TIME_MASK('WEEKDAY',\u2019MyHolidayfile.txt\u2019) 1 for all hours (or 15-minute periods) from 06:00 to 22:00 on all days except for weekends, i.e. Monday to Friday inclusive. 0 otherwise. @TIME_MASK('WEEKEND',\u2019MyHolidayfile.txt\u2019) 1 for all hours (or 15-minute periods) from 22:00 to 06:00 from Monday to Friday, and 1 for the entire day on Saturday and Sunday. 0 otherwise. @TIME_MASK('HOLIDAY',\u2019MyHolidayfile.txt\u2019) Same mask as for \"WEEKEND\", in addition to 1 for all fixed and moveable public holidays defined in the current file. See \"holiday\" and \"mholidays\". 0 otherwise. @TIME_MASK('NORMALDAY',\u2019MyHolidayfile.txt\u2019) Opposite of WEEKDAY. The result above can be illustrated in a figure showing the difference between the various masks:","title":"Time_Mask"},{"location":"mesh/calculations/functions/time_mask/#time_mask","text":"","title":"TIME_MASK"},{"location":"mesh/calculations/functions/time_mask/#about-the-function","text":"This function creates time series from its arguments, normally used as time masks (a series with 1 or 0 as value), but not limited to only this type.","title":"About the function"},{"location":"mesh/calculations/functions/time_mask/#syntax","text":"There two main variants of this function. The general variant: TIME_MASK(s,S,D,s) TIME_MAS(s,S,D) TIME_MASK(S,D) A special variant using a holiday file: TIME_MASK(s) TIME_MASK(s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/time_mask/#time_maskssds-and-time_maskssd","text":"The principle for the function is that you specify a repeat frequency, an array of time points and a corresponding array of function values. The time points are repeated at the frequency given as the first argument. The last argument allows you to specify the resolution for the result series. # Type Description 1 s Repeat frequency. For values, see Repeat frequency. 2 S Time point description array in any format. See Time point description array. 3 D Array of values which apply to the time points given in the preceding argument. 4 s Result series resolution. For values, see Resolution.","title":"TIME_MASK(s,S,D,s) and TIME_MASK(s,S,D)"},{"location":"mesh/calculations/functions/time_mask/#repeat-frequency","text":"This argument consists of a time span code in addition to some options. The time span code can be one of the following calendar codes: Symbol Definition WEEKDAY Weekdays at daytime. Gives the value 1 at time steps within 'workhours'. WEEKEND Night and weekend - the opposite of WEEKDAY for all days except WEEKEND. HOLIDAY Night, weekends and holidays - the opposite of 'NORMALDAY'. NORMALDAY Weekday at daytime, except for holidays - same as 'WEEKDAY', but holidays are excluded ('holiday' and 'mholidays'). The following frequency codes can be used: Symbol Definition MIN15 Quarter of an hour HOUR Hour DAY 24-hour period WEEK Week MONTH Month YEAR Year NONE Absolute time points, no repetition frequency The options to frequency code are defined in <> brackets. Symbol Definition The result series gets linear curve type. Local DST calendar used when moving time points with given frequency. Database configured calendar used when moving time points with given frequency. UTC calendar used when moving time points with given frequency. Tip! You may incorporate calendar options into frequency codes as a prefix code. Valid calendar prefix codes are LOCAL, STANDARD, UTC and DB. For example frequency code LOCALDAY is the same as DAY","title":"Repeat frequency"},{"location":"mesh/calculations/functions/time_mask/#time-point-description-array","text":"You can use the following special codes instead of a list of definitions. Symbol Definition MONTHLY Transformed to 12 time points representing start of each month, starting with January WEEKLY Transformed to 52 time points representing start of each week DAILY Transformed to 7 time points representing start of Monday, Tuesday etc HOURLY Transformed to 24 time points representing, from hour 0 to 23 QUARTERLY Transformed to 4 time points If you use one of these codes, you must still supply the correct number of values in the next argument.","title":"Time point description array"},{"location":"mesh/calculations/functions/time_mask/#resolution","text":"Symbol Definition MIN15 Quarter of an hour HOUR Hour DAY 24-hour period WEEK Week MONTH Month YEAR Year VARINT Breakpoint","title":"Resolution"},{"location":"mesh/calculations/functions/time_mask/#example","text":"Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'HOUR') This gives a time series with daily repeat frequency and hourly time resolution. The presentation of data values is step wise. The table shows the result from a day on winter time (normal time). The definition of the expression has no reference to a defined time zone and uses the time zone of the database. Note! If the same expressions are run for a day in summer time, the values are shifted to one hour later. Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'HOUR') This gives a time series with daily repeat frequency and hourly time resolution. The presentation of data values is linear. Result time series = @TIME_MASK('DAY', {'DAY+07h', 'DAY+10h', 'DAY+14h', 'DAY+18h'}, {1,2,3,4},'VARINT') This gives a time series with daily repeat frequency and breakpoint time resolution. The presentation of data values is step wise.","title":"Example"},{"location":"mesh/calculations/functions/time_mask/#time_masksd","text":"This syntax variant has no repeat frequency, the given points in time are absolute. Gives the same effect as using TIME_MASK(s,S,D) with repeat frequency 'NONE'.","title":"TIME_MASK(S,D)"},{"location":"mesh/calculations/functions/time_mask/#time_masks-and-time_maskss","text":"These variants let you define a logical time series from criteria given in by parameters in a text file. TIME_MASK(s) references the default calendar file holidays.txt. TIME_MASK(s,s) uses a user-defined file. Several user-defined files can be used in the same report. The default resolution is hours. If the resolution is 15-minute periods (TIMESTEP {MIN 15,1}) the result series while have this resolution. As an example, the function can be used to find the power usage in specific periods of the day, for instance in connection with low load, peak load etc.","title":"TIME_MASK(s) and TIME_MASK(s,s)"},{"location":"mesh/calculations/functions/time_mask/#example_1","text":"@TIME_MASK(s,s) The MyHolidayfile.txt is a user defined calendar file: # Filename: MyHolidayfile.txt # Tariff template: time definitions workhours 06:00 22:00 weekend 6 7 # Fixed holidays (date in American format, year/month/day) holiday 1/1 1/6 4/30 5/1 12/24 12/25 12/26 12/31 1997/6/20 1997/08/22 mholiday es-3 es-2 es+1 es+39 es+40 es+50 seasons 12/1 4/1 6/1 9/1 lseason 4/1 11/1 The function returns the following according to the calendar file definition: Expression Result mask @TIME_MASK('WEEKDAY',\u2019MyHolidayfile.txt\u2019) 1 for all hours (or 15-minute periods) from 06:00 to 22:00 on all days except for weekends, i.e. Monday to Friday inclusive. 0 otherwise. @TIME_MASK('WEEKEND',\u2019MyHolidayfile.txt\u2019) 1 for all hours (or 15-minute periods) from 22:00 to 06:00 from Monday to Friday, and 1 for the entire day on Saturday and Sunday. 0 otherwise. @TIME_MASK('HOLIDAY',\u2019MyHolidayfile.txt\u2019) Same mask as for \"WEEKEND\", in addition to 1 for all fixed and moveable public holidays defined in the current file. See \"holiday\" and \"mholidays\". 0 otherwise. @TIME_MASK('NORMALDAY',\u2019MyHolidayfile.txt\u2019) Opposite of WEEKDAY. The result above can be illustrated in a figure showing the difference between the various masks:","title":"Example"},{"location":"mesh/calculations/functions/time_point_information/","text":"Time point information About the function This is a family of functions to get information from time points. The standard calendar is used, i.e. UTC+1 with no DST for normal Nordic setup. Syntax Minute(d) Hour(d) Day(d) Week(d) WeekDay(d) Month(d) Year(d) YearDay(d) Description Type Description d A time point represented as a number. The result from functions are: Minute within hour (0 \u2013 59) Hour within day (0 \u2013 23) Day within month (1-31) Month within year (1-12) Year DayInWeek, 1 for Monday, 7 for Sunday YearDay, day number within year (1-366)","title":"Time Point Information"},{"location":"mesh/calculations/functions/time_point_information/#time-point-information","text":"","title":"Time point information"},{"location":"mesh/calculations/functions/time_point_information/#about-the-function","text":"This is a family of functions to get information from time points. The standard calendar is used, i.e. UTC+1 with no DST for normal Nordic setup.","title":"About the function"},{"location":"mesh/calculations/functions/time_point_information/#syntax","text":"Minute(d) Hour(d) Day(d) Week(d) WeekDay(d) Month(d) Year(d) YearDay(d)","title":"Syntax"},{"location":"mesh/calculations/functions/time_point_information/#description","text":"Type Description d A time point represented as a number. The result from functions are: Minute within hour (0 \u2013 59) Hour within day (0 \u2013 23) Day within month (1-31) Month within year (1-12) Year DayInWeek, 1 for Monday, 7 for Sunday YearDay, day number within year (1-366)","title":"Description"},{"location":"mesh/calculations/functions/time_to_string/","text":"TimeToString About the function The function converts a time point to text specification on the YYYYMMDDhhmmss format prefixed with UTC as the calendar reference. Syntax TimeToString(d) Description Type Description d A time point represented as a number. The function returns the time point as an UTC string that can be used as argument to other functions expecting a time specification.","title":"TimeToString"},{"location":"mesh/calculations/functions/time_to_string/#timetostring","text":"","title":"TimeToString"},{"location":"mesh/calculations/functions/time_to_string/#about-the-function","text":"The function converts a time point to text specification on the YYYYMMDDhhmmss format prefixed with UTC as the calendar reference.","title":"About the function"},{"location":"mesh/calculations/functions/time_to_string/#syntax","text":"TimeToString(d)","title":"Syntax"},{"location":"mesh/calculations/functions/time_to_string/#description","text":"Type Description d A time point represented as a number. The function returns the time point as an UTC string that can be used as argument to other functions expecting a time specification.","title":"Description"},{"location":"mesh/calculations/functions/timespan/","text":"TimeSpan About the function The function transform its argument to a time span represented as a number. Syntax TimeSpan(s) Description Type Description s A definition like MIN15, HOUR, DAY, WEEK, MONTH, YEAR The function returns a time span that can be used to calculate another time point combined with the result of the Time function. The time span represents 30 days for month and 365 days for year. See examples in the Time function and Time examples .","title":"TimeSpan"},{"location":"mesh/calculations/functions/timespan/#timespan","text":"","title":"TimeSpan"},{"location":"mesh/calculations/functions/timespan/#about-the-function","text":"The function transform its argument to a time span represented as a number.","title":"About the function"},{"location":"mesh/calculations/functions/timespan/#syntax","text":"TimeSpan(s)","title":"Syntax"},{"location":"mesh/calculations/functions/timespan/#description","text":"Type Description s A definition like MIN15, HOUR, DAY, WEEK, MONTH, YEAR The function returns a time span that can be used to calculate another time point combined with the result of the Time function. The time span represents 30 days for month and 365 days for year. See examples in the Time function and Time examples .","title":"Description"},{"location":"mesh/calculations/functions/tostring/","text":"ToString About the function This function translates a number to a string. It will not round the value, only truncate it. Optional argument describes number of decimals to include in the string. Syntax ToString(d[,d]) Description # Type Description 1 d Numerical value that should be made into a string. 2 d Number of decimal places to include in the string representation. Default is 0. Example Double attribute named 'Factor' has a numerical value 2.756. @ToString(@d('.Factor') returns \"2\" @ToString(@d('.Factor',1) returns \"2.7\" @ToString(@d('.Factor',2) returns \"2.75\"","title":"ToString"},{"location":"mesh/calculations/functions/tostring/#tostring","text":"","title":"ToString"},{"location":"mesh/calculations/functions/tostring/#about-the-function","text":"This function translates a number to a string. It will not round the value, only truncate it. Optional argument describes number of decimals to include in the string.","title":"About the function"},{"location":"mesh/calculations/functions/tostring/#syntax","text":"ToString(d[,d])","title":"Syntax"},{"location":"mesh/calculations/functions/tostring/#description","text":"# Type Description 1 d Numerical value that should be made into a string. 2 d Number of decimal places to include in the string representation. Default is 0.","title":"Description"},{"location":"mesh/calculations/functions/tostring/#example","text":"Double attribute named 'Factor' has a numerical value 2.756. @ToString(@d('.Factor') returns \"2\" @ToString(@d('.Factor',1) returns \"2.7\" @ToString(@d('.Factor',2) returns \"2.75\"","title":"Example"},{"location":"mesh/calculations/functions/trace/","text":"Trace About the function This function enables log messages from calculation expressions. It is primarily intended for test purposes. You must turn on tracing to display these messages in the Object Structure log window in Nimbus. Syntax Trace(s) Turns trace mechanisms on or off. Argument is either 'ON' or 'OFF' (case insensitive). Trace(d,s) Creates a log message. Trace(d,s,t) Creates a log message with some basic time series information (resolution, curve type, unit of measurement). Trace(d,s,t,d) Creates a log message with some basic time series information (resolution, curve type, unit of measurement) and includes N values of the time series. The last argument is the number N and have maximum value 10. Description # Type Description 1 d Defines the information type. Legal value is 0, 1 or 2 \u2013 representing Information, Warning and Error respectively. 2 s Log message. 3 t A time series reference. 4 d Number of values from the time series to include in the log output. Maximum number is 10. Example @Trace('ON') @Trace(0, 'Information : Calculates Tmp1') Tmp1 = @t('TsRaw5') * 1.0 \u2026... @Trace(1,'A text presented as warning comes here') \u2026.. @Trace(2,'An error message comes here') @Trace('OFF')","title":"Trace"},{"location":"mesh/calculations/functions/trace/#trace","text":"","title":"Trace"},{"location":"mesh/calculations/functions/trace/#about-the-function","text":"This function enables log messages from calculation expressions. It is primarily intended for test purposes. You must turn on tracing to display these messages in the Object Structure log window in Nimbus.","title":"About the function"},{"location":"mesh/calculations/functions/trace/#syntax","text":"Trace(s) Turns trace mechanisms on or off. Argument is either 'ON' or 'OFF' (case insensitive). Trace(d,s) Creates a log message. Trace(d,s,t) Creates a log message with some basic time series information (resolution, curve type, unit of measurement). Trace(d,s,t,d) Creates a log message with some basic time series information (resolution, curve type, unit of measurement) and includes N values of the time series. The last argument is the number N and have maximum value 10.","title":"Syntax"},{"location":"mesh/calculations/functions/trace/#description","text":"# Type Description 1 d Defines the information type. Legal value is 0, 1 or 2 \u2013 representing Information, Warning and Error respectively. 2 s Log message. 3 t A time series reference. 4 d Number of values from the time series to include in the log output. Maximum number is 10.","title":"Description"},{"location":"mesh/calculations/functions/trace/#example","text":"@Trace('ON') @Trace(0, 'Information : Calculates Tmp1') Tmp1 = @t('TsRaw5') * 1.0 \u2026... @Trace(1,'A text presented as warning comes here') \u2026.. @Trace(2,'An error message comes here') @Trace('OFF')","title":"Example"},{"location":"mesh/calculations/functions/trans_profile/","text":"TRANS_PROFILE This topic describes TRANS_PROFILE variants ( R8 , Ra8 , R9 , Ra9 , R10 , Ra10 , R11 , Ra11 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Transform group functions R8 About the function Converts a time series into a finer resolution. The function uses the SUM method as a basis for the distribution. Syntax TRANS_PROFILE(t,t) Description TYPE Description t Input time series to be converted. t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution of the result. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period Example Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points. Ra8 About the function Same as R8 , but with absolute handling of the profile. The profile can be scaled using a scaling factor, defined as first argument. Syntax TRANS_PROFILE(d,t,t) Description # Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R8. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed in each period connected to a value on the input data series. Gives the resolution of the result. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R8 . Example 1 Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(1,@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(1,@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points. Example 2 Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(10,@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(10,@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points. R9 About the function Same as the function R8 , but with an extra argument deciding distribution method. Syntax TRANS_PROFILE(t,t,s) Description # TYPE Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution on the result. 3 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R8. Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi = Pi - MI Ra9 About the function Same as R9 , but with absolute handling of the profile. The profile can be scaled using a scaling factor, defined in argument 1. Syntax TRANS_PROFILE(d,t,t,s) Description # Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R9. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution on the result. 4 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as Ra8. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R9 . R10 About the function Same as R8 but uses a mask series in argument 3. Syntax TRANS_PROFILE(t,t,t) Description # TYPE Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 3 t Mask series representing the distributed time interval. Defines the resolution of the result time series. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi= Pi- MI See also R7 that offers the same functionality. Ra10 About the function Same as R10 , but with absolute handling of profile. The profile can be scaled using a scaling factor defined in argument 1. Syntax TRANS_PROFILE(d,t,t,t) Description # Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R10. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed in each period connected to a value on the input data series. 4 t Mask series representing the distributed time interval. Defines the resolution of the result time series. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R10 . R11 About the function Same function as R10 , but with an extra argument deciding distribution method. Valid values are 'MEAN', 'AVERAGE' or 'SUM'. The last value gives the exact same result as R10 . Syntax TRANS_PROFILE(t,t,t,s) Description # Type Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 3 t Mask series representing the distributed time interval. Defines the resolution of the result time series. 4 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R10. When the method is mean/average value based, the values are calculated like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi = Pi - MI Ra11 About the function Same as R11 , but with absolute handling of profile. The profile can be scaled using a scaling factor, defined in argument 1. Syntax TRANS_PROFILE(d,t,t,t,s) Description # Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R10. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 4 t Mask series representing the distributed time interval. Defines the resolution of the result time series. 5 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R10. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R11 .","title":"TRANS_PROFILE"},{"location":"mesh/calculations/functions/trans_profile/#trans_profile","text":"This topic describes TRANS_PROFILE variants ( R8 , Ra8 , R9 , Ra9 , R10 , Ra10 , R11 , Ra11 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Transform group functions","title":"TRANS_PROFILE"},{"location":"mesh/calculations/functions/trans_profile/#r8","text":"","title":"R8"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function","text":"Converts a time series into a finer resolution. The function uses the SUM method as a basis for the distribution.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax","text":"TRANS_PROFILE(t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description","text":"TYPE Description t Input time series to be converted. t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution of the result. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#example","text":"Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points.","title":"Example"},{"location":"mesh/calculations/functions/trans_profile/#ra8","text":"","title":"Ra8"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_1","text":"Same as R8 , but with absolute handling of the profile. The profile can be scaled using a scaling factor, defined as first argument.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_1","text":"TRANS_PROFILE(d,t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_1","text":"# Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R8. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed in each period connected to a value on the input data series. Gives the resolution of the result. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R8 . Example 1 Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(1,@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(1,@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points. Example 2 Profile = @TIME_MASK('HOUR',{'HOUR','HOUR+15x','HOUR+30x','HOUR+45x'},{1,2,3,2},'MIN15') Result time series = @TRANS_PROFILE(10,@t('Ts5'),Profile) Note! This set up gives the same result as @DISTRIBUTE(10,@t('Ts5'),MaskSeries,Profile) where the mask series argument is true for all the time points.","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#r9","text":"","title":"R9"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_2","text":"Same as the function R8 , but with an extra argument deciding distribution method.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_2","text":"TRANS_PROFILE(t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_2","text":"# TYPE Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution on the result. 3 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R8. Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi = Pi - MI","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#ra9","text":"","title":"Ra9"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_3","text":"Same as R9 , but with absolute handling of the profile. The profile can be scaled using a scaling factor, defined in argument 1.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_3","text":"TRANS_PROFILE(d,t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_3","text":"# Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R9. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed on each period connected to a value on the input data series. Gives the resolution on the result. 4 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as Ra8. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R9 .","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#r10","text":"","title":"R10"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_4","text":"Same as R8 but uses a mask series in argument 3.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_4","text":"TRANS_PROFILE(t,t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_4","text":"# TYPE Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 3 t Mask series representing the distributed time interval. Defines the resolution of the result time series. The distribution of the values is done like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period NI = Number of valid time point to distributed the input value into Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi= Pi- MI See also R7 that offers the same functionality.","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#ra10","text":"","title":"Ra10"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_5","text":"Same as R10 , but with absolute handling of profile. The profile can be scaled using a scaling factor defined in argument 1.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_5","text":"TRANS_PROFILE(d,t,t,t)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_5","text":"# Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R10. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed in each period connected to a value on the input data series. 4 t Mask series representing the distributed time interval. Defines the resolution of the result time series. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R10 .","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#r11","text":"","title":"R11"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_6","text":"Same function as R10 , but with an extra argument deciding distribution method. Valid values are 'MEAN', 'AVERAGE' or 'SUM'. The last value gives the exact same result as R10 .","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_6","text":"TRANS_PROFILE(t,t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_6","text":"# Type Description 1 t Input time series to be converted. 2 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 3 t Mask series representing the distributed time interval. Defines the resolution of the result time series. 4 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R10. When the method is mean/average value based, the values are calculated like this: Vi = Value calculated for the time point i in the result time series AI = Value from the input time series for the distributed period Pi = Profile value for the time point i in the result time series MI = Calculated mean value for the profile series for the distributed period If the value on the input data series is 0, the value is calculated like this: Vi = Pi - MI","title":"Description"},{"location":"mesh/calculations/functions/trans_profile/#ra11","text":"","title":"Ra11"},{"location":"mesh/calculations/functions/trans_profile/#about-the-function_7","text":"Same as R11 , but with absolute handling of profile. The profile can be scaled using a scaling factor, defined in argument 1.","title":"About the function"},{"location":"mesh/calculations/functions/trans_profile/#syntax_7","text":"TRANS_PROFILE(d,t,t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/trans_profile/#description_7","text":"# Type Description 1 d Scaling factor. If the scaling factor is 0, relative profiling is used, i.e. the function behaves like R10. 2 t Input time series to be converted. 3 t Profile series stating how the values are distributed on each period connected to a value on the input data series. 4 t Mask series representing the distributed time interval. Defines the resolution of the result time series. 5 s Valid distribution methods 'MEAN', 'AVERAGE' or 'SUM'. 'SUM' gives exactly the same result as R10. The distribution of the values is done like this: K is a scaling factor coming from argument 1 in the function. The other symbols used in the formula are the same as described in R11 .","title":"Description"},{"location":"mesh/calculations/functions/transform/","text":"TRANSFORM This topic describes the TRANSFORM variants ( R1 , R2 , R3 , R4 , R5 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Which functions can be used when? Transformation of time series from one resolution to another resolution is specified by symbols like HOUR, DAY, WEEK etc. Some of these symbols have a time zone foundation. For example, DAY can be related to European Standard Time (UTC+1), which is different from the DAY scope in Finland (UTC+2). When the time zone argument to TRANSFORM is omitted, the configured standard time zone with no Daylight Saving Time enabled is used. The TRANSFORM function is also used internally in the system when there is a request for time series values with a resolution that is different from its native definition. For example, it can be used as part of presenting a DAY based series into an HOUR based presentation, or vice versa. When doing this, the system will check if there are presentation hints available, as well as inspect the time series type and value unit to come up with reasonable arguments to the TRANSFORM operation. Note! In the mentioned example, the time zone used will always be the configured standard time zone. If this default behaviour appears to be wrong for your business process, you have to make a transformation that uses explicit TRANSFORM expressions in virtual time series or as part of a time series report. If the transformation is done from a fixed interval series to a variable interval series (breakpoint resolution), you may need to use additional status mask filtering to achieve the result you expect. This is mostly relevant when there are NaN values in the fixed resolution source series, because such value points are transformed to a NaN value with time from the start of each fixed resolution interval. If you want the breakpoint series to not contain explicit NaN values you have to combine the TRANSFORM function with STATUS_MASK as shown in example below: ## = @STATUS_MASK(@TRANSFORM(@t('.FixedSourceSeriesWithNaNValues'),'VARINT','DEFAULT'), 'missing', 'remove') The STATUS_MASK wrapper removes values with status missing from the transformed time series. R1 About the function This is the most common conversion function. You can use it to convert both ways, i.e. both from finer to coarser resolution, and the other way. The most common use is accumulation, i.e. transformation to coarser resolution. Most transformation methods are available for this latter use. Syntax TRANSFORM(t,s,s) Description # Type Description 1 t Time series to be converted. 2 s Time resolution of the result, given as a RESOLUTION symbol (see separate table). 3 s Conversion method, given as a TRANSMETHOD symbol (see separate table). Example Example 1: @TRANSFORM(t,s,s) Create week sums from a time series Res1 = @TRANSFORM(@t('HourTs'), 'WEEK', 'SUM') Example 2: @TRANSFORM(t,s,s) Create day average from a break point series Res2 = @TRANSFORM(@t('BrpTs'), 'DAY', 'AVGI') Example 3: Shows variants and their resulting time series Input series: Uses conversion from quarter to hour resolution: ResSum = @TRANSFORM(@t(\u2018Ts15Min\u2019,'HOUR','SUM') ResMean = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MEAN') ResMin = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MIN') ResMax = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MAX') ResFirst = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','FIRST') ResLast = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','LAST') R2 About the function Conversion to periods given by points of time on the series given as argument 2. The result is a break point series. This function enables periods that are not standard calendar units, e.g. 3 hours, 10 days, etc. Syntax TRANSFORM(t,t,s) Description # Type Description 1 t Time series to be converted. 2 t Time resolution on result, given as a break point series. The result series contains values on the points of time that exist on this series for current period. The values on this series are not used. 3 s Conversion method, given as a TRANSMETHOD symbol. Example If you want to create an 8 hour accumulation for a time series you may do like this: Create time mask series defining accumulation points of time: TM = @TIME_MASK('DAY', {'DAY','DAY+8h','DAY+16h'}, {1,2,3}, 'VARINT') Res = @TRANSFORM(@t('HourTs'), TM, 'SUM') Res is a result series with break point resolution. R3 About the function Conversions given by the number given as argument 2. The number represents number of seconds in the period. Syntax TRANSFORM(t,d,s) Description # Type Description 1 t Time series to be converted. 2 d Time resolution on the result, given as number of seconds in each period. 3 s Conversion method, given as a TRANSMETHOD symbol. Example If d is defined as the value 864000 this means a period of 10 days (60 60 24*10). The result is a break point series. R4 About the function Corresponding functionality as to R1 , but with an additional argument representing a mask series. This decides which values in the base series that should contribute to converted value. If you should transform to a time series with finer resolution, you must use the DISTRIBUTE function. Syntax TRANSFORM(t,s,s,t) Description # Type Description 1 t Time series to be converted. 2 s Time resolution on result, given as a RESOLUTION symbol. 3 s Conversion method, given as a TRANSMETHOD symbol. 4 t Mask series deciding which values on the time series in argument 1 that should contribute to the result. Example If you wish to calculate a day series with the sum of values for 6am to 8pm, you can define the following expression: Create a time mask series that define hours to be included in the sum (value equals 1 on the mask series): TM = @TIME_MASK('DAY', {'DAY+6h','DAY+20h'}, {1,0}) Res = @TRANSFORM(@t('HourTs'), 'DAY', 'SUM', TM) R5 About the function Corresponding functionality as in R1 , but with an additional argument that decides which time zone that is the base for the conversion. This gives the possibilities to user periods that are different from the rest of the environment. Syntax TRANSFORM(t,s,s,s) Description # Type Description 1 t Time series to be converted. 2 s Time resolution on result, given as a RESOLUTION symbol. 3 s Conversion method, given as a TRANSMETHOD symbol. 4 s Symbol stating time zone. 'LOCAL', 'LOKAL' and 'LT' give local time zone, 'NORMAL', 'STANDARD' and 'NT' gives normal time zone. Otherwise, the system will perform a lookup and see whether the value of the symbol is the name on an explicitly stated time zone in the system. Unknown zone equals no zone and then normal time zone is used. Example If you wish to calculate the DAY average on every hour of the day with Daylight Saving Time (DST), you can make an expression like this : Res = @TRANSFORM(@TRANSFORM(@t(\u2018HourSeries\u2019), 'DAY', 'MEAN', 'LT'), 'HOUR', 'MEAN', 'LT')","title":"TRANSFORM"},{"location":"mesh/calculations/functions/transform/#transform","text":"This topic describes the TRANSFORM variants ( R1 , R2 , R3 , R4 , R5 ) for transforming from one time resolution to another. To get an overview of all the transformation function variants, see: Which functions can be used when? Transformation of time series from one resolution to another resolution is specified by symbols like HOUR, DAY, WEEK etc. Some of these symbols have a time zone foundation. For example, DAY can be related to European Standard Time (UTC+1), which is different from the DAY scope in Finland (UTC+2). When the time zone argument to TRANSFORM is omitted, the configured standard time zone with no Daylight Saving Time enabled is used. The TRANSFORM function is also used internally in the system when there is a request for time series values with a resolution that is different from its native definition. For example, it can be used as part of presenting a DAY based series into an HOUR based presentation, or vice versa. When doing this, the system will check if there are presentation hints available, as well as inspect the time series type and value unit to come up with reasonable arguments to the TRANSFORM operation. Note! In the mentioned example, the time zone used will always be the configured standard time zone. If this default behaviour appears to be wrong for your business process, you have to make a transformation that uses explicit TRANSFORM expressions in virtual time series or as part of a time series report. If the transformation is done from a fixed interval series to a variable interval series (breakpoint resolution), you may need to use additional status mask filtering to achieve the result you expect. This is mostly relevant when there are NaN values in the fixed resolution source series, because such value points are transformed to a NaN value with time from the start of each fixed resolution interval. If you want the breakpoint series to not contain explicit NaN values you have to combine the TRANSFORM function with STATUS_MASK as shown in example below: ## = @STATUS_MASK(@TRANSFORM(@t('.FixedSourceSeriesWithNaNValues'),'VARINT','DEFAULT'), 'missing', 'remove') The STATUS_MASK wrapper removes values with status missing from the transformed time series.","title":"TRANSFORM"},{"location":"mesh/calculations/functions/transform/#r1","text":"","title":"R1"},{"location":"mesh/calculations/functions/transform/#about-the-function","text":"This is the most common conversion function. You can use it to convert both ways, i.e. both from finer to coarser resolution, and the other way. The most common use is accumulation, i.e. transformation to coarser resolution. Most transformation methods are available for this latter use.","title":"About the function"},{"location":"mesh/calculations/functions/transform/#syntax","text":"TRANSFORM(t,s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/transform/#description","text":"# Type Description 1 t Time series to be converted. 2 s Time resolution of the result, given as a RESOLUTION symbol (see separate table). 3 s Conversion method, given as a TRANSMETHOD symbol (see separate table).","title":"Description"},{"location":"mesh/calculations/functions/transform/#example","text":"Example 1: @TRANSFORM(t,s,s) Create week sums from a time series Res1 = @TRANSFORM(@t('HourTs'), 'WEEK', 'SUM') Example 2: @TRANSFORM(t,s,s) Create day average from a break point series Res2 = @TRANSFORM(@t('BrpTs'), 'DAY', 'AVGI') Example 3: Shows variants and their resulting time series Input series: Uses conversion from quarter to hour resolution: ResSum = @TRANSFORM(@t(\u2018Ts15Min\u2019,'HOUR','SUM') ResMean = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MEAN') ResMin = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MIN') ResMax = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','MAX') ResFirst = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','FIRST') ResLast = @TRANSFORM(@t(\u2018Ts15Min\u2019),'HOUR','LAST')","title":"Example"},{"location":"mesh/calculations/functions/transform/#r2","text":"","title":"R2"},{"location":"mesh/calculations/functions/transform/#about-the-function_1","text":"Conversion to periods given by points of time on the series given as argument 2. The result is a break point series. This function enables periods that are not standard calendar units, e.g. 3 hours, 10 days, etc.","title":"About the function"},{"location":"mesh/calculations/functions/transform/#syntax_1","text":"TRANSFORM(t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/transform/#description_1","text":"# Type Description 1 t Time series to be converted. 2 t Time resolution on result, given as a break point series. The result series contains values on the points of time that exist on this series for current period. The values on this series are not used. 3 s Conversion method, given as a TRANSMETHOD symbol.","title":"Description"},{"location":"mesh/calculations/functions/transform/#example_1","text":"If you want to create an 8 hour accumulation for a time series you may do like this: Create time mask series defining accumulation points of time: TM = @TIME_MASK('DAY', {'DAY','DAY+8h','DAY+16h'}, {1,2,3}, 'VARINT') Res = @TRANSFORM(@t('HourTs'), TM, 'SUM') Res is a result series with break point resolution.","title":"Example"},{"location":"mesh/calculations/functions/transform/#r3","text":"","title":"R3"},{"location":"mesh/calculations/functions/transform/#about-the-function_2","text":"Conversions given by the number given as argument 2. The number represents number of seconds in the period.","title":"About the function"},{"location":"mesh/calculations/functions/transform/#syntax_2","text":"TRANSFORM(t,d,s)","title":"Syntax"},{"location":"mesh/calculations/functions/transform/#description_2","text":"# Type Description 1 t Time series to be converted. 2 d Time resolution on the result, given as number of seconds in each period. 3 s Conversion method, given as a TRANSMETHOD symbol.","title":"Description"},{"location":"mesh/calculations/functions/transform/#example_2","text":"If d is defined as the value 864000 this means a period of 10 days (60 60 24*10). The result is a break point series.","title":"Example"},{"location":"mesh/calculations/functions/transform/#r4","text":"","title":"R4"},{"location":"mesh/calculations/functions/transform/#about-the-function_3","text":"Corresponding functionality as to R1 , but with an additional argument representing a mask series. This decides which values in the base series that should contribute to converted value. If you should transform to a time series with finer resolution, you must use the DISTRIBUTE function.","title":"About the function"},{"location":"mesh/calculations/functions/transform/#syntax_3","text":"TRANSFORM(t,s,s,t)","title":"Syntax"},{"location":"mesh/calculations/functions/transform/#description_3","text":"# Type Description 1 t Time series to be converted. 2 s Time resolution on result, given as a RESOLUTION symbol. 3 s Conversion method, given as a TRANSMETHOD symbol. 4 t Mask series deciding which values on the time series in argument 1 that should contribute to the result.","title":"Description"},{"location":"mesh/calculations/functions/transform/#example_3","text":"If you wish to calculate a day series with the sum of values for 6am to 8pm, you can define the following expression: Create a time mask series that define hours to be included in the sum (value equals 1 on the mask series): TM = @TIME_MASK('DAY', {'DAY+6h','DAY+20h'}, {1,0}) Res = @TRANSFORM(@t('HourTs'), 'DAY', 'SUM', TM)","title":"Example"},{"location":"mesh/calculations/functions/transform/#r5","text":"","title":"R5"},{"location":"mesh/calculations/functions/transform/#about-the-function_4","text":"Corresponding functionality as in R1 , but with an additional argument that decides which time zone that is the base for the conversion. This gives the possibilities to user periods that are different from the rest of the environment.","title":"About the function"},{"location":"mesh/calculations/functions/transform/#syntax_4","text":"TRANSFORM(t,s,s,s)","title":"Syntax"},{"location":"mesh/calculations/functions/transform/#description_4","text":"# Type Description 1 t Time series to be converted. 2 s Time resolution on result, given as a RESOLUTION symbol. 3 s Conversion method, given as a TRANSMETHOD symbol. 4 s Symbol stating time zone. 'LOCAL', 'LOKAL' and 'LT' give local time zone, 'NORMAL', 'STANDARD' and 'NT' gives normal time zone. Otherwise, the system will perform a lookup and see whether the value of the symbol is the name on an explicitly stated time zone in the system. Unknown zone equals no zone and then normal time zone is used. Example If you wish to calculate the DAY average on every hour of the day with Daylight Saving Time (DST), you can make an expression like this : Res = @TRANSFORM(@TRANSFORM(@t(\u2018HourSeries\u2019), 'DAY', 'MEAN', 'LT'), 'HOUR', 'MEAN', 'LT')","title":"Description"},{"location":"mesh/calculations/functions/transform_terms/","text":"Terms used in the functions The functions in this category are used to calculate time series with a different time resolution than the source. The result can be in the following resolution: Table 1: RESOLUTION symbol values RESOLUTION symbol Description VARINT Break point series, i.e. free distance between each point of time with value. MIN15 Fixed 15 minutes interval HOUR Fixed hour interval DAY Fixed day interval WEEK Fixed week interval MONTH Fixed month interval YEAR Fixed year interval Table 2a: TRANSMETHOD Symbol values valid in transformation to coarser time resolution TRANSMETHOD Symbol Description SUM SUMV The sum of the values included in the base for this value. Does not consider how long the values are valid, i.e. a break point series with two values in the current interval that will give the sum of these two values. SUMI Integral based sum with resolution second. Calculates the sum of value multiplied with number of seconds each value is valid. Value equal 1 at the start of the day will give 86400 as day value if the base is one break point series and 3600 if this is an hour series with only one value on first hour. MEAN AVG or AVGV AVERAGE For fixed interval series. Sum of all values in accumulation period divided by number of values in the accumulation period (24 for hour series that is transformed to day series). For break point series: Mean value of the values included in the base for this value. Does not consider how long the values are valid, i.e. a break point series with two values in the current interval that will give the mean value of these two values. AVGI Integral based mean value, i.e. considers how much of the accumulation period that a given value is valid (to next value that can be NaN for a fixed interval series). This value is presented as mean value in the summary part of the presentation in Table. FIRST First value in the accumulation period. For break point series this is the functional value at the start of the accumulation period, unless there exist an explicit value. Please note! For fixed interval series it is the first value not being NaN in the accumulation period. LAST Last value in the accumulation period. For break point series this is the functional value at the end of the accumulation period, unless there exist an explicit value. Note! For fixed interval series it is the last value not being NaN in the accumulation period. MIN Smallest value in the accumulation period. MAX Largest value in the accumulation period. GSUM This transformation code requires that you use TRANSFORM version with resolution given as a break point series (version R2) and that the base series is fixed interval. Same as SUM but with different period handling. In this case the period is not adjusted with regards to resolution. Here you can e.g. transform to week value based on Wednesday to Wednesday or inhomogeneous periods given by points of time on a given break point series. This transformation code requires that you use TRANSFORM version with resolution given as a break point series (version R2). GMEAN See GSUM. Same properties, but here mean value for period is calculated. Observe that in case the transformation method is integral based (for example ACCAVGI and ACCAVGI_NOW), the source series must have curvetype staircase start of step. For accumulation with base in break point series, you have the following particular methods that consider current period in a special way. Table 2b: Special accumulation methods TRANSMETHOD Symbol Description ACCVOLUME Transforms meter reading values with random solution to a fixed interval period. This is done by calculating the functional value at interval points of time, calculate integral based mean for the resolution interval and then change up to next interval. Note! There is also a separate function to do this transformation, @Metered2Volume ACCM2V See ACCVOLUME Table 3: TRANSMETHOD symbol values valid in transformation to finer time resolution TRANSMETHOD Symbol Description SUM The sum of the result values for expanded period equals the value in the input data series. MEAN AVERAGE The mean values of the result values for expanded period equals the value in the input data series. Explicit default transformation If you state transformation code DEFAULT, the system will decide method from value type and value unit on the series. These are the rules that are taken into account: TRANSMETHOD equals DEFAULT Unit/type Description Time series type of type linear Here the first value in the base series is used, i.e. code FIRST Value unit Celsius, MM3, MW MWh/h, kWh/h Meter %, % of max, % of normal M3/s, MW/Hz NOK/MWh, SEK/MWh, EUR/MWh Liter/s, Liter/s/km2 Meter/s Here mean value is used as method. AVG for fixed interval series and for break point series AVGI is used, integral based mean value. Value unit mm, cm And value type: snow depth, snow water equivalent ground water level, soil moisture Here mean value is also used as method. For break point series AVGI is used, integral based mean value. Otherwise when accumulating Mean value method AVGI for break point series and SUM for fixed interval series. When transforming to a finer resolution General SUM, i.e. value is divided on number of points in this that covers new resolution MW, kW and more Mean value (AVG) If the environment variable ICC_TSRSERVER_VARINT_SUMI_ON_ACCUMULATE is defined, break point series that do not have step type linear will always be accumulated with method SUMI. Implicit default transformation A time series report definition can include an attribute stating that the presentation e.g. should have week resolution even if the report only consists of hour series. From presentation in table you can also select a different resolution. It is i.e. necessary to transform hour values to week values without stating how this is done through a calculation expression. This is called implicit default transformation. Basically the same rules as described under Explicit default transformation are used. But you can influence how this should happen by setting attributes on columns. This is controlled by the attribute TYPE with value {method}, where method can be one of these values: ACCSUM, ACCSUMI, ACCAVG, ACCAVGI, ACCMEAN ACCFIRST, ACCLAST, ACCMIN, ACCMAX, ACCLAST_NOW, ACCAVGI_NOW, ACCSUMI_NOW These are the same codes defined in TRANSMETHOD but with prefix ACC. The explanation for the symbols is the same as the corresponding TRANSMETHOD documentation. Example on transformation attribute in a column definition: TYPE {ACCMIN} Mask series In some of the functions the term mask series is used. This is a time series where you separate between the values NaN, 0 and all other values. NaN and 0 are logically perceived as logically untrue value (FALSE) and all other values are perceived as logically true value (TRUE). A mask series can e.g. be used to define which hours that should be included in the calculation of a day value with method SUM. Profile series In some of the functions the term profile series is used. This is a time series that can be used in transformation to finer resolution, e.g. from day to hour. In this function you can either use mean value or sum consideration, i.e. if the mean value from calculated values should equal the value they were derived from or if it is the sum of the values that should equal the start point value. Handling profile The profile series can be used in two ways, relative or absolute. Current functions exist in two versions, one using relative profile and one using the profile directly (called absolute). The latter version can be scaled using a coefficient that is an argument to the function. The figure shows that use of relative profile will strengthen the variation if the mean value for the input data series (V) is large compared to the mean value on the profile series (M). By using absolute profile the variation will equal the profile series, possibly adjusted with a factor different from 1 that is given as first argument to the functions using absolute profile. Input data series In all functions the first time series is argument to the time series to be converted in one way or the other.","title":"Terms used in the functions"},{"location":"mesh/calculations/functions/transform_terms/#terms-used-in-the-functions","text":"The functions in this category are used to calculate time series with a different time resolution than the source. The result can be in the following resolution:","title":"Terms used in the functions"},{"location":"mesh/calculations/functions/transform_terms/#table-1-resolution-symbol-values","text":"RESOLUTION symbol Description VARINT Break point series, i.e. free distance between each point of time with value. MIN15 Fixed 15 minutes interval HOUR Fixed hour interval DAY Fixed day interval WEEK Fixed week interval MONTH Fixed month interval YEAR Fixed year interval","title":"Table 1: RESOLUTION symbol values"},{"location":"mesh/calculations/functions/transform_terms/#table-2a-transmethod-symbol-values-valid-in-transformation-to-coarser-time-resolution","text":"TRANSMETHOD Symbol Description SUM SUMV The sum of the values included in the base for this value. Does not consider how long the values are valid, i.e. a break point series with two values in the current interval that will give the sum of these two values. SUMI Integral based sum with resolution second. Calculates the sum of value multiplied with number of seconds each value is valid. Value equal 1 at the start of the day will give 86400 as day value if the base is one break point series and 3600 if this is an hour series with only one value on first hour. MEAN AVG or AVGV AVERAGE For fixed interval series. Sum of all values in accumulation period divided by number of values in the accumulation period (24 for hour series that is transformed to day series). For break point series: Mean value of the values included in the base for this value. Does not consider how long the values are valid, i.e. a break point series with two values in the current interval that will give the mean value of these two values. AVGI Integral based mean value, i.e. considers how much of the accumulation period that a given value is valid (to next value that can be NaN for a fixed interval series). This value is presented as mean value in the summary part of the presentation in Table. FIRST First value in the accumulation period. For break point series this is the functional value at the start of the accumulation period, unless there exist an explicit value. Please note! For fixed interval series it is the first value not being NaN in the accumulation period. LAST Last value in the accumulation period. For break point series this is the functional value at the end of the accumulation period, unless there exist an explicit value. Note! For fixed interval series it is the last value not being NaN in the accumulation period. MIN Smallest value in the accumulation period. MAX Largest value in the accumulation period. GSUM This transformation code requires that you use TRANSFORM version with resolution given as a break point series (version R2) and that the base series is fixed interval. Same as SUM but with different period handling. In this case the period is not adjusted with regards to resolution. Here you can e.g. transform to week value based on Wednesday to Wednesday or inhomogeneous periods given by points of time on a given break point series. This transformation code requires that you use TRANSFORM version with resolution given as a break point series (version R2). GMEAN See GSUM. Same properties, but here mean value for period is calculated. Observe that in case the transformation method is integral based (for example ACCAVGI and ACCAVGI_NOW), the source series must have curvetype staircase start of step. For accumulation with base in break point series, you have the following particular methods that consider current period in a special way.","title":"Table 2a: TRANSMETHOD Symbol values valid in transformation to coarser time resolution"},{"location":"mesh/calculations/functions/transform_terms/#table-2b-special-accumulation-methods","text":"TRANSMETHOD Symbol Description ACCVOLUME Transforms meter reading values with random solution to a fixed interval period. This is done by calculating the functional value at interval points of time, calculate integral based mean for the resolution interval and then change up to next interval. Note! There is also a separate function to do this transformation, @Metered2Volume ACCM2V See ACCVOLUME","title":"Table 2b: Special accumulation methods"},{"location":"mesh/calculations/functions/transform_terms/#table-3-transmethod-symbol-values-valid-in-transformation-to-finer-time-resolution","text":"TRANSMETHOD Symbol Description SUM The sum of the result values for expanded period equals the value in the input data series. MEAN AVERAGE The mean values of the result values for expanded period equals the value in the input data series.","title":"Table 3: TRANSMETHOD symbol values valid in transformation to finer time resolution"},{"location":"mesh/calculations/functions/transform_terms/#explicit-default-transformation","text":"If you state transformation code DEFAULT, the system will decide method from value type and value unit on the series. These are the rules that are taken into account: TRANSMETHOD equals DEFAULT Unit/type Description Time series type of type linear Here the first value in the base series is used, i.e. code FIRST Value unit Celsius, MM3, MW MWh/h, kWh/h Meter %, % of max, % of normal M3/s, MW/Hz NOK/MWh, SEK/MWh, EUR/MWh Liter/s, Liter/s/km2 Meter/s Here mean value is used as method. AVG for fixed interval series and for break point series AVGI is used, integral based mean value. Value unit mm, cm And value type: snow depth, snow water equivalent ground water level, soil moisture Here mean value is also used as method. For break point series AVGI is used, integral based mean value. Otherwise when accumulating Mean value method AVGI for break point series and SUM for fixed interval series. When transforming to a finer resolution General SUM, i.e. value is divided on number of points in this that covers new resolution MW, kW and more Mean value (AVG) If the environment variable ICC_TSRSERVER_VARINT_SUMI_ON_ACCUMULATE is defined, break point series that do not have step type linear will always be accumulated with method SUMI.","title":"Explicit default transformation"},{"location":"mesh/calculations/functions/transform_terms/#implicit-default-transformation","text":"A time series report definition can include an attribute stating that the presentation e.g. should have week resolution even if the report only consists of hour series. From presentation in table you can also select a different resolution. It is i.e. necessary to transform hour values to week values without stating how this is done through a calculation expression. This is called implicit default transformation. Basically the same rules as described under Explicit default transformation are used. But you can influence how this should happen by setting attributes on columns. This is controlled by the attribute TYPE with value {method}, where method can be one of these values: ACCSUM, ACCSUMI, ACCAVG, ACCAVGI, ACCMEAN ACCFIRST, ACCLAST, ACCMIN, ACCMAX, ACCLAST_NOW, ACCAVGI_NOW, ACCSUMI_NOW These are the same codes defined in TRANSMETHOD but with prefix ACC. The explanation for the symbols is the same as the corresponding TRANSMETHOD documentation. Example on transformation attribute in a column definition: TYPE {ACCMIN}","title":"Implicit default transformation"},{"location":"mesh/calculations/functions/transform_terms/#mask-series","text":"In some of the functions the term mask series is used. This is a time series where you separate between the values NaN, 0 and all other values. NaN and 0 are logically perceived as logically untrue value (FALSE) and all other values are perceived as logically true value (TRUE). A mask series can e.g. be used to define which hours that should be included in the calculation of a day value with method SUM.","title":"Mask series"},{"location":"mesh/calculations/functions/transform_terms/#profile-series","text":"In some of the functions the term profile series is used. This is a time series that can be used in transformation to finer resolution, e.g. from day to hour. In this function you can either use mean value or sum consideration, i.e. if the mean value from calculated values should equal the value they were derived from or if it is the sum of the values that should equal the start point value.","title":"Profile series"},{"location":"mesh/calculations/functions/transform_terms/#handling-profile","text":"The profile series can be used in two ways, relative or absolute. Current functions exist in two versions, one using relative profile and one using the profile directly (called absolute). The latter version can be scaled using a coefficient that is an argument to the function. The figure shows that use of relative profile will strengthen the variation if the mean value for the input data series (V) is large compared to the mean value on the profile series (M). By using absolute profile the variation will equal the profile series, possibly adjusted with a factor different from 1 that is given as first argument to the functions using absolute profile.","title":"Handling profile"},{"location":"mesh/calculations/functions/transform_terms/#input-data-series","text":"In all functions the first time series is argument to the time series to be converted in one way or the other.","title":"Input data series"},{"location":"mesh/calculations/functions/transform_what_when/","text":"Which functions can be used when? Here is a list of common calculations where transformation of values from one resolution to another is included ACCUMULATE VALUES STANDARD BEHAVIOR This means transforming from a break point series to a fixed interval series, or from a fixed interval series to a different fixed interval series with coarser resolution, for example from hour to day series. For this type of task this is used: R1 = @TRANSFORM(t,s,s) ACCUMULATE VALUES TO SPECIFIC RESOLUTIONS This means transformation from one time series to a different time series with a resolution that is not the same as calendar units, e.g. quarter, hour, day, week, month or year. You can choose a fixed period given from the start of the calculation or more general as points of time on a break point series. For this type of tasks the following are used: R2 = @TRANSFORM(t,t,s) R3 = @TRANSFORM(t,d,s) MAKE TRANSFORMATION WITH REFERENCE TO TIME ZONE The calculator performs calculations with reference to normal time if nothing else is given. A normal example is to accumulate hour values to day values or week values using local time (summer time) or a different time zone. For this type of task the following is used: R5 = @TRANSFORM(t,s,s,s) ACCUMULATE SELECTED VALUES Standard accumulation uses all values included in the source period for each single result value, e.g. all values in a day. If you do not wish this, you use a mask series with values equal to 1 for the points of time/values that are included and 0 otherwise. The mask series must have the same resolution as the source series. For this type of task the following is used: R4 = @TRANSFORM(t,s,s,t) DISTRIBUTING VALUES WITH REFERENCE TO PROFILE If you transform from fixed interval resolution to a finer resolution, e.g. from day to hour and want the calculated value to be distributed with reference to a profile, you cannot use standard transformation given from R1. For this type of task the following is used: R6 = @DISTRIBUTE(t,t) R7 = @DISTRIBUTE(t,t,t) R8 = @TRANS_PROFILE(t,t) R9 = @TRANS_PROFILE(t,t,s) R10 = @TRANS_PROFILE(t,t,t) R11 = @TRANS_PROFILE(t,t,t,s) Most of these functions exist in two editions with different use of profile values, relative or absolute.","title":"Which function can be used when"},{"location":"mesh/calculations/functions/transform_what_when/#which-functions-can-be-used-when","text":"Here is a list of common calculations where transformation of values from one resolution to another is included","title":"Which functions can be used when?"},{"location":"mesh/calculations/functions/transform_what_when/#accumulate-values-standard-behavior","text":"This means transforming from a break point series to a fixed interval series, or from a fixed interval series to a different fixed interval series with coarser resolution, for example from hour to day series. For this type of task this is used: R1 = @TRANSFORM(t,s,s)","title":"ACCUMULATE VALUES STANDARD BEHAVIOR"},{"location":"mesh/calculations/functions/transform_what_when/#accumulate-values-to-specific-resolutions","text":"This means transformation from one time series to a different time series with a resolution that is not the same as calendar units, e.g. quarter, hour, day, week, month or year. You can choose a fixed period given from the start of the calculation or more general as points of time on a break point series. For this type of tasks the following are used: R2 = @TRANSFORM(t,t,s) R3 = @TRANSFORM(t,d,s)","title":"ACCUMULATE VALUES TO SPECIFIC RESOLUTIONS"},{"location":"mesh/calculations/functions/transform_what_when/#make-transformation-with-reference-to-time-zone","text":"The calculator performs calculations with reference to normal time if nothing else is given. A normal example is to accumulate hour values to day values or week values using local time (summer time) or a different time zone. For this type of task the following is used: R5 = @TRANSFORM(t,s,s,s)","title":"MAKE TRANSFORMATION WITH REFERENCE TO TIME ZONE"},{"location":"mesh/calculations/functions/transform_what_when/#accumulate-selected-values","text":"Standard accumulation uses all values included in the source period for each single result value, e.g. all values in a day. If you do not wish this, you use a mask series with values equal to 1 for the points of time/values that are included and 0 otherwise. The mask series must have the same resolution as the source series. For this type of task the following is used: R4 = @TRANSFORM(t,s,s,t)","title":"ACCUMULATE SELECTED VALUES"},{"location":"mesh/calculations/functions/transform_what_when/#distributing-values-with-reference-to-profile","text":"If you transform from fixed interval resolution to a finer resolution, e.g. from day to hour and want the calculated value to be distributed with reference to a profile, you cannot use standard transformation given from R1. For this type of task the following is used: R6 = @DISTRIBUTE(t,t) R7 = @DISTRIBUTE(t,t,t) R8 = @TRANS_PROFILE(t,t) R9 = @TRANS_PROFILE(t,t,s) R10 = @TRANS_PROFILE(t,t,t) R11 = @TRANS_PROFILE(t,t,t,s) Most of these functions exist in two editions with different use of profile values, relative or absolute.","title":"DISTRIBUTING VALUES WITH REFERENCE TO PROFILE"},{"location":"mesh/calculations/functions/ts/","text":"TS About the function Creates time series for further use in expressions or as a separate time series. Syntax TS(s[,d]) TS(s,s[,d]) Description TS(s[,d]) # Type Description Example 1 s Unit. 'VARINT', 'MIN15', 'HOUR' etc. 2 d Optional. Value. Description TS(s,s[,d]) # Type Description Example 1 s Unit. 'VARINT', 'MIN15', 'HOUR' etc. 2 s Type of curve. Type of curve is 'NONE', 'STEP' or 'LINEAR'. 3 d Optional. Value. The value is assigned to all points in time. Example @TS(s) TS1 = @TS('VARINT') Time series TS1 is defined as a break point series and is set empty (NaN) as default. @TS(s,d) TS2 = @TS('VARINT',1) Time series TS2 is defined as break point series and get 1 as value. Series with other resolutions: TS3 = @TS('HOUR') Time series TS3 gives an empty time series (NaN) with hourly resolution. TS4 = @TS('HOUR',0) Time series TS4 gives a time series with 0 in all of the hours. Other common resolutions are 'DAY' and 'WEEK'.","title":"TS"},{"location":"mesh/calculations/functions/ts/#ts","text":"","title":"TS"},{"location":"mesh/calculations/functions/ts/#about-the-function","text":"Creates time series for further use in expressions or as a separate time series.","title":"About the function"},{"location":"mesh/calculations/functions/ts/#syntax","text":"TS(s[,d]) TS(s,s[,d]) Description TS(s[,d]) # Type Description Example 1 s Unit. 'VARINT', 'MIN15', 'HOUR' etc. 2 d Optional. Value. Description TS(s,s[,d]) # Type Description Example 1 s Unit. 'VARINT', 'MIN15', 'HOUR' etc. 2 s Type of curve. Type of curve is 'NONE', 'STEP' or 'LINEAR'. 3 d Optional. Value. The value is assigned to all points in time.","title":"Syntax"},{"location":"mesh/calculations/functions/ts/#example","text":"@TS(s) TS1 = @TS('VARINT') Time series TS1 is defined as a break point series and is set empty (NaN) as default. @TS(s,d) TS2 = @TS('VARINT',1) Time series TS2 is defined as break point series and get 1 as value. Series with other resolutions: TS3 = @TS('HOUR') Time series TS3 gives an empty time series (NaN) with hourly resolution. TS4 = @TS('HOUR',0) Time series TS4 gives a time series with 0 in all of the hours. Other common resolutions are 'DAY' and 'WEEK'.","title":"Example"},{"location":"mesh/calculations/functions/ts_acc_from/","text":"TS_ACC_FROM Note! Although Mesh supports this function, we recommend using ACCUMULATE for this purpose where possible. About the function Returns a new, calculated time series. The function calculates the next value based on the previous value (running accumulation) and is used for converting point values to accumulated values. The new time series has the same resolution as the input series. Syntax TS_ACC_FROM(t,t,d,d,d) Calculation yi(t)=yi-1(t)+ Axi+d-1+B Description # Type ## Description 1 t Result series y. The starting value of this series remains unchanged. 2 t Input series x. Contains values which are added to the previous value of the result series. 3 d Linear term A. 4 d Constant term B. 5 d Offset d of point in time: 0: the value is retrieved from the previous time step. 1: the value is retrieved from the current time step. Note! When using Calculator, it is important that you enter this with no assignment to the left side, as follows: @TS_ACC_FROM(##,%Ts,0,1,1) Example Example 1: @TS_ACC_FROM(t,t,d,d,d) @TS_ACC_FROM(%'abo_t3',%'abo_t1',1,0,0) Calculated with the following values: yi-1(t)=abo_t3, xi-+d-1(t) =abo_t1, A=1, B=0. Values from the x-series is taken from the previous time step. Result is shown in column 3 of the table. For instance, the result in row 5 is calculated from values 234+6 i column 1 and 2, row 4. Example 2: @TS_ACC_FROM(t,t,d,d,d) @TS_ACC_FROM>(%'abo_t2',%'abo_t1',1,0,1) Calculated with the following values: yi(t)=abo_t2, xi+d-1(t) =abo_t1, A=1, B=0. Value from the x-series is taken from the current time step. Result is shown in column 5 of the table.","title":"TS_ACC_FROM"},{"location":"mesh/calculations/functions/ts_acc_from/#ts_acc_from","text":"Note! Although Mesh supports this function, we recommend using ACCUMULATE for this purpose where possible.","title":"TS_ACC_FROM"},{"location":"mesh/calculations/functions/ts_acc_from/#about-the-function","text":"Returns a new, calculated time series. The function calculates the next value based on the previous value (running accumulation) and is used for converting point values to accumulated values. The new time series has the same resolution as the input series.","title":"About the function"},{"location":"mesh/calculations/functions/ts_acc_from/#syntax","text":"TS_ACC_FROM(t,t,d,d,d)","title":"Syntax"},{"location":"mesh/calculations/functions/ts_acc_from/#calculation","text":"yi(t)=yi-1(t)+ Axi+d-1+B","title":"Calculation"},{"location":"mesh/calculations/functions/ts_acc_from/#description","text":"# Type ## Description 1 t Result series y. The starting value of this series remains unchanged. 2 t Input series x. Contains values which are added to the previous value of the result series. 3 d Linear term A. 4 d Constant term B. 5 d Offset d of point in time: 0: the value is retrieved from the previous time step. 1: the value is retrieved from the current time step. Note! When using Calculator, it is important that you enter this with no assignment to the left side, as follows: @TS_ACC_FROM(##,%Ts,0,1,1)","title":"Description"},{"location":"mesh/calculations/functions/ts_acc_from/#example","text":"","title":"Example"},{"location":"mesh/calculations/functions/ts_acc_from/#example-1-ts_acc_fromttddd","text":"@TS_ACC_FROM(%'abo_t3',%'abo_t1',1,0,0) Calculated with the following values: yi-1(t)=abo_t3, xi-+d-1(t) =abo_t1, A=1, B=0. Values from the x-series is taken from the previous time step. Result is shown in column 3 of the table. For instance, the result in row 5 is calculated from values 234+6 i column 1 and 2, row 4.","title":"Example 1: @TS_ACC_FROM(t,t,d,d,d)"},{"location":"mesh/calculations/functions/ts_acc_from/#example-2-ts_acc_fromttddd","text":"@TS_ACC_FROM>(%'abo_t2',%'abo_t1',1,0,1) Calculated with the following values: yi(t)=abo_t2, xi+d-1(t) =abo_t1, A=1, B=0. Value from the x-series is taken from the current time step. Result is shown in column 5 of the table.","title":"Example 2: @TS_ACC_FROM(t,t,d,d,d)"},{"location":"mesh/calculations/functions/ts_expand/","text":"TS_EXPAND About the function Replaces empty values in a fixed interval series. If the series has the linear curve type, the function interpolates between real values. Otherwise, the previous real value is used. Syntax TS_EXPAND(t[,s]) TS_EXPAND(t,s[,s]) Description # Type Description 1 t Input time series with a fixed interval with potential missing values (defined as NaN values). 2 s Optional argument where you can specify curve type and potentially override the curve type definition on the input time series. The LINEAR value (case insensitive) gets linear behaviour on expansion. The STEP value, gets step behaviour on expansion. Example 1: @TS_EXPAND(t) Temperature_hour_operative = @TS_EXPAND(@t('Temperature_hour_raw')) Example 2: @TS_EXPAND(t,s) Temperature_hour_operative = @TS_EXPAND(@t('Temperature_hour_raw'),\u2019step\u2019) The original time series has a linear curve type. Description TS_EXPAND(t,s,s) # Type Description 1 t Input time series with potential missing values (defined as NaN values). 2 s Specification of time resolution for the result time series. The same behavior as @TRANSFORM with method FIRST. E.g. \u2018HOUR\u2019, \u2018DAY\u2019 etc. 3 s Optional argument where you can specify curve type and potentially override the curve type definition on the input time series. The LINEAR value (case insensitive) gets linear behaviour on expansion. The STEP value, gets step behaviour on expansion.","title":"TS_EXPAND"},{"location":"mesh/calculations/functions/ts_expand/#ts_expand","text":"","title":"TS_EXPAND"},{"location":"mesh/calculations/functions/ts_expand/#about-the-function","text":"Replaces empty values in a fixed interval series. If the series has the linear curve type, the function interpolates between real values. Otherwise, the previous real value is used.","title":"About the function"},{"location":"mesh/calculations/functions/ts_expand/#syntax","text":"TS_EXPAND(t[,s]) TS_EXPAND(t,s[,s])","title":"Syntax"},{"location":"mesh/calculations/functions/ts_expand/#description","text":"# Type Description 1 t Input time series with a fixed interval with potential missing values (defined as NaN values). 2 s Optional argument where you can specify curve type and potentially override the curve type definition on the input time series. The LINEAR value (case insensitive) gets linear behaviour on expansion. The STEP value, gets step behaviour on expansion. Example 1: @TS_EXPAND(t) Temperature_hour_operative = @TS_EXPAND(@t('Temperature_hour_raw')) Example 2: @TS_EXPAND(t,s) Temperature_hour_operative = @TS_EXPAND(@t('Temperature_hour_raw'),\u2019step\u2019) The original time series has a linear curve type. Description TS_EXPAND(t,s,s) # Type Description 1 t Input time series with potential missing values (defined as NaN values). 2 s Specification of time resolution for the result time series. The same behavior as @TRANSFORM with method FIRST. E.g. \u2018HOUR\u2019, \u2018DAY\u2019 etc. 3 s Optional argument where you can specify curve type and potentially override the curve type definition on the input time series. The LINEAR value (case insensitive) gets linear behaviour on expansion. The STEP value, gets step behaviour on expansion.","title":"Description"},{"location":"mesh/calculations/functions/ts_gliding_average/","text":"TS_GLIDING_AVERAGE About the function Smooths out major fluctuations by taking average values from surrounding values. The amount by which the new values are smoothed out depends on the value of \"d\". \"d\" indicates how many surrounding values should be used to produce the average value, which means the size of the time window. If a smooth curve is required, \"d\" must have a relatively high value. Syntax @TS_GLIDING_AVERAGE(t,d) Description # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. Example Waterlevel_hour_operative = @TS_GLIDING_AVERAGE (@t('Waterlevel_hour_raw'),3) The value for each time step using the gliding interval 3, is calculated by summarizing the previous value, the current value and the next value, divided by 3. Se example:). Selects the time step 01.07.14 05:00: 04:00 = 18.00 05:00 = 17.00 06:00 = 13.00 Res = (18+17+13)/3 = 16","title":"TS_GLIDING_AVERAGE"},{"location":"mesh/calculations/functions/ts_gliding_average/#ts_gliding_average","text":"","title":"TS_GLIDING_AVERAGE"},{"location":"mesh/calculations/functions/ts_gliding_average/#about-the-function","text":"Smooths out major fluctuations by taking average values from surrounding values. The amount by which the new values are smoothed out depends on the value of \"d\". \"d\" indicates how many surrounding values should be used to produce the average value, which means the size of the time window. If a smooth curve is required, \"d\" must have a relatively high value.","title":"About the function"},{"location":"mesh/calculations/functions/ts_gliding_average/#syntax","text":"@TS_GLIDING_AVERAGE(t,d)","title":"Syntax"},{"location":"mesh/calculations/functions/ts_gliding_average/#description","text":"# Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number.","title":"Description"},{"location":"mesh/calculations/functions/ts_gliding_average/#example","text":"Waterlevel_hour_operative = @TS_GLIDING_AVERAGE (@t('Waterlevel_hour_raw'),3) The value for each time step using the gliding interval 3, is calculated by summarizing the previous value, the current value and the next value, divided by 3. Se example:). Selects the time step 01.07.14 05:00: 04:00 = 18.00 05:00 = 17.00 06:00 = 13.00 Res = (18+17+13)/3 = 16","title":"Example"},{"location":"mesh/calculations/functions/ts_gliding_gauss/","text":"TS_GLIDING_GAUSS About the function The values of the time series are normally distributed, d determines the size of the time window. Syntax @TS_GLIDING_GAUSS(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. Example Waterlevel_hour_operative = @TS_GLIDING_GAUSS (@t('Waterlevel_hour_raw'),3) The result is a smoother time series with no major fluctuations, e.g.","title":"TS_GLIDING_GAUSS"},{"location":"mesh/calculations/functions/ts_gliding_gauss/#ts_gliding_gauss","text":"","title":"TS_GLIDING_GAUSS"},{"location":"mesh/calculations/functions/ts_gliding_gauss/#about-the-function","text":"The values of the time series are normally distributed, d determines the size of the time window.","title":"About the function"},{"location":"mesh/calculations/functions/ts_gliding_gauss/#syntax","text":"@TS_GLIDING_GAUSS(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number.","title":"Syntax"},{"location":"mesh/calculations/functions/ts_gliding_gauss/#example","text":"Waterlevel_hour_operative = @TS_GLIDING_GAUSS (@t('Waterlevel_hour_raw'),3) The result is a smoother time series with no major fluctuations, e.g.","title":"Example"},{"location":"mesh/calculations/functions/ts_gliding_median/","text":"TS_GLIDING_MEDIAN About the function Returns a smoothed time series based on calculations of medians. Syntax @TS_GLIDING_MEDIAN(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. Example Waterlevel_hour_operative = @TS_GLIDING_MEDIAN (@t('Waterlevel_hour_raw'),3) With d = 3, the median is calculated with the previous value, current value and next value. For the result time series the median is 19 at 06:00, as the median of the sequence (8, 20, 19) is 19. Using a higher d number the result will get smoother.","title":"TS_GLIDING_MEDIAN"},{"location":"mesh/calculations/functions/ts_gliding_median/#ts_gliding_median","text":"","title":"TS_GLIDING_MEDIAN"},{"location":"mesh/calculations/functions/ts_gliding_median/#about-the-function","text":"Returns a smoothed time series based on calculations of medians.","title":"About the function"},{"location":"mesh/calculations/functions/ts_gliding_median/#syntax","text":"@TS_GLIDING_MEDIAN(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number.","title":"Syntax"},{"location":"mesh/calculations/functions/ts_gliding_median/#example","text":"Waterlevel_hour_operative = @TS_GLIDING_MEDIAN (@t('Waterlevel_hour_raw'),3) With d = 3, the median is calculated with the previous value, current value and next value. For the result time series the median is 19 at 06:00, as the median of the sequence (8, 20, 19) is 19. Using a higher d number the result will get smoother.","title":"Example"},{"location":"mesh/calculations/functions/ts_gliding_median_gauss/","text":"TS_GLIDING_MEDIAN_GAUSS About the function This function first calculates the median and then normally distributes the median values. d determines the size of the time window. Syntax @ TS_GLIDING_MEDIAN_GAUSS(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number. Example Waterlevel_hour_operative = @TS_GLIDING_MEDIAN (@t('Waterlevel_hour_raw'),3) With d = 3, the median is calculated with the previous value, current value and next value and then normally distributed.","title":"TS_GLIDING_MEDIAN_GAUSS"},{"location":"mesh/calculations/functions/ts_gliding_median_gauss/#ts_gliding_median_gauss","text":"","title":"TS_GLIDING_MEDIAN_GAUSS"},{"location":"mesh/calculations/functions/ts_gliding_median_gauss/#about-the-function","text":"This function first calculates the median and then normally distributes the median values. d determines the size of the time window.","title":"About the function"},{"location":"mesh/calculations/functions/ts_gliding_median_gauss/#syntax","text":"@ TS_GLIDING_MEDIAN_GAUSS(t,d) # Type Description 1 t Time series of numerical values. 2 d Numerical value. Indicates how many surrounding values that are used to produce the average value. d must be an uneven number.","title":"Syntax"},{"location":"mesh/calculations/functions/ts_gliding_median_gauss/#example","text":"Waterlevel_hour_operative = @TS_GLIDING_MEDIAN (@t('Waterlevel_hour_raw'),3) With d = 3, the median is calculated with the previous value, current value and next value and then normally distributed.","title":"Example"},{"location":"mesh/calculations/functions/ts_offset/","text":"TS_OFFSET About the function This function time-shifts a time series, i.e. uses values from a period which is different from the current calculation period. The result series has the same resolution as the input time series. Syntax TS_OFFSET(t,d[,s]) Description TS_OFFSET(t,d,[s]) is used relative to current period. # Type Description Example 1 t Series from which you have to retrieve values. 2 d Offset in hours or the unit as specified in argument 3. 3 s Offset unit code. Default value hours. 'DAY' The table below shows the valid offset unit codes. Additionally, the unit codes can be combined with a zone code, representing the local time, standard time, UTC time and database time. For instance LOCALDAY. Note! LOCAL can only be combined with time unit DAY or coarser. UNIT code MIN15 HOUR DAY WEEK MONTH YEAR LOCAL STANDARD UTC DB Example Example 1: @TS_OFFSET(t,d) CompareTemp = @TS_OFFSET(@t('AreaTemperature'),-2) The values of AreaTemp are time-shifted. \"d\" determines the number of time intervals by which the time series is to be shifted. We can see that the result moves backwards in time for negative numbers. Example 2: @TS_OFFSET(t,d) CompareTemp = @TS_OFFSET(@t('AreaTemperature'),3) The values of AreaTemp are time-shifted. \"d\" determines the number of time intervals by which the time series is to be shifted. We can see that the result moves forward in time for positive numbers.","title":"TS_OFFSET"},{"location":"mesh/calculations/functions/ts_offset/#ts_offset","text":"","title":"TS_OFFSET"},{"location":"mesh/calculations/functions/ts_offset/#about-the-function","text":"This function time-shifts a time series, i.e. uses values from a period which is different from the current calculation period. The result series has the same resolution as the input time series.","title":"About the function"},{"location":"mesh/calculations/functions/ts_offset/#syntax","text":"TS_OFFSET(t,d[,s])","title":"Syntax"},{"location":"mesh/calculations/functions/ts_offset/#description","text":"TS_OFFSET(t,d,[s]) is used relative to current period. # Type Description Example 1 t Series from which you have to retrieve values. 2 d Offset in hours or the unit as specified in argument 3. 3 s Offset unit code. Default value hours. 'DAY' The table below shows the valid offset unit codes. Additionally, the unit codes can be combined with a zone code, representing the local time, standard time, UTC time and database time. For instance LOCALDAY. Note! LOCAL can only be combined with time unit DAY or coarser. UNIT code MIN15 HOUR DAY WEEK MONTH YEAR LOCAL STANDARD UTC DB Example Example 1: @TS_OFFSET(t,d) CompareTemp = @TS_OFFSET(@t('AreaTemperature'),-2) The values of AreaTemp are time-shifted. \"d\" determines the number of time intervals by which the time series is to be shifted. We can see that the result moves backwards in time for negative numbers. Example 2: @TS_OFFSET(t,d) CompareTemp = @TS_OFFSET(@t('AreaTemperature'),3) The values of AreaTemp are time-shifted. \"d\" determines the number of time intervals by which the time series is to be shifted. We can see that the result moves forward in time for positive numbers.","title":"Description"},{"location":"mesh/calculations/functions/tsiqfill/","text":"TS_IQ-FILL About the function Places logical values in any empty fields in a time series by taking the average of the previous and following values in the time series. The result series has the same resolution as the time series/argument series. Values created by this function gets the status \"Suspect\" (S). Syntax TS_IQ_FILL(t) Description The function TS_IQ_FILL considers the properties of the time series in the argument. Type Step: the previous value is filled in the empty cells on to the next value. Type Linear: the value between the points in time follows linear development from value at time [t] til time [t+1]. If the first cell(s) is empty, the next value is copied. If the last cell(s) is empty, the previous values is copied. Example Example 1: @TS_IQ_FILL(t) step Result = @TS_IQ_FILL(%'TS10S') Finds the first value in the first row. The value 5,00 is filled into the empty space preceding the next value, 10,00. See table. Example 2: @TS_IQ_FILL(t) linear Result = @TS_IQ_FILL(%'TS10L') The values are filled in accordance with linear development. For instance in row 2 for TS10L: Difference between the nearest values 10,00-5,00 = 5,00 Number of steps between row 6 and row 1: 5 Increment: 5.00/5 = 1.00 New value by adding the increment: 5.00+1.00 = 6.00 in row 3. See table. Following the last value of the series the result is equal for both editions, the last value is kept.","title":"TS_IQ-FILL"},{"location":"mesh/calculations/functions/tsiqfill/#ts_iq-fill","text":"","title":"TS_IQ-FILL"},{"location":"mesh/calculations/functions/tsiqfill/#about-the-function","text":"Places logical values in any empty fields in a time series by taking the average of the previous and following values in the time series. The result series has the same resolution as the time series/argument series. Values created by this function gets the status \"Suspect\" (S).","title":"About the function"},{"location":"mesh/calculations/functions/tsiqfill/#syntax","text":"TS_IQ_FILL(t)","title":"Syntax"},{"location":"mesh/calculations/functions/tsiqfill/#description","text":"The function TS_IQ_FILL considers the properties of the time series in the argument. Type Step: the previous value is filled in the empty cells on to the next value. Type Linear: the value between the points in time follows linear development from value at time [t] til time [t+1]. If the first cell(s) is empty, the next value is copied. If the last cell(s) is empty, the previous values is copied.","title":"Description"},{"location":"mesh/calculations/functions/tsiqfill/#example","text":"Example 1: @TS_IQ_FILL(t) step Result = @TS_IQ_FILL(%'TS10S') Finds the first value in the first row. The value 5,00 is filled into the empty space preceding the next value, 10,00. See table. Example 2: @TS_IQ_FILL(t) linear Result = @TS_IQ_FILL(%'TS10L') The values are filled in accordance with linear development. For instance in row 2 for TS10L: Difference between the nearest values 10,00-5,00 = 5,00 Number of steps between row 6 and row 1: 5 Increment: 5.00/5 = 1.00 New value by adding the increment: 5.00+1.00 = 6.00 in row 3. See table. Following the last value of the series the result is equal for both editions, the last value is kept.","title":"Example"},{"location":"mesh/calculations/functions/unit_codes_for_set_ts_val_unit/","text":"Unit codes for SET_TS_VALUNIT In this table you can find unit codes for time series that are set using the SET_TS_VALUNIT function. Unit code (unme_key) name of the unit (code) description (descript) -32767 None Non-denoted size. Must not be confused with UNDEF_UNMEA. 0 Undefined Undefined 100 m3 Cubic meters 101 Mm3 Million cubic meters 102 Meter Meter 103 Percent Percent 104 MW Mega watt 105 GWh Giga watt hours 106 MWh Mega watt hours 107 Wh Watt hours 108 m3/sec Cubic meters/second 109 l/sec Liters / second 110 l/sec/km2 Liters/second/square-kilometer 111 m2 Square-meter 112 km2 Square-kilometer 113 Degrees Degrees 0-360 114 Degrees C. Degrees Celsius 115 Kilogram Veight in kilogram 116 Pascal Pascal 117 Volt Volt 118 Ampere Ampere 119 W/m2 Watt / square-meters 120 m/sec Meter / second 121 S/M Conductivity (s/m) 122 mg/l Milligram / liter 123 kg/s Kilogram / sekund 124 Millimeter Millimeter 125 kW/meter Kilo watt / meter 126 Nor crowns Norwegian crowns 127 Mill NOK NOK 1 000 000 . 128 NOK/MWh NOK/MWh 129 MWh/h Megawatt hours/hour 130 Milligram Milligram 131 cm Centimeter 132 % of max Percent of max 133 % of norm Percent of normal value 140 kWh/h Kilo watt hours/hour 141 USD/MWh USD/MWh 142 USD US dollar 200 MW/MJ/S MW per heatunit 201 Tons Tons 203 Tons/hour Tons per hour 204 NM3 NM3 205 GJ Giga Joule 206 PU Per Unit 207 NM3/h NM3/hour 208 GJ/h Giga Joule/hour 210 Bar Pressure 211 mBar Air pressure in millibar 212 hPa Air pressure in hektopascal 213 RPM Rotations per minute 800 kWh Kilo watt hours 810 C / 100m Degrees Celsius per 100 meter 811 Hours Number of hours 820 Hz Hertz 821 MVA Mega volt Ampere 822 MVAr MVA reactive effect 823 MVArh MVA reactive energy 824 MVArh/h MVA reactive effect 825 MW/Hz Degree of regulation 826 kVAr kVA reactive effect 827 kVArh kVA reactive energy 828 kVArh/h kVA reactive effect 829 kPa Kilo Pascal 830 m3/h Cubic meters/hour 831 SEK/MWh SEK per MWh 832 MWh/C MWh per degree Celsius 833 Degrees F. Degrees Fahrenheit 834 kV Kilo volt 835 kW Kilo Watt 836 W Watt 837 CZK/MWh CZK/MWh 838 PLZ/MWh PLZ/MWh 839 EUR/MWh EUR/MWh 840 DKK/MWh DKK/MWh 841 RUR/MWh RUR/MWh 842 DKK/GJ DKK/GJ 843 EUA EU Allowances volume 844 EUR/EUA EUR per Allowances volume 845 CZK/EUA CZK per Allowances volume 846 MW/MW Fuel Ratio 847 l/h Liters per hour 848 l Liters 849 mm/h Millimeter per hour 850 MJ/Sm3 Megajoule per cubic meter 851 kWh/Sm3 Kilo watt hours per cubic meter 852 kg/Sm3 Kilogram per cubic meter 853 mol% Water content in gas in percent 999 TS/sec # Times series per second 1000 NOK NOK 1001 SEK SEK 1002 DKK DEK 1003 FIM FIM 1004 DEM DEM 1005 RUR RUR 1006 NLG NLG 1007 CZK Czech koruna 1008 PLN Poland zloty 1999 EUR Euro","title":"Unit Codes for Set_Ts_Valunit"},{"location":"mesh/calculations/functions/unit_codes_for_set_ts_val_unit/#unit-codes-for-set_ts_valunit","text":"In this table you can find unit codes for time series that are set using the SET_TS_VALUNIT function. Unit code (unme_key) name of the unit (code) description (descript) -32767 None Non-denoted size. Must not be confused with UNDEF_UNMEA. 0 Undefined Undefined 100 m3 Cubic meters 101 Mm3 Million cubic meters 102 Meter Meter 103 Percent Percent 104 MW Mega watt 105 GWh Giga watt hours 106 MWh Mega watt hours 107 Wh Watt hours 108 m3/sec Cubic meters/second 109 l/sec Liters / second 110 l/sec/km2 Liters/second/square-kilometer 111 m2 Square-meter 112 km2 Square-kilometer 113 Degrees Degrees 0-360 114 Degrees C. Degrees Celsius 115 Kilogram Veight in kilogram 116 Pascal Pascal 117 Volt Volt 118 Ampere Ampere 119 W/m2 Watt / square-meters 120 m/sec Meter / second 121 S/M Conductivity (s/m) 122 mg/l Milligram / liter 123 kg/s Kilogram / sekund 124 Millimeter Millimeter 125 kW/meter Kilo watt / meter 126 Nor crowns Norwegian crowns 127 Mill NOK NOK 1 000 000 . 128 NOK/MWh NOK/MWh 129 MWh/h Megawatt hours/hour 130 Milligram Milligram 131 cm Centimeter 132 % of max Percent of max 133 % of norm Percent of normal value 140 kWh/h Kilo watt hours/hour 141 USD/MWh USD/MWh 142 USD US dollar 200 MW/MJ/S MW per heatunit 201 Tons Tons 203 Tons/hour Tons per hour 204 NM3 NM3 205 GJ Giga Joule 206 PU Per Unit 207 NM3/h NM3/hour 208 GJ/h Giga Joule/hour 210 Bar Pressure 211 mBar Air pressure in millibar 212 hPa Air pressure in hektopascal 213 RPM Rotations per minute 800 kWh Kilo watt hours 810 C / 100m Degrees Celsius per 100 meter 811 Hours Number of hours 820 Hz Hertz 821 MVA Mega volt Ampere 822 MVAr MVA reactive effect 823 MVArh MVA reactive energy 824 MVArh/h MVA reactive effect 825 MW/Hz Degree of regulation 826 kVAr kVA reactive effect 827 kVArh kVA reactive energy 828 kVArh/h kVA reactive effect 829 kPa Kilo Pascal 830 m3/h Cubic meters/hour 831 SEK/MWh SEK per MWh 832 MWh/C MWh per degree Celsius 833 Degrees F. Degrees Fahrenheit 834 kV Kilo volt 835 kW Kilo Watt 836 W Watt 837 CZK/MWh CZK/MWh 838 PLZ/MWh PLZ/MWh 839 EUR/MWh EUR/MWh 840 DKK/MWh DKK/MWh 841 RUR/MWh RUR/MWh 842 DKK/GJ DKK/GJ 843 EUA EU Allowances volume 844 EUR/EUA EUR per Allowances volume 845 CZK/EUA CZK per Allowances volume 846 MW/MW Fuel Ratio 847 l/h Liters per hour 848 l Liters 849 mm/h Millimeter per hour 850 MJ/Sm3 Megajoule per cubic meter 851 kWh/Sm3 Kilo watt hours per cubic meter 852 kg/Sm3 Kilogram per cubic meter 853 mol% Water content in gas in percent 999 TS/sec # Times series per second 1000 NOK NOK 1001 SEK SEK 1002 DKK DEK 1003 FIM FIM 1004 DEM DEM 1005 RUR RUR 1006 NLG NLG 1007 CZK Czech koruna 1008 PLN Poland zloty 1999 EUR Euro","title":"Unit codes for SET_TS_VALUNIT"},{"location":"mesh/calculations/functions/valid/","text":"Valid About the function A time series reference specified by @t(\u2018TheReference\u2019) may give no result. The reason for this may be one of the following: TheReference does not exist. There is no connection to a physical time series from the current context. In these cases the system will display a warning message. The warning message tells the user it did not manage to resolve TheReference for a given object. You may use either IsValid or Valid to handle these cases. Syntax IsValid(t) Syntax Valid(T) Description Type Description t Array of source time series, where each of them is normally the result of a @t(\u2018TheReference\u2019). The function returns an array of valid time series.","title":"Valid"},{"location":"mesh/calculations/functions/valid/#valid","text":"","title":"Valid"},{"location":"mesh/calculations/functions/valid/#about-the-function","text":"A time series reference specified by @t(\u2018TheReference\u2019) may give no result. The reason for this may be one of the following: TheReference does not exist. There is no connection to a physical time series from the current context. In these cases the system will display a warning message. The warning message tells the user it did not manage to resolve TheReference for a given object. You may use either IsValid or Valid to handle these cases.","title":"About the function"},{"location":"mesh/calculations/functions/valid/#syntax","text":"IsValid(t)","title":"Syntax"},{"location":"mesh/calculations/functions/valid/#syntax_1","text":"Valid(T)","title":"Syntax"},{"location":"mesh/calculations/functions/valid/#description","text":"Type Description t Array of source time series, where each of them is normally the result of a @t(\u2018TheReference\u2019). The function returns an array of valid time series.","title":"Description"},{"location":"mesh/calculations/functions/validate_abs_limit/","text":"ValidateAbsLimit About the function Validates time series using absolute limits. Values outside the specified limits, are marked with ! (Not Ok). Values with control towards upper or lower limit are set to validated and marked with V01 , meaning validation method 1. You can see this code if you turn on value information in Nimbus. Syntax ValidateAbsLimit(t,t|d,t|d) Description # Type Description 1 t Time series to validate. 2 t d Time series for lower limit. Numerical value for lower limit. 3 t d Time series for upper limit. Numerical value for lower limit. Example 1 Waterlevel_hour_VEE = @ValidateAbsLimit(@t('Waterlevel_hour_raw'),@t('RsvLowerLimitProfile'),@t('RsvUpperLimitProfile')) This example validates the input time series against lower and upper limit time series. If the limit time series have a repetitive frequency, you can use the PROFILE function to repeat values from a given period and resolution. Example 2 RsvLowerLimitProfile = @PROFILE(@t('RsvLowerLimit'),'YEAR') @t('RsvLowerLimit') is a breakpoint time series with monthly values. You can also use a vector of numbers and use the TIME_MASK function to place the values right in time. Example 3 LowerLimit = @TIME_MASK('YEAR',{'YEAR','YEAR+1m','YEAR+2m','YEAR+3m','YEAR+4m','YEAR+5m','YEAR+6m','YEAR+7m','YEAR+8m','YEAR+9m','YEAR+10m','YEAR+11m'},@D('RsvLowerLimitMonthly'),'VARINT') If the lower and upper limits are constant, you can use the function syntax @ValidateAbsLimit(t,d,d). Example 4 Waterlevel_hour_VEE = @ValidateAbsLimit(@RESET_STATUS(@t('Waterlevel_hour_raw')),207,210) In this example, all existing statuses on the input data series are removed before the function adds its status values. This is done using the RESET_STATUS function on the input data series. All values outside the upper level value 210 or the lower limit value 207, are marked with ! (Not OK) and the validation method V01 .","title":"ValidateAbsLimit"},{"location":"mesh/calculations/functions/validate_abs_limit/#validateabslimit","text":"About the function Validates time series using absolute limits. Values outside the specified limits, are marked with ! (Not Ok). Values with control towards upper or lower limit are set to validated and marked with V01 , meaning validation method 1. You can see this code if you turn on value information in Nimbus. Syntax ValidateAbsLimit(t,t|d,t|d)","title":"ValidateAbsLimit"},{"location":"mesh/calculations/functions/validate_abs_limit/#description","text":"# Type Description 1 t Time series to validate. 2 t d Time series for lower limit. Numerical value for lower limit. 3 t d Time series for upper limit. Numerical value for lower limit. Example 1 Waterlevel_hour_VEE = @ValidateAbsLimit(@t('Waterlevel_hour_raw'),@t('RsvLowerLimitProfile'),@t('RsvUpperLimitProfile')) This example validates the input time series against lower and upper limit time series. If the limit time series have a repetitive frequency, you can use the PROFILE function to repeat values from a given period and resolution. Example 2 RsvLowerLimitProfile = @PROFILE(@t('RsvLowerLimit'),'YEAR') @t('RsvLowerLimit') is a breakpoint time series with monthly values. You can also use a vector of numbers and use the TIME_MASK function to place the values right in time. Example 3 LowerLimit = @TIME_MASK('YEAR',{'YEAR','YEAR+1m','YEAR+2m','YEAR+3m','YEAR+4m','YEAR+5m','YEAR+6m','YEAR+7m','YEAR+8m','YEAR+9m','YEAR+10m','YEAR+11m'},@D('RsvLowerLimitMonthly'),'VARINT') If the lower and upper limits are constant, you can use the function syntax @ValidateAbsLimit(t,d,d). Example 4 Waterlevel_hour_VEE = @ValidateAbsLimit(@RESET_STATUS(@t('Waterlevel_hour_raw')),207,210) In this example, all existing statuses on the input data series are removed before the function adds its status values. This is done using the RESET_STATUS function on the input data series. All values outside the upper level value 210 or the lower limit value 207, are marked with ! (Not OK) and the validation method V01 .","title":"Description"},{"location":"mesh/calculations/functions/validate_delta_limit/","text":"ValidateDeltaLimit About the function Validates time series using delta change limits. Values outside the specified limits, will be marked as ! (Not OK). Values with control towards delta limit are set to validated with remark V02, meaning validation method 2. You can see this code if you turn on value information in Nimbus. Syntax ValidateDeltaLimit(t,t,t,d,s) Description # Type Description 1 t Time series to validate. 2 t Time series for delta lower limit. 3 t Time series for delta upper limit. 4 d Value describing maximum number of errors. When maximum number of errors has been reached, subsequent values will not be validated. 5 s Symbol describing whether or not limitation time series are to be interpreted as percentage values. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @ValidateDeltaLimit(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('RsvDeltaLimitLower')),@TS('VARINT',@d('RsvDeltaLimitUpper')), @d('ValidateMaxErrors'), @s('ValuesInPercent')) This example validates the time series using limits described in the time series @TS('VARINT',@d('RsvDeltaLimitLower')) and @TS('VARINT',@d('RsvDeltaLimitUpper')). These are time series created from attribute values on the specific object. The maximum number of errors, @d('ValidateMaxErrors'), also refers to an attribute value on the specific object. When the number of errors reaches the actual value, no more validation are done. Values are not interpreted as percentage values if the attribute on the specific object @s('ValuesInPercent') is set to FALSE. In the screen example, all existing statuses on the input data series are removed before the function adds its status values. This is done using the RESET_STATUS function on the input data series. The RsvDeltaLimitLower attribute is set to -0.05 and RsvDeltaLimitUpper is set to 0.05. The values are not in percent. All values outside exceeding the delta limits, are marked with ! (Not OK) and the validation method V02 .","title":"ValidateDeltaLimit"},{"location":"mesh/calculations/functions/validate_delta_limit/#validatedeltalimit","text":"About the function Validates time series using delta change limits. Values outside the specified limits, will be marked as ! (Not OK). Values with control towards delta limit are set to validated with remark V02, meaning validation method 2. You can see this code if you turn on value information in Nimbus. Syntax ValidateDeltaLimit(t,t,t,d,s)","title":"ValidateDeltaLimit"},{"location":"mesh/calculations/functions/validate_delta_limit/#description","text":"# Type Description 1 t Time series to validate. 2 t Time series for delta lower limit. 3 t Time series for delta upper limit. 4 d Value describing maximum number of errors. When maximum number of errors has been reached, subsequent values will not be validated. 5 s Symbol describing whether or not limitation time series are to be interpreted as percentage values. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @ValidateDeltaLimit(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('RsvDeltaLimitLower')),@TS('VARINT',@d('RsvDeltaLimitUpper')), @d('ValidateMaxErrors'), @s('ValuesInPercent')) This example validates the time series using limits described in the time series @TS('VARINT',@d('RsvDeltaLimitLower')) and @TS('VARINT',@d('RsvDeltaLimitUpper')). These are time series created from attribute values on the specific object. The maximum number of errors, @d('ValidateMaxErrors'), also refers to an attribute value on the specific object. When the number of errors reaches the actual value, no more validation are done. Values are not interpreted as percentage values if the attribute on the specific object @s('ValuesInPercent') is set to FALSE. In the screen example, all existing statuses on the input data series are removed before the function adds its status values. This is done using the RESET_STATUS function on the input data series. The RsvDeltaLimitLower attribute is set to -0.05 and RsvDeltaLimitUpper is set to 0.05. The values are not in percent. All values outside exceeding the delta limits, are marked with ! (Not OK) and the validation method V02 .","title":"Description"},{"location":"mesh/calculations/functions/validate_delta_limit_extreme/","text":"ValidateDeltaLimitExtreme About the function ValidateDeltaLimitExtreme is similar to ValidateDeltaLimit , but also validates using extreme limits. Values outside the specified limits, are marked with ! (Not OK). Values with control towards delta limit extreme are set to validated with remark V03 , meaning validation method 3. You can see this code if you turn on value information in Nimbus. Syntax ValidateDeltaLimitExtreme(t,t,t,t,s) Description # Type Description 1 t Time series to validate. 2 t Time series for delta lower limit. 3 t Time series for delta upper limit. 4 t Time series for extreme limit. 5 s Symbol describing whether or not values on limitation time series should be interpreted as percentage values. This is specified as either 'TRUE' or 'FALSE'. Example Waterlevel_hour_VEE = @ValidateDeltaLimitExtreme(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('RsvDeltaLimitLower')),@TS('VARINT',@d('RsvDeltaLimitUpper')), @t('RsvExtremeLimit'), @s('ValuesInPercent')) This example validates the time series using limits described in the time series @TS('VARINT',@d('RsvDeltaLimitLower')) and @TS('VARINT',@d('RsvDeltaLimitUpper')). These are time series created from attribute values on the specific object. Extreme limits are described in the @t('RsvExtremeLimit') time series. Values are not interpreted as percentage values if the attribute on the specific object @s('ValuesInPercent') is set to FALSE.","title":"ValidateDeltaLimitExtreme"},{"location":"mesh/calculations/functions/validate_delta_limit_extreme/#validatedeltalimitextreme","text":"About the function ValidateDeltaLimitExtreme is similar to ValidateDeltaLimit , but also validates using extreme limits. Values outside the specified limits, are marked with ! (Not OK). Values with control towards delta limit extreme are set to validated with remark V03 , meaning validation method 3. You can see this code if you turn on value information in Nimbus.","title":"ValidateDeltaLimitExtreme"},{"location":"mesh/calculations/functions/validate_delta_limit_extreme/#syntax","text":"ValidateDeltaLimitExtreme(t,t,t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/validate_delta_limit_extreme/#description","text":"# Type Description 1 t Time series to validate. 2 t Time series for delta lower limit. 3 t Time series for delta upper limit. 4 t Time series for extreme limit. 5 s Symbol describing whether or not values on limitation time series should be interpreted as percentage values. This is specified as either 'TRUE' or 'FALSE'.","title":"Description"},{"location":"mesh/calculations/functions/validate_delta_limit_extreme/#example","text":"Waterlevel_hour_VEE = @ValidateDeltaLimitExtreme(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('RsvDeltaLimitLower')),@TS('VARINT',@d('RsvDeltaLimitUpper')), @t('RsvExtremeLimit'), @s('ValuesInPercent')) This example validates the time series using limits described in the time series @TS('VARINT',@d('RsvDeltaLimitLower')) and @TS('VARINT',@d('RsvDeltaLimitUpper')). These are time series created from attribute values on the specific object. Extreme limits are described in the @t('RsvExtremeLimit') time series. Values are not interpreted as percentage values if the attribute on the specific object @s('ValuesInPercent') is set to FALSE.","title":"Example"},{"location":"mesh/calculations/functions/validate_repeat_value/","text":"ValidateRepeatValue About the function This function validates time series based on repetition frequency. Values repeated too often, are marked with ! (Not OK). Values with control towards repeated values are set to validated and marked with V04 , meaning validation method 4. You can see this code if you turn on value information in Nimbus. Syntax ValidateRepeatValue(t,t,d,d) Description # Type Description 1 t Time series to be validated. 2 t Time series describing maximum number of repeated values. 3 d Value describing delta used when comparing values. 4 d Value that is considered as an exception to the rule. Example Waterlevel_hour_VEE = @ValidateRepeatValue(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('ValidateMaxRepeatedValues')),@d('ValidateDeltaValues'),@d('ValidateExceptionValues')) This example validates the time series using repetitions described in the time series @TS('VARINT',@d('ValidateMaxRepeatedValues')), which is a time series created from the attribute value, @d('ValidateMaxRepeatedValues'), on the specific object. The delta used when comparing the values, @d('ValidateMaxErrors'), and the value that is considered an exception to the rule, @d('ValidateExceptionValues'), are also defined as attributes on the specific object. This example validates the time series using repetitions described in the time series @TS('VARINT',@d('ValidateMaxRepeatedValues')). The delta used when comparing the values is set to 0.01 and the value 0.0 is considered correct no matter how many times it is repeated.","title":"ValidateRepeatValue"},{"location":"mesh/calculations/functions/validate_repeat_value/#validaterepeatvalue","text":"About the function This function validates time series based on repetition frequency. Values repeated too often, are marked with ! (Not OK). Values with control towards repeated values are set to validated and marked with V04 , meaning validation method 4. You can see this code if you turn on value information in Nimbus. Syntax ValidateRepeatValue(t,t,d,d)","title":"ValidateRepeatValue"},{"location":"mesh/calculations/functions/validate_repeat_value/#description","text":"# Type Description 1 t Time series to be validated. 2 t Time series describing maximum number of repeated values. 3 d Value describing delta used when comparing values. 4 d Value that is considered as an exception to the rule.","title":"Description"},{"location":"mesh/calculations/functions/validate_repeat_value/#example","text":"Waterlevel_hour_VEE = @ValidateRepeatValue(@RESET_STATUS(@t('Waterlevel_hour_raw')),@TS('VARINT',@d('ValidateMaxRepeatedValues')),@d('ValidateDeltaValues'),@d('ValidateExceptionValues')) This example validates the time series using repetitions described in the time series @TS('VARINT',@d('ValidateMaxRepeatedValues')), which is a time series created from the attribute value, @d('ValidateMaxRepeatedValues'), on the specific object. The delta used when comparing the values, @d('ValidateMaxErrors'), and the value that is considered an exception to the rule, @d('ValidateExceptionValues'), are also defined as attributes on the specific object. This example validates the time series using repetitions described in the time series @TS('VARINT',@d('ValidateMaxRepeatedValues')). The delta used when comparing the values is set to 0.01 and the value 0.0 is considered correct no matter how many times it is repeated.","title":"Example"},{"location":"mesh/calculations/functions/values_from_year/","text":"ValuesFromYear About the function Gets values from a specified year on input series and places them into the requested period. Syntax ValuesFromYear(t,d) Description # Type Description Example 1 t Source time series. 2 d Year as a four digit number. Standard DB calendar is used to map year number into time period. 2000 Example CompareTemp = @ValuesFromYear(@t('AreaTemperature'),2000)","title":"ValuesFromYear"},{"location":"mesh/calculations/functions/values_from_year/#valuesfromyear","text":"","title":"ValuesFromYear"},{"location":"mesh/calculations/functions/values_from_year/#about-the-function","text":"Gets values from a specified year on input series and places them into the requested period.","title":"About the function"},{"location":"mesh/calculations/functions/values_from_year/#syntax","text":"ValuesFromYear(t,d)","title":"Syntax"},{"location":"mesh/calculations/functions/values_from_year/#description","text":"# Type Description Example 1 t Source time series. 2 d Year as a four digit number. Standard DB calendar is used to map year number into time period. 2000 Example CompareTemp = @ValuesFromYear(@t('AreaTemperature'),2000)","title":"Description"},{"location":"mesh/calculations/functions/xy/","text":"XY About the function Combines an XY definition and an X series to produce the corresponding Y result. Syntax XY(t,s) Description # Type Description 1 t Source time series for the X values. 2 s Search string for the XY attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be .TheXYAttribute (assuming the name of this attribute is TheXYAttribute). The dot (.) limits the search operation to local attributes on current object. Parent object, the argument should be \u2026TheXYAttribute. The two first dots means go to the parent, and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"XY"},{"location":"mesh/calculations/functions/xy/#xy","text":"","title":"XY"},{"location":"mesh/calculations/functions/xy/#about-the-function","text":"Combines an XY definition and an X series to produce the corresponding Y result.","title":"About the function"},{"location":"mesh/calculations/functions/xy/#syntax","text":"XY(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/xy/#description","text":"# Type Description 1 t Source time series for the X values. 2 s Search string for the XY attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be .TheXYAttribute (assuming the name of this attribute is TheXYAttribute). The dot (.) limits the search operation to local attributes on current object. Parent object, the argument should be \u2026TheXYAttribute. The two first dots means go to the parent, and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"Description"},{"location":"mesh/calculations/functions/yx/","text":"YX About the function Combines an XY definition and a Y series to produce the corresponding X result. Syntax YX(t,s) Description # Type Description 1 t Source time series for the Y values. 2 s Search string for the XY attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be .TheXYAttribute (assuming the name of this attribute is TheXYAttribute). The dot (.) limits the search operation to local attributes on current object. Parent object, the argument should be \u2026TheXYAttribute. The two first dots means go to the parent, and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"YX"},{"location":"mesh/calculations/functions/yx/#yx","text":"","title":"YX"},{"location":"mesh/calculations/functions/yx/#about-the-function","text":"Combines an XY definition and a Y series to produce the corresponding X result.","title":"About the function"},{"location":"mesh/calculations/functions/yx/#syntax","text":"YX(t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/yx/#description","text":"# Type Description 1 t Source time series for the Y values. 2 s Search string for the XY attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be .TheXYAttribute (assuming the name of this attribute is TheXYAttribute). The dot (.) limits the search operation to local attributes on current object. Parent object, the argument should be \u2026TheXYAttribute. The two first dots means go to the parent, and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"Description"},{"location":"mesh/calculations/functions/zxy/","text":"ZX_Y About the function Gets the result Y from an XYZ-attribute with input series Z and X. An XYZ-attribute is a table in three dimensions defined on a Mesh object, e.g. a gate capacity table. Syntax ZX_Y(t,t,s) Description # Type Description 1 t Source time series for the Z values. 2 t Source time series for the X values. 3 s Search string for the XYZ attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be \u2018.TheXYZAttribute\u2019 (assuming the name of this attribute is TheXYZAttribute). The dot (.) limits the search operation to local attributes on the current object. Parent object, the argument should be \u2018\u2026TheXYZAttribute\u2019. The two first dots means go to the parent and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator. Example This function returns the gate discharge: ## = @ZX_Y(@t(\u2018.gate_opening\u2019), @t(\u2018.reservoir_level\u2019),\u2019.gate_capacity_table\u2019)","title":"ZX_Y"},{"location":"mesh/calculations/functions/zxy/#zx_y","text":"About the function Gets the result Y from an XYZ-attribute with input series Z and X. An XYZ-attribute is a table in three dimensions defined on a Mesh object, e.g. a gate capacity table.","title":"ZX_Y"},{"location":"mesh/calculations/functions/zxy/#syntax","text":"ZX_Y(t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/zxy/#description","text":"# Type Description 1 t Source time series for the Z values. 2 t Source time series for the X values. 3 s Search string for the XYZ attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be \u2018.TheXYZAttribute\u2019 (assuming the name of this attribute is TheXYZAttribute). The dot (.) limits the search operation to local attributes on the current object. Parent object, the argument should be \u2018\u2026TheXYZAttribute\u2019. The two first dots means go to the parent and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"Description"},{"location":"mesh/calculations/functions/zxy/#example","text":"This function returns the gate discharge: ## = @ZX_Y(@t(\u2018.gate_opening\u2019), @t(\u2018.reservoir_level\u2019),\u2019.gate_capacity_table\u2019)","title":"Example"},{"location":"mesh/calculations/functions/zyx/","text":"ZY_X About the function Gets the result X from an XYZ-attribute with input series Z and Y. An XYZ-attribute is a table in three dimensions defined on a Mesh object, e.g. a gate capacity table. Syntax ZY_X(t,t,s) Description # Type Description 1 t Source time series for the Z values. 2 t Source time series for the Y values. 3 s Search string for the XYZ attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be \u2018.TheXYZAttribute\u2019 (assuming the name of this attribute is TheXYZAttribute). The dot (.) limits the search operation to local attributes on the current object. Parent object, the argument should be \u2018\u2026TheXYZAttribute\u2019. The two first dots means go to the parent and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator. Example This function returns the reservoir level: ## = @ZY_X(@t(\u2018.gate_opening\u2019), @t(\u2018.gate_discharge\u2019),\u2019.gate_capacity_table\u2019)","title":"ZY_X"},{"location":"mesh/calculations/functions/zyx/#zy_x","text":"","title":"ZY_X"},{"location":"mesh/calculations/functions/zyx/#about-the-function","text":"Gets the result X from an XYZ-attribute with input series Z and Y. An XYZ-attribute is a table in three dimensions defined on a Mesh object, e.g. a gate capacity table.","title":"About the function"},{"location":"mesh/calculations/functions/zyx/#syntax","text":"ZY_X(t,t,s)","title":"Syntax"},{"location":"mesh/calculations/functions/zyx/#description","text":"# Type Description 1 t Source time series for the Z values. 2 t Source time series for the Y values. 3 s Search string for the XYZ attribute to use in the conversion. If this attribute is located on the: Same object as the expression, the argument should be \u2018.TheXYZAttribute\u2019 (assuming the name of this attribute is TheXYZAttribute). The dot (.) limits the search operation to local attributes on the current object. Parent object, the argument should be \u2018\u2026TheXYZAttribute\u2019. The two first dots means go to the parent and the third dot is the current object attribute prefix. If the search string is prefixed with NOLOG, for example NOLOG.TheXYAttribute, the function will not produce log messages. Tip! The prefix is removed before using the search string. This function uses the same principles as CONVERT_VOLUME for setting up necessary attributes in Mesh Configurator.","title":"Description"},{"location":"mesh/calculations/functions/zyx/#example","text":"This function returns the reservoir level: ## = @ZY_X(@t(\u2018.gate_opening\u2019), @t(\u2018.gate_discharge\u2019),\u2019.gate_capacity_table\u2019)","title":"Example"},{"location":"mesh/glossary/MeshGlossary/","text":"Mesh glossary Model definition Model definition - Consists of object definitions, attribute types and namespaces. The model definition is also a top-level namespace. Object definition - Consists of attribute definitions. You can compare it to a C++ class. Attribute definition - You can compare it to a C++ class member. May be based on an attribute type (for more details refer to attribute type ). Attribute definitions may be singular or an array of one of the following types: String, boolean, int, double or UTC time. These are known as simple types . XY set, enumeration, rating curve or time series attribute (time series can be a calculation or a reference to a physical time series or virtual time series from resource). These are known as complex types . Ownership or link relation to an object definition. Refer to relation attributes paragraph for more information. Additionally, depending on the attribute type, the attribute definitions specify parameters like default value, accepted value ranges, etc. Changing the name of an attribute definition will also change the names of all already existing attributes in the model to the new value. Attribute type - Used for creating re-usable attribute definitions . Once defined could be used by different object definitions for creating an attribute definition based on it. Every attribute definition that is based on an attribute type will inherit name, description and unit of measurement (if applicable) of that attribute type. For enumeration attribute types the definitions will also inherit default value if not provided explicitly when creating the attribute definition. Updates of all above mentioned properties (name, description and unit of measurement) can be done on attribute definition level. In such case the attribute type and attribute definition may have different property values. However, there is a special way of handling changes to name and unit of measurement done on attribute type level. Updating an attribute type name or unit of measurement will update also names and unit of measurements in all attribute definitions that were created based on the given attribute type. Other properties like description will change just the property on the attribute type level. See examples below: Namespace - Used for grouping and filtering purposes in a model definition . You can compare it to a C++ namespace. Namespace may contain: object definitions attribute types other (nested) namespaces Template calculation definition - Defines calculation expression that could be used by time series attributes . Tags - special enumeration values that can be attached to attribute types and object definitions. Similar to namespaces they are used for grouping and filtering purposes. Model Model - Model definition instance. Object - Object definition instance. Attribute - Attribute definition instance. Name of the attribute is inherited from attribute definition. Resource Resource - Container storing data (e.g.: time series), used by Model(s) . Physical time series - Time series data (timestamps, values and flags) and meta data (e.g.: curve type, resolution, etc.). Virtual time series - Has defined an expression to calculate time series data (similar to calculation time series ) but is stored in resources. Catalog - Used for grouping and filtering purposes. Catalog typically contains physical time series , virtual time series or other catalogs . Similar to namespaces in model definition . Time series attributes Time series attribute - can be a: reference to a physical time series or virtual time series from resource calculation time series , where the expression is defined on the following levels: local expression - defined on model level template expression - defined on model definition level in template calculation Relation attributes Objects in Mesh model can relate to each other. Relation between objects is done using relation attributes. The relation attribute defines type of the relation, target object type and other parameters. There are two groups of relations between objects in Mesh model. Ownership relation Each object is owned by some other object (owner). It is called ownership relation. Ownership relations can be: * one-to-one * one-to-many (collection): where value of many is in range defined by minimum and maximum cardinality on relation attribute definition level. By convention ownership relation attribute names start with 'has_...', e.g.: has_PowerPlant . Removing an object will remove recursively all of its owned objects as well, if there were any. Link relation Link relation is a relation where one object may point to another object, but does not own it. There is also a versioned link relation, which is a link relation where the target object can change over time. It consists of a list of pairs: * Target object identifier. * Timestamp which indicates start of the period where the target object is active (linked to), the target object is active until the next target object in the list, if any, becomes active. There are four types of link relation attributes: * one-to-one * one-to-many (collection) * versioned one-to-one * versioned one-to-many (collection) Similar to ownership relation the value of many is in range defined by minimum and maximum cardinality on relation attribute definition level. By convention link relation attribute names start with 'to_...', e.g.: 'to_EnergyMarket'. Removing an object that had link relations to other objects will NOT remove the linked objects. XY curves An XY curve is a set of (x, y) pairs where x and y are 64 bit floating point values. x y 1 2 2 1.5 3 0.5 10 -1 An XY set is a set of XY curves, each curve indexed by a 64 bit floating point reference value. These reference values are sometimes called Z. We often visualize XY sets like so: x z y z y 0 180 2 1.5 0.3 3 0.5 1 10 -1 9 The first non-header row contains the reference/Z values for that column. Usually the headers will have actual names, see further below. A versioned XY set is a versioned list of XY sets. Each XY set in the list has a timestamp which indicates the start of the active period for that XY set, and the XY set is active until the next time-sorted XY set in the versioned XY set becomes active. Mesh has attribute types for XY sets ( XYSetAttribute ) and versioned XY sets ( XYZSeriesAttribute ). In the attribute definitions of those attributes we store a description and a unit of measurement for each of X, Y, and Z. For example if we have the following axis definitions... Axis Description Unit of measurement X Wind speed m/s Y Production MW Z Wind direction degrees ...Nimbus will visualize the above XY set as: Wind speed m/s Wind direction degrees Production MW Wind direction degrees Production MW 0 180 2 1.5 0.3 3 0.5 1 10 -1 9 Rating curves A rating curve is used to convert water level in river measurements x in a watercourse to discharge. In Mesh we use the f(x) = a * (x + b)^c formula to approximate discharge, and we store rating curves as a set of segments where each segment contains values for the 64 bit floating point factors a , b , and c . Additionally each segment i stores a 64 bit floating point x_range_until value and is valid for a range of x values [x_range_until[i-1], x_range_until[i]) . For example, with a segment... x_range_until a b c 10 1.24 13.7 11.1 50 11.2 1.0 6.65 100 4.27 1.55 0.87 ...we'd have the following rating curve function: f(x) = \\begin{cases} 1.24 * (x + 13.7)^{11.1} & \\text{if } 0 \\leq x \\lt 10\\\\ 11.2 * (x + 1.0)^{6.65} & \\text{if } 10 \\leq x \\lt 50\\\\ 4.27 * (x + 1.55)^{0.87} & \\text{if } 50 \\leq x \\lt 100\\\\ \\text{nan} & \\text{otherwise} \\end{cases} Rating curves can change over time because of for example changes in a river due to erosion and sedimentation. Such changes affect the discharge function and the function equation factors need to be adjusted. To reflect that the rating curve segments in Mesh are grouped into rating curve versions . Each version is timestamped with the time at which the version becomes active, and the version is active until the next version, if any, becomes active. version x_range_until a b c 2019 10 1.24 13.7 11.1 2019 50 11.2 1.0 6.65 2019 100 4.27 1.55 0.87 2020 10 3.31 11.7 12.1 2020 50 10.1 1.5 5.45 2020 100 5.00 1.32 0.96 2021 10 2.22 12.7 10.1 2021 50 11.1 1.3 5.65 2021 100 3.27 2.55 0.37 In addition each version has an x_range_from field, with the minimal $x$ value for the curve. For x < x_range_from for the given version the f(x) = nan . In Mesh rating curve attributes contain a set of rating curve versions. Extended metadata Extended metadata is an additional and optional information that can be set on: - Namespaces and model definition (which is also a namespace) - Attribute definitions - Object definitions It is a list of key-value pairs: category name and a JSON object. Maximum size of the JSON object serialized to a string is 4000 characters. If a given attribute definition, object definition or namespace has more than one extended metadata, then the category names must be unique. For example, an object definition may have 2 extended metadata entries: * Category name MyCategory1 with associated JSON object: { \"Labels\" : [\"Label A\",\"Label B\"], \"Something\" : {\"MaxValue\":100} } Category name MyCategory2 with associated JSON object: { \"Active\": true } Mapping From now on it is strongly advised to use new definitions, but some of them were already known under different names: Model definition - object model, meta model, repository (in Mesh Explorer) Object definition - element type, object type (in Mesh Configurator) Model - physical model Object - physical object Attribute - property Versioned XY set - XYZSeries","title":"Mesh Glossary"},{"location":"mesh/glossary/MeshGlossary/#mesh-glossary","text":"","title":"Mesh glossary"},{"location":"mesh/glossary/MeshGlossary/#model-definition","text":"Model definition - Consists of object definitions, attribute types and namespaces. The model definition is also a top-level namespace. Object definition - Consists of attribute definitions. You can compare it to a C++ class. Attribute definition - You can compare it to a C++ class member. May be based on an attribute type (for more details refer to attribute type ). Attribute definitions may be singular or an array of one of the following types: String, boolean, int, double or UTC time. These are known as simple types . XY set, enumeration, rating curve or time series attribute (time series can be a calculation or a reference to a physical time series or virtual time series from resource). These are known as complex types . Ownership or link relation to an object definition. Refer to relation attributes paragraph for more information. Additionally, depending on the attribute type, the attribute definitions specify parameters like default value, accepted value ranges, etc. Changing the name of an attribute definition will also change the names of all already existing attributes in the model to the new value. Attribute type - Used for creating re-usable attribute definitions . Once defined could be used by different object definitions for creating an attribute definition based on it. Every attribute definition that is based on an attribute type will inherit name, description and unit of measurement (if applicable) of that attribute type. For enumeration attribute types the definitions will also inherit default value if not provided explicitly when creating the attribute definition. Updates of all above mentioned properties (name, description and unit of measurement) can be done on attribute definition level. In such case the attribute type and attribute definition may have different property values. However, there is a special way of handling changes to name and unit of measurement done on attribute type level. Updating an attribute type name or unit of measurement will update also names and unit of measurements in all attribute definitions that were created based on the given attribute type. Other properties like description will change just the property on the attribute type level. See examples below: Namespace - Used for grouping and filtering purposes in a model definition . You can compare it to a C++ namespace. Namespace may contain: object definitions attribute types other (nested) namespaces Template calculation definition - Defines calculation expression that could be used by time series attributes . Tags - special enumeration values that can be attached to attribute types and object definitions. Similar to namespaces they are used for grouping and filtering purposes.","title":"Model definition"},{"location":"mesh/glossary/MeshGlossary/#model","text":"Model - Model definition instance. Object - Object definition instance. Attribute - Attribute definition instance. Name of the attribute is inherited from attribute definition.","title":"Model"},{"location":"mesh/glossary/MeshGlossary/#resource","text":"Resource - Container storing data (e.g.: time series), used by Model(s) . Physical time series - Time series data (timestamps, values and flags) and meta data (e.g.: curve type, resolution, etc.). Virtual time series - Has defined an expression to calculate time series data (similar to calculation time series ) but is stored in resources. Catalog - Used for grouping and filtering purposes. Catalog typically contains physical time series , virtual time series or other catalogs . Similar to namespaces in model definition .","title":"Resource"},{"location":"mesh/glossary/MeshGlossary/#time-series-attributes","text":"Time series attribute - can be a: reference to a physical time series or virtual time series from resource calculation time series , where the expression is defined on the following levels: local expression - defined on model level template expression - defined on model definition level in template calculation","title":"Time series attributes"},{"location":"mesh/glossary/MeshGlossary/#relation-attributes","text":"Objects in Mesh model can relate to each other. Relation between objects is done using relation attributes. The relation attribute defines type of the relation, target object type and other parameters. There are two groups of relations between objects in Mesh model.","title":"Relation attributes"},{"location":"mesh/glossary/MeshGlossary/#ownership-relation","text":"Each object is owned by some other object (owner). It is called ownership relation. Ownership relations can be: * one-to-one * one-to-many (collection): where value of many is in range defined by minimum and maximum cardinality on relation attribute definition level. By convention ownership relation attribute names start with 'has_...', e.g.: has_PowerPlant . Removing an object will remove recursively all of its owned objects as well, if there were any.","title":"Ownership relation"},{"location":"mesh/glossary/MeshGlossary/#link-relation","text":"Link relation is a relation where one object may point to another object, but does not own it. There is also a versioned link relation, which is a link relation where the target object can change over time. It consists of a list of pairs: * Target object identifier. * Timestamp which indicates start of the period where the target object is active (linked to), the target object is active until the next target object in the list, if any, becomes active. There are four types of link relation attributes: * one-to-one * one-to-many (collection) * versioned one-to-one * versioned one-to-many (collection) Similar to ownership relation the value of many is in range defined by minimum and maximum cardinality on relation attribute definition level. By convention link relation attribute names start with 'to_...', e.g.: 'to_EnergyMarket'. Removing an object that had link relations to other objects will NOT remove the linked objects.","title":"Link relation"},{"location":"mesh/glossary/MeshGlossary/#xy-curves","text":"An XY curve is a set of (x, y) pairs where x and y are 64 bit floating point values. x y 1 2 2 1.5 3 0.5 10 -1 An XY set is a set of XY curves, each curve indexed by a 64 bit floating point reference value. These reference values are sometimes called Z. We often visualize XY sets like so: x z y z y 0 180 2 1.5 0.3 3 0.5 1 10 -1 9 The first non-header row contains the reference/Z values for that column. Usually the headers will have actual names, see further below. A versioned XY set is a versioned list of XY sets. Each XY set in the list has a timestamp which indicates the start of the active period for that XY set, and the XY set is active until the next time-sorted XY set in the versioned XY set becomes active. Mesh has attribute types for XY sets ( XYSetAttribute ) and versioned XY sets ( XYZSeriesAttribute ). In the attribute definitions of those attributes we store a description and a unit of measurement for each of X, Y, and Z. For example if we have the following axis definitions... Axis Description Unit of measurement X Wind speed m/s Y Production MW Z Wind direction degrees ...Nimbus will visualize the above XY set as: Wind speed m/s Wind direction degrees Production MW Wind direction degrees Production MW 0 180 2 1.5 0.3 3 0.5 1 10 -1 9","title":"XY curves"},{"location":"mesh/glossary/MeshGlossary/#rating-curves","text":"A rating curve is used to convert water level in river measurements x in a watercourse to discharge. In Mesh we use the f(x) = a * (x + b)^c formula to approximate discharge, and we store rating curves as a set of segments where each segment contains values for the 64 bit floating point factors a , b , and c . Additionally each segment i stores a 64 bit floating point x_range_until value and is valid for a range of x values [x_range_until[i-1], x_range_until[i]) . For example, with a segment... x_range_until a b c 10 1.24 13.7 11.1 50 11.2 1.0 6.65 100 4.27 1.55 0.87 ...we'd have the following rating curve function: f(x) = \\begin{cases} 1.24 * (x + 13.7)^{11.1} & \\text{if } 0 \\leq x \\lt 10\\\\ 11.2 * (x + 1.0)^{6.65} & \\text{if } 10 \\leq x \\lt 50\\\\ 4.27 * (x + 1.55)^{0.87} & \\text{if } 50 \\leq x \\lt 100\\\\ \\text{nan} & \\text{otherwise} \\end{cases} Rating curves can change over time because of for example changes in a river due to erosion and sedimentation. Such changes affect the discharge function and the function equation factors need to be adjusted. To reflect that the rating curve segments in Mesh are grouped into rating curve versions . Each version is timestamped with the time at which the version becomes active, and the version is active until the next version, if any, becomes active. version x_range_until a b c 2019 10 1.24 13.7 11.1 2019 50 11.2 1.0 6.65 2019 100 4.27 1.55 0.87 2020 10 3.31 11.7 12.1 2020 50 10.1 1.5 5.45 2020 100 5.00 1.32 0.96 2021 10 2.22 12.7 10.1 2021 50 11.1 1.3 5.65 2021 100 3.27 2.55 0.37 In addition each version has an x_range_from field, with the minimal $x$ value for the curve. For x < x_range_from for the given version the f(x) = nan . In Mesh rating curve attributes contain a set of rating curve versions.","title":"Rating curves"},{"location":"mesh/glossary/MeshGlossary/#extended-metadata","text":"Extended metadata is an additional and optional information that can be set on: - Namespaces and model definition (which is also a namespace) - Attribute definitions - Object definitions It is a list of key-value pairs: category name and a JSON object. Maximum size of the JSON object serialized to a string is 4000 characters. If a given attribute definition, object definition or namespace has more than one extended metadata, then the category names must be unique. For example, an object definition may have 2 extended metadata entries: * Category name MyCategory1 with associated JSON object: { \"Labels\" : [\"Label A\",\"Label B\"], \"Something\" : {\"MaxValue\":100} } Category name MyCategory2 with associated JSON object: { \"Active\": true }","title":"Extended metadata"},{"location":"mesh/glossary/MeshGlossary/#mapping","text":"From now on it is strongly advised to use new definitions, but some of them were already known under different names: Model definition - object model, meta model, repository (in Mesh Explorer) Object definition - element type, object type (in Mesh Configurator) Model - physical model Object - physical object Attribute - property Versioned XY set - XYZSeries","title":"Mapping"},{"location":"mesh/grpc/APISpecification/","text":"gRPC API Specification The details of the Mesh gRPC API are defined in a set of Protocol Buffer ( .proto ) files. These files specify the available services, messages, and methods for interacting with the Mesh via gRPC. Available proto files: auth/v1alpha/auth.proto \u2014 Authentication service definitions availability/v1alpha/availability.proto \u2014 Availability service definitions calc/v1alpha/calc.proto \u2014 Calculation service definitions config/v1alpha/config.proto \u2014 Configuration service definitions hydsim/v1alpha/hydsim.proto \u2014 Hydro simulation service definitions model/v1alpha/model.proto \u2014 Model service definitions model/v1alpha/resources.proto \u2014 Model resources definitions model_definition/v1alpha/resources.proto \u2014 Model definition resources resource/v1alpha/resource.proto \u2014 Resource service definitions session/v1alpha/session.proto \u2014 Session service definitions time_series/v1alpha/time_series.proto \u2014 Time series service definitions type/resources.proto \u2014 Type resources definitions Refer to these proto files for the most up-to-date and detailed information about the Mesh gRPC API, including message formats, methods, and request/response structures.","title":"API Specification"},{"location":"mesh/grpc/APISpecification/#grpc-api-specification","text":"The details of the Mesh gRPC API are defined in a set of Protocol Buffer ( .proto ) files. These files specify the available services, messages, and methods for interacting with the Mesh via gRPC. Available proto files: auth/v1alpha/auth.proto \u2014 Authentication service definitions availability/v1alpha/availability.proto \u2014 Availability service definitions calc/v1alpha/calc.proto \u2014 Calculation service definitions config/v1alpha/config.proto \u2014 Configuration service definitions hydsim/v1alpha/hydsim.proto \u2014 Hydro simulation service definitions model/v1alpha/model.proto \u2014 Model service definitions model/v1alpha/resources.proto \u2014 Model resources definitions model_definition/v1alpha/resources.proto \u2014 Model definition resources resource/v1alpha/resource.proto \u2014 Resource service definitions session/v1alpha/session.proto \u2014 Session service definitions time_series/v1alpha/time_series.proto \u2014 Time series service definitions type/resources.proto \u2014 Type resources definitions Refer to these proto files for the most up-to-date and detailed information about the Mesh gRPC API, including message formats, methods, and request/response structures.","title":"gRPC API Specification"},{"location":"mesh/grpc/Authorization/","text":"Configuration For functionality description and configuration please refer to: Mesh service installation guide . Testing OAuth 2.0 For Microsoft Entra ID environment you can follow the steps below: For the protected API (i.e.: Mesh gRPC server) create an application registration: Authorization code flow Expose API of the created application and add a scope: Create client secret and save its value: Create app roles for the users/groups: Assign app roles to the users/groups: Now we want to get an access token. First we need to call authorize endpoint and get authorization code. Open internet browser, enter the following URL and change the parameters according to your setup: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/authorize?response_type=code&client_id=YOUR_CLIENT_ID&redirect_uri=REDIRECT_URI_FROM_STEP_1&scope=openid%20profile In return we should get something like this: https://localhost:5001/?code=0.AUsA9qdgUwMwDkOIVHHdOulTT9PD9pRh4G9DiaXHQCed8k1LAHs.AgABAAIAAAD--DLA3VO7QrddgJg7WevrAgDs_wUA9P9bchFZhU35cRjwyL4Ody0v5VVAPW5RhSdysOasDYmhU-QSjiZVIiL_Ma8fxNlGdoZiM0bi_fQ0alKr8qEB-ZhezENOme3DdYd11Q_1_6gVqtgUV_yqRO8oHvh7mma14QD_r41ClgcZhxYvTLlDyAddqqL4Qk92-7u2kaMYfu9RlinZ9DoCI29-GGjTAgxUePlQgVBfMmquKaQG2sBs3tbEhi3prwZrzI-vqbRel0mur7ssn2-2YKREjmL4d9cc04V0mYoy612SEJm3UgZMjvby5A9M28pYFUdlBNSOoNl8tYku7jRVROYGESJL5OxPRYEA-yecPo2LtHUqsnp6X9CEV4s8z7G8rMmQlYZibzuppr5WJ_AWj_d_jaZrYJI2oJFO3KrkoRGvK-v71l_6bdVxesMc2m5QQFInHMF6_P_9NqxqevKq1nub98ms8DqgfIcUatYLxcVTIBKFIDrSLcYYDLMkTvuIpTmTBX0dSbdTcYL8tNCcEh197bUPZHIu8jHaL-eV8wQm1TprzsbJun6y0e1C5ExYe3IfUFbl6uomjcb6VDqZV4l3RSiFGJxe9af7CPzbWSqnx7Z0D4c3H1BIxul8j_oL1OgSL1wIJlLnx88XQgHz9p0v0k9dCGSUK-95Mjq8BiOG7URWJx_Q6SozZvsgm0TT7GBv5-NTigRHJL7L6iAOZTl4vhFl9evex7SX5N3Y_5w_N1h2kvhPA7ufRlJaF77N6t2hvxsiJ85Q8Yby76zN2f3fxhvUBze1YQT25wGTE8znP79dVTll2EVNk--FYn7qTzc5P6aOzhlgvFHS6IsDg18yefI_S0_7jDDTVLopHPdpIqY&session_state=ba3502a4-903f-461c-bbdb-995e4d76ed62# Copy the code parameter value. Now we need to make a POST request to the token endpoint. For this I'm using Postman, but you can use also curl or other software. URL: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/token grant_type: authorization_code redirect_uri: REDIRECT_URI_FROM_STEP_1 client_id: YOUR_CLIENT_ID scope: YOUR_SCOPE_FROM_STEP_2 code: CODE_GOT_FROM_TOKEN_ENDPOINT client_secret: YOUR_CLIENT_SECRET_FROM_STEP_3 You will get a response message with access token. You can check the access token's content in e.g.: jwt.io . The access token could now be used to call e.g. Mesh gRPC server. For gRPC the token needs to be send in the Authorization header when making a call to the API, like: Authorization: Bearer <token> Client credentials flow In the protected API application create app roles for the applications (daemons): For the daemon client application follow the steps below. Create new application registration, leave the Redirect URI empty: Create client secret and save its value. Request API permission for the app role created in step 1: Now we need to grant consent for the requested permission. Click on the Enterprise applications link: At the end we should see proper status in the API permission view: Now we want to get an access token. We need to make a POST request to the token endpoint. For this I'm using Postman, but you can use also curl or other software. URL: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/token grant_type: client_credentials client_id: YOUR_CLIENT_ID (the deamon app ID) scope: PROTECTED_API_APPLICATION_ID_URI + '/.default' (e.g.: api://94f6c3d3-e061-436f-89a5-c740279df24d/.default) client_secret: YOUR_CLIENT_SECRET_FROM_STEP_3 You will get a response message with access token. You can check the access token's content in e.g.: jwt.io . The access token could now be used to call e.g. Mesh gRPC server. For gRPC the token needs to be send in the Authorization header when making a call to the API, like: Authorization: Bearer <token> Python SDK To test the access token you can also use one of the Python SDK's example scripts . You can also extend the example script with e.g.: MSAL library to acquire the access token in the background. See documentation on how to connect and authorize using Mesh Python SDK to a Mesh server that is using OAuth authorization: https://volue-public.github.io/energy-mesh-python/external_auth.html Kerberos Python SDK See documentation on how to connect and authorize using Mesh Python SDK to a Mesh server that is using Kerberos authentication: https://volue-public.github.io/energy-mesh-python/kerberos.html","title":"Authorization"},{"location":"mesh/grpc/Authorization/#configuration","text":"For functionality description and configuration please refer to: Mesh service installation guide .","title":"Configuration"},{"location":"mesh/grpc/Authorization/#testing","text":"","title":"Testing"},{"location":"mesh/grpc/Authorization/#oauth-20","text":"For Microsoft Entra ID environment you can follow the steps below: For the protected API (i.e.: Mesh gRPC server) create an application registration:","title":"OAuth 2.0"},{"location":"mesh/grpc/Authorization/#authorization-code-flow","text":"Expose API of the created application and add a scope: Create client secret and save its value: Create app roles for the users/groups: Assign app roles to the users/groups: Now we want to get an access token. First we need to call authorize endpoint and get authorization code. Open internet browser, enter the following URL and change the parameters according to your setup: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/authorize?response_type=code&client_id=YOUR_CLIENT_ID&redirect_uri=REDIRECT_URI_FROM_STEP_1&scope=openid%20profile In return we should get something like this: https://localhost:5001/?code=0.AUsA9qdgUwMwDkOIVHHdOulTT9PD9pRh4G9DiaXHQCed8k1LAHs.AgABAAIAAAD--DLA3VO7QrddgJg7WevrAgDs_wUA9P9bchFZhU35cRjwyL4Ody0v5VVAPW5RhSdysOasDYmhU-QSjiZVIiL_Ma8fxNlGdoZiM0bi_fQ0alKr8qEB-ZhezENOme3DdYd11Q_1_6gVqtgUV_yqRO8oHvh7mma14QD_r41ClgcZhxYvTLlDyAddqqL4Qk92-7u2kaMYfu9RlinZ9DoCI29-GGjTAgxUePlQgVBfMmquKaQG2sBs3tbEhi3prwZrzI-vqbRel0mur7ssn2-2YKREjmL4d9cc04V0mYoy612SEJm3UgZMjvby5A9M28pYFUdlBNSOoNl8tYku7jRVROYGESJL5OxPRYEA-yecPo2LtHUqsnp6X9CEV4s8z7G8rMmQlYZibzuppr5WJ_AWj_d_jaZrYJI2oJFO3KrkoRGvK-v71l_6bdVxesMc2m5QQFInHMF6_P_9NqxqevKq1nub98ms8DqgfIcUatYLxcVTIBKFIDrSLcYYDLMkTvuIpTmTBX0dSbdTcYL8tNCcEh197bUPZHIu8jHaL-eV8wQm1TprzsbJun6y0e1C5ExYe3IfUFbl6uomjcb6VDqZV4l3RSiFGJxe9af7CPzbWSqnx7Z0D4c3H1BIxul8j_oL1OgSL1wIJlLnx88XQgHz9p0v0k9dCGSUK-95Mjq8BiOG7URWJx_Q6SozZvsgm0TT7GBv5-NTigRHJL7L6iAOZTl4vhFl9evex7SX5N3Y_5w_N1h2kvhPA7ufRlJaF77N6t2hvxsiJ85Q8Yby76zN2f3fxhvUBze1YQT25wGTE8znP79dVTll2EVNk--FYn7qTzc5P6aOzhlgvFHS6IsDg18yefI_S0_7jDDTVLopHPdpIqY&session_state=ba3502a4-903f-461c-bbdb-995e4d76ed62# Copy the code parameter value. Now we need to make a POST request to the token endpoint. For this I'm using Postman, but you can use also curl or other software. URL: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/token grant_type: authorization_code redirect_uri: REDIRECT_URI_FROM_STEP_1 client_id: YOUR_CLIENT_ID scope: YOUR_SCOPE_FROM_STEP_2 code: CODE_GOT_FROM_TOKEN_ENDPOINT client_secret: YOUR_CLIENT_SECRET_FROM_STEP_3 You will get a response message with access token. You can check the access token's content in e.g.: jwt.io . The access token could now be used to call e.g. Mesh gRPC server. For gRPC the token needs to be send in the Authorization header when making a call to the API, like: Authorization: Bearer <token>","title":"Authorization code flow"},{"location":"mesh/grpc/Authorization/#client-credentials-flow","text":"In the protected API application create app roles for the applications (daemons): For the daemon client application follow the steps below. Create new application registration, leave the Redirect URI empty: Create client secret and save its value. Request API permission for the app role created in step 1: Now we need to grant consent for the requested permission. Click on the Enterprise applications link: At the end we should see proper status in the API permission view: Now we want to get an access token. We need to make a POST request to the token endpoint. For this I'm using Postman, but you can use also curl or other software. URL: https://login.microsoftonline.com/YOUR_DOMAIN.onmicrosoft.com/oauth2/v2.0/token grant_type: client_credentials client_id: YOUR_CLIENT_ID (the deamon app ID) scope: PROTECTED_API_APPLICATION_ID_URI + '/.default' (e.g.: api://94f6c3d3-e061-436f-89a5-c740279df24d/.default) client_secret: YOUR_CLIENT_SECRET_FROM_STEP_3 You will get a response message with access token. You can check the access token's content in e.g.: jwt.io . The access token could now be used to call e.g. Mesh gRPC server. For gRPC the token needs to be send in the Authorization header when making a call to the API, like: Authorization: Bearer <token>","title":"Client credentials flow"},{"location":"mesh/grpc/Authorization/#python-sdk","text":"To test the access token you can also use one of the Python SDK's example scripts . You can also extend the example script with e.g.: MSAL library to acquire the access token in the background. See documentation on how to connect and authorize using Mesh Python SDK to a Mesh server that is using OAuth authorization: https://volue-public.github.io/energy-mesh-python/external_auth.html","title":"Python SDK"},{"location":"mesh/grpc/Authorization/#kerberos","text":"","title":"Kerberos"},{"location":"mesh/grpc/Authorization/#python-sdk_1","text":"See documentation on how to connect and authorize using Mesh Python SDK to a Mesh server that is using Kerberos authentication: https://volue-public.github.io/energy-mesh-python/kerberos.html","title":"Python SDK"},{"location":"mesh/grpc/ClientCertificates/","text":"gRPC client TLS certificates Mesh server gRPC interface can be configured to use Transport Layer Security (TLS) and if used then only TLS connections from the clients will be accepted. Certificates TLS uses X.509 digital certificates, further on referred as TLS certificate. Such certificate contains, among others, public key and information about the issuer. Additionally for each TLS certificate there is a corresponding private key. Contrary to the public key, it is a secret and must be kept secure. Those are needed for server authentication and encryption of the transmitted data. There are two types of TLS certificates: Certificate Authority (CA) certificates than can issue/sign other certificates. Top level CA certificates are self-signed and are called Root CA certificates. Other CA certificates are called intermediate. End-entity certificates identifying a person, system, organization, etc. They are issued by CA. They can't issue other certificates. Root and intermediate CA certificates form so called chain of trust for a given end-entity certificate: gRPC clients The gRPC client needs to be able to verify if the TLS certificate used by Mesh server gRPC interface is trusted . Self-signed certificates For self-signed certificates, not issued by publicly trusted CAs we must always provide the certificate in PEM format to the gRPC client. The certificate must be accessible by the gRPC client, e.g.: no password protection, etc. However, there is option to add such self-signed certificate to operating system trusted roots. In such case, please refer to the next section. Adding certificate to trusted roots should be handled by the system administrator and is out of scope for this document. Note: gRPC clients don't need Mesh server private key(s). Those must be kept secure on the Mesh server machine. Certificates signed by trusted CA For certificates that are signed by publicly trusted CA let's look at how two of the most popular gRPC implementations handle them. gRPC core (C implementation) For Linux, FreeBSD and MacOS: If the certificate issuer 1 is in the operating system trusted roots, then gRPC runtime will load it automatically and nothing extra is required. Windows certificate store is not supported at the time of writing this document: gRPC 1.59.0. gRPC core implementation also comes with its own list of trusted roots, see: https://github.com/grpc/grpc/blob/master/etc/roots.pem If the certificate issuer 1 is in that list then nothing extra is required. Otherwise, the certificate must be provided in PEM format to the gRPC client. gRPC .NET If the certificate is in the operating system trusted roots, then gRPC runtime will load it automatically and nothing extra is required. Otherwise, the certificate must be provided in PEM format to the gRPC client. Or one of the issuer's certificates in the chain of trust. \u21a9 \u21a9","title":"Client certificates"},{"location":"mesh/grpc/ClientCertificates/#grpc-client-tls-certificates","text":"Mesh server gRPC interface can be configured to use Transport Layer Security (TLS) and if used then only TLS connections from the clients will be accepted.","title":"gRPC client TLS certificates"},{"location":"mesh/grpc/ClientCertificates/#certificates","text":"TLS uses X.509 digital certificates, further on referred as TLS certificate. Such certificate contains, among others, public key and information about the issuer. Additionally for each TLS certificate there is a corresponding private key. Contrary to the public key, it is a secret and must be kept secure. Those are needed for server authentication and encryption of the transmitted data. There are two types of TLS certificates: Certificate Authority (CA) certificates than can issue/sign other certificates. Top level CA certificates are self-signed and are called Root CA certificates. Other CA certificates are called intermediate. End-entity certificates identifying a person, system, organization, etc. They are issued by CA. They can't issue other certificates. Root and intermediate CA certificates form so called chain of trust for a given end-entity certificate:","title":"Certificates"},{"location":"mesh/grpc/ClientCertificates/#grpc-clients","text":"The gRPC client needs to be able to verify if the TLS certificate used by Mesh server gRPC interface is trusted .","title":"gRPC clients"},{"location":"mesh/grpc/ClientCertificates/#self-signed-certificates","text":"For self-signed certificates, not issued by publicly trusted CAs we must always provide the certificate in PEM format to the gRPC client. The certificate must be accessible by the gRPC client, e.g.: no password protection, etc. However, there is option to add such self-signed certificate to operating system trusted roots. In such case, please refer to the next section. Adding certificate to trusted roots should be handled by the system administrator and is out of scope for this document. Note: gRPC clients don't need Mesh server private key(s). Those must be kept secure on the Mesh server machine.","title":"Self-signed certificates"},{"location":"mesh/grpc/ClientCertificates/#certificates-signed-by-trusted-ca","text":"For certificates that are signed by publicly trusted CA let's look at how two of the most popular gRPC implementations handle them.","title":"Certificates signed by trusted CA"},{"location":"mesh/grpc/ClientCertificates/#grpc-core-c-implementation","text":"For Linux, FreeBSD and MacOS: If the certificate issuer 1 is in the operating system trusted roots, then gRPC runtime will load it automatically and nothing extra is required. Windows certificate store is not supported at the time of writing this document: gRPC 1.59.0. gRPC core implementation also comes with its own list of trusted roots, see: https://github.com/grpc/grpc/blob/master/etc/roots.pem If the certificate issuer 1 is in that list then nothing extra is required. Otherwise, the certificate must be provided in PEM format to the gRPC client.","title":"gRPC core (C implementation)"},{"location":"mesh/grpc/ClientCertificates/#grpc-net","text":"If the certificate is in the operating system trusted roots, then gRPC runtime will load it automatically and nothing extra is required. Otherwise, the certificate must be provided in PEM format to the gRPC client. Or one of the issuer's certificates in the chain of trust. \u21a9 \u21a9","title":"gRPC .NET"},{"location":"mesh/installation/MeshServiceInstallationGuide/","text":"Mesh Service Installation Guide Mesh Service Installation Guide About this document Prerequisites System requirements Checklist before you start the installation General setup Hardware requirements Windows services and TCP communication Communication between Nimbus Client and Mesh server Install the Mesh Service Configuring core dump creation Configuration mesh.json - minimum version Database connection Mesh ports and authentication for ZMQ Mesh gRPC server Enable the server and configure port numbers Use Transport Layer Security (TLS) Certificates Loading certificates from file system Windows Certificate Store Authentication Kerberos OAuth 2.0 access tokens Access token types Configuration Authorisation Limit time series cache usage Verify the installation Update the Mesh object model Error situations General installation problems Problems related to Oracle 19 Security considerations mesh.json - complete Contact information About this document This document describes how to install and upgrade the Mesh Service. Installation and upgrade follow the same steps. It is intended for a technical audience, to be used by system administrator/IT personnel or by Volue\u2019s consultants. Prerequisites System requirements Operating system: Windows Server Standard 2019 or 2022, 64-bit SmG Database (with compatible SmG version) Microsoft Visual C++ Redistributable for Visual Studio 2015-2022 .NET Framework 4.8 Database upgrades are done via the SmG database upgrade. Ensure you have the correct version of SmG, see latest release notes. Note! Running more than one instance of Mesh against a single Oracle database may cause major errors. This configuration is only supported in some special cases. Checklist before you start the installation Before installing the Mesh Service, ensure you have: Administrator access to the target server. The required Operating system installed on target server, see System requirements. The required Microsoft Visual C++ Redistributable installed on the target server, see System requirements. The information needed to connect to the Oracle database from the Mesh server. Usually a TNSNAMES.ora file, a database name, a username, and a password. The name of the directory containing TNSNAMES.ora should be specified in the TNS_ADMIN environment variable. The Mesh Service installation package. General setup Hardware requirements Note! You should dimension servers running Mesh to handle both high CPU load, expansive memory use and high I/O throughput regarding network interconnect towards the database. The results of requested calculations are kept in memory as much as possible; for this reason, we recommend a high amount of memory to gain optimal performance. Windows services and TCP communication Windows Firewall with Advanced Security: For remote calls, you must set an inbound rule, allowing TCP connections in the following default ports: Port Direction Usage 1521 Outbound Default port to access the Oracle database 9000 Inbound Http communication from Nimbus 9001 Inbound Net.Tcp communication from Nimbus 20000 Inbound Access to the Mesh health endpoint, used from Nimbus when failover is configured 40321 Inbound ZMQ communication 50051 Inbound Communication from clients using gRPC Communication between Nimbus Client and Mesh server Port 20000 must be open on the server where the Mesh server is installed in order to avoid performance issues in the Nimbus Client connected to Mesh. In addition, port 20000 is needed if failover of the Nimbus Client against the Mesh server is required. Install the Mesh Service Mesh Service is a Windows service. It can run as a user member of the local Administrator group or as a user with log on as a service rights. The installer is distributed as a ZIP file named like Mesh-2.12.1.21.zip. To install the Mesh Service: Extract the zip file containing the installation package to desired location. Navigate to this location and run: .\\mesh.ps1 -Install -UrlAclUser BUILTIN\\Users This script will register necessary endpoints and create a Windows service named Powel Mesh Service . Configuring core dump creation A core dump is an image of the process and all of its memory at a point in time. These dumps make it significantly easier to debug and fix errors. We recommend that all users enable automatic core dumps for the Mesh process, and that core dumps for any crashes are sent to the Volue Support together with the Mesh log and any information about what was happening in the system at the time of the crash. See https://docs.microsoft.com/en-us/windows/win32/wer/collecting-user-mode-dumps for more information on how to collect core dumps. Alternatively set the following registry values under HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\Windows Error Reporting\\LocalDumps\\Powel.Mesh.Server.exe : Parameter Type Value REG_EXPAND_SZ DumpFolder C:\\MeshCoreDumps REG_DWORD DumpType 2 REG_DWORD DumpCount 10 The size of a Mesh core dump with the configuration above is equal to the memory used by Mesh at the time of the dump. If disk space is an issue you may reduce DumpCount, or set DumpType to 1 which makes the dumps smaller but less useful. Configuration After the service is installed, the following configuration is required. Database connection Mesh ports and authentication for ZMQ Mesh gRPC server Use Transport Layer Security (TLS) Authentication Authorisation Limit cache mesh.json - minimum version The Mesh configuration is defined in the mesh.json file which normally is located in the directory above the Mesh service application ( Powel.Mesh.Server.exe ). A minimal configuration looks like this: { \"Log\": { \"Console\": true, // Log to stdout when not run as a service \"WindowsEventLog\": false, // Log to the Windows Event Log \"Directory\": \"C:\\\\Powel\\\\Mesh\\\\logs\", // Log to the given directory \"Level\": \"info\" // One of \"trace\", \"debug\", \"info\", \"warning\", \"error\", default \"info\" }, \"Oracle\": { \"Server\": \"<DatabaseServer>\", \"Username\": \"<DatabaseUser>\", \"Password\": \"<DatabasePassword>\" }, \"Http\": { \"Port\": 20000, \"Kerberos\": true, \"Health\": true // Enable the health endpoint. }, \"Grpc\": { \"Address\": \"[::]:50051\", \"Kerberos\": true, \"Tls\": { \"CertificatePath\": \"<PathToCertificateInPEMFormat>\", \"CertificateKeyPath\": \"<PathToPrivateKeyInPEMFormat>\" } }, \"Zmq\": { \"Port\": 40321, \"Kerberos\": true } } Database connection The Mesh database is part of the SmG database. The Mesh service has to connect and operate on the SmG database as the SmG Schema Owner. There are 2 ways of connecting to the database. Using credentials or using external authentication. You define the database connection string in mesh.json : Credentials \"Oracle\": { \"Server\": \"<Database>\", \"Username\": \"<DatabaseUser>\", \"Password\": \"<DatabasePassword>\" }, Verify that the values in these files are correct by executing the following statement from command prompt: sqlplus <DatabaseUser>/<DatabasePassword>@<Database> Oracle external authentication To use it: - The database server must be configured to support external authentication and the account running Mesh service must be granted proper privileges in the database. The following privileges are required: - execute on sys.dbms_lock - execute on sys.dbms_change_notification - change notification - On the client side (i.e. server running Mesh service) the Oracle client must be configured to use NTS authentication. See sqlnet.ora file: SQLNET.AUTHENTICATION_SERVICES= (NTS) - On the client side, set ExternalCredentials parameter to true in the Oracle section in mesh.json configuration file: json \"Oracle\": { \"Server\": \"<Database>\", \"ExternalCredentials\": true } Mesh ports and authentication for ZMQ In the Mesh configuration file mesh.json the lines are used (with default values): \"Zmq\": { \"Threads\": 8, //optional \"Kerberos\": true, \"Port\": 40321 }, This defines which port Mesh use to listen for ZMQ requests. This port number must be the same in clients using ZMQ. The firewall must also be open on this port. Kerberization of ZMQ, is by default turned on. Clients using ZMQ are all Smart Power clients interfacing with Mesh, except Mesh Data Transfer. Mesh gRPC server A gRPC interface is exposed for both external and internal usage. There is also a gRPC client, Mesh Python SDK , that uses the gRPC interface and provides an easy and optimised way of working with Mesh for Python developers. Note! The Mesh gRPC interface is still in alpha. The interface is changing rapidly, breaking changes are allowed and stability is not guaranteed nor expected. Enable the server and configure port numbers To enable Mesh gRPC server, configure the following lines in the Mesh configuration file mesh.json . \"Grpc\": { \"Kerberos\": true, \"OAuth\": false, \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"<PathToCertificateInPEMFormat>\", \"CertificateKeyPath\": \"<PathToPrivateKeyInPEMFormat>\" } }, This defines which port Mesh uses to listen for gRPC requests. This port number must be the same in the clients using gRPC. The firewall must also be open on this port. The example shows an unencrypted and unauthenticated configuration, and we highly recommend to both encrypt and authenticate/authorize the gRPC interface (see below for how to configure it). Use Transport Layer Security (TLS) There are two possible types of connections to the gRPC server from the clients. An insecure, where data is unencrypted and sent as plaintext over the network, thus it is not recommended for production environment. A secure where the server is authenticated by the clients via the Transport Layer Security (TLS protocol) certificate and data is encrypted. Mesh server gRPC interface can be configured to use Transport Layer Security (TLS) and if used then only TLS connections from the clients will be accepted. The TLS server authentication serves two purposes: It authenticates the server, a client that connects to a server can verify the server's certificate and check if it is trusted . It encrypts the communication, by using HTTPS as a transport protocol. For security reasons, encryption is required for client authentication and authorisation. Certificates TLS uses X.509 digital certificates, further on referred as TLS certificate. Such certificate contains, among others, public key and information about the issuer. Additionally for each TLS certificate there is a corresponding private key. Contrary to the public key, it is a secret and must be kept secure. The Mesh team requires/strongly advises to use certificates signed by publicly trusted Certificate Authorities (CAs). Such certificates can be obtained for free and they ensure no additional configuration is needed to be done on the client side in order to connect to a TLS secured Mesh gRPC server. On the other hand using self-signed certificates, depending on the client environment, may require configuration work in order to connect to a TLS secured Mesh gRPC server. That is why we require/strongly suggest using the former type of certificates. For more information see the document about client certificates. Note! As Volue we do not suggest using specific TLS certificate vendors. We provide a set of guidelines and requirements. The final decision belongs to the customer. By default Mesh configuration ( mesh.json ) has the TLS enabled, but the certificate settings must be set manually for each environment. There are two options to load the certificates. Loading certificates from file system Providing paths to certificate and private key in PEM format. The files mustn't be encrypted and must be accessible by the account that is running Mesh server. \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, ... }, For security reasons, access to private key MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). Windows Certificate Store Alternatively the certificates can be loaded from the Windows Certificate Store. To use it: The private key must be marked as \"exportable\" in the Windows Certificate Store. The certificate must have a corresponding private key defined in the Windows Certificate Store. The certificate must be accessible by the user account that is running Mesh. All current user certificate stores except the Current User/Personal store inherit the contents of the local machine certificate stores. Moreover, currently the support is limited to private keys based on the RSA algorithm. To enable reading certificate from the Windows Certificate Store you need to specify: { \"Grpc\": { \"Tls\": { \"WindowsCertStore\": { \"CertificateThumbprint\": \"142e888b1640210e83b1c21b6fc414aefb1f8813\", \"SystemStoreName\": \"ROOT\" } }, ... } } Parameters: CertificateThumbprint is a 160 bit SHA1 hash. Listed in the certificate details section. SystemStoreName name of the system store. Some predefined system stores are: ROOT - mapping to *Trusted Root Certification Authorities\" MY - mapping to Personal CA - mapping to *Intermediate Certification Authorities\" Authentication Mesh server could be configured to protect its gRPC API so that only authenticated users that are assigned to specific roles can access it. There are two options: Kerberos OAuth 2.0 access tokens Note! If the Mesh gRPC server is configured to use authentication, only authenticated users may work with Mesh. Kerberos Mesh authenticates users and grants access to specific APIs based on what AD groups the authenticated users belong to. Configuration: \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, \"Kerberos\": true, \"Authorization\": { \"GroupsFile\": \"roles_mapping.json\" }, ... } If the gRPC client runs as \"Local System\" then in calls to Mesh it is represented as the machine account itself. If Mesh service is running on the same machine then in such cases the gRPC client belongs to \"System\" group. This is useful in cases where for example: customers do not want to create extra service accounts for Mesh Data Transfer services that are running locally. Example groups file: { \"Kerberos\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], // For localhost services running as \"Local System\" \"System\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } } Mesh clients need to provide a service principal name (SPN) when connecting to Mesh with Kerberos enabled. If Mesh is running as AD User: Start Windows Server PowerShell and enter: Get-ADUser -Filter {UserPrincipalName -eq \"user.name@domain.com\"} | Select-Object SamAccountName Then check if SPN exists: setspn -L SamAccountName setspn -L domain\\SamAccountName Depending on the SPN found, use it as the service principal name in clients like Mesh Data Transfer. If Mesh is running as a machine user (like Local System): Then the service principal name will usually be HOST/full.qualified.domain.name or HOST/f.q.d.n@DOMAIN.COM but it might be different in your environment. OAuth 2.0 access tokens The users authenticate and request access to Mesh from external authorisation servers, and Mesh validates the access token that is obtained from the authorisation server. OAuth 2.0 is an industry-standard protocol for authorisation. Depending on the Identity Provider implementing the OAuth 2.0 protocol, there might be some differences in the access token structure, flows, etc. Implementation of Mesh server OAuth authorisation was tested against Microsoft Entra ID (previously known as Azure Active Directory) Identity Provider and supports: user access tokens acquired by using authorisation code flow (token version 1 and 2) application-only access tokens acquired by using client credentials flow (token version 1 and 2) We do not guarantee that authorisation based on other Identity Providers will work. Access token types We distinguish between user and application-only access tokens: User access token - User tokens are used for flows like authorisation code flow where a user is authenticated and gives consent to the requested permissions. User access tokens must include scope ( scp or scope ) and name claims. Application-only access tokens - Application-only access tokens are acquired using client credentials flow. They are used in server-to-server interactions, where the client applications are referred to as daemons or service accounts . In this flow the client application is called confidential client. Contrary to user access tokens the application-only access tokens in Microsoft Entra do not contain scope ( scp or scope ) and name claims. Application-only access tokens have the same values of sub and oid claims. The client application must use authorisation based on application permissions (app roles) . With this approach the roles claim will be part of the access token. Configuration To use it: An OAuth 2.0 JWT compatible access token must be signed using RSA algorithm. Authorisation is done using roles claim that must be part of the access token. Additionally, all access tokens must contain the following claims: oid, aud, iss and sub. All those claims must have string data types (not an array). Additionally, user access tokens must contain scope (scp or scope) and name claims. All those claims must have string data types (not an array). TLS connection must be enabled. To enable OAuth support you need to specify (change the values according to customer's environment): \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, \"OAuth\": true, \"Authorization\": { \"Audience\": \"api://CLIENT_ID\", \"JwksEndpoint\": \"https://login.microsoftonline.com/TENANT_ID/discovery/v2.0/keys\", \"Issuer\": \"https://sts.windows.net/TENANT_ID/\", \"Scope\": \"mesh.grpc\", // this is required for user access tokens, not used for application-only access tokens \"GroupsFile\": \"roles_mapping.json\" }, ... } Note that Kerberos is enabled by default. Parameters: JwksEndpoint - JSON Web Key Set (JWKS) endpoint URI. JWKS contains all public keys needed to validate (check signature) generated access token by the authorisation server. Audience - audience token claim. Must match aud token claim. Depending on the access token version, the expected format may be different. For v1.0 tokens it may have the \u201capi://\u201d prefix. For v2.0 tokens it is always just a client ID. It is best to check decode access token in e.g. jwt.io website and check the actual aud claim value. Issuer - issuer token claim. Must match iss token claim. Scope - scope token claim. Must match scp or scope token claim. The check is done only for user access tokens. GroupsFile - JSON file that maps roles to specific permissions in our API. Example groups file: { \"OAuth\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], \"Daemons\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } } Authorisation We can limit access to Mesh functionality through the gRPC interface to the following groups: time_series - functionality accessing time series values. model - functionality accessing the model and model definition instances. For each of these groups it is possible to limit access to the normal CRUD operations: create - functionality that will create new information. read - functionality that will read information without changing anything. update - functionality that will update existing information. delete - functionality that will delete existing information. The GroupsFile defines the access to the different functionality for any user dependent on which groups or roles this user is assigned to in the company's user store. An example of such a definition is shown below giving all users in the Users group/role only read access to time series and model, while users in the Admins or Daemons group/role has full access to time series and model. When a user is a member of multiple groups or assigned multiple roles, their effective access rights are the union of the rights granted by each group and role. For security reasons, access to GroupsFile MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). The Kerberos group names and OAuth roles mappings are defined separately. { \"Kerberos\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], \"Daemons\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], // For localhost services running as \"Local System\" \"System\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] }, // if both OAuth and Kerberos are enabled: \"OAuth\": { \"OAuthUsers\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } } Limit time series cache usage By default, Mesh will read into memory all time series values found in the database for the requested time series and these values will stay in memory as long as the service is running. It is possible to limit/control the memory usage by the cache by adding the following configuration: \"SharedPointCache\": { \"LimitMb\": 1000, \"DefaultIntervalDays\": 20, \"PreloadAllTimeSeries\": false, \"PreloadPreviousState\": false, \"CacheStateFileDirectory\": \"<path>\" }, Parameters: LimitMb - the maximum number of megabytes allowed in the shared point cache. DefaultIntervalDays - when the preloading is enabled Mesh will not preload points before now minus the configured number of days. PreloadAllTimeSeries - if set to true , Mesh will preload all physical time series points on startup. PreloadPreviousState - if set to true , Mesh will preload previous cache state on startup. If both PreloadAllTimeSeries and PreloadPreviousState is set to true at the same time, Mesh will first preload the previous cache state and then the other time series values. CacheStateFileDirectory - path to the directory where Mesh persists the cache state. Note! Most installations should not have to change the default configuration, except the CacheStateFileDirectory field, as it is related to the memory/performance tuning. For security reasons, access to CacheStateFileDirectory should be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). Verify the installation To verify the installation: Check that the service is running. Run tests using the service, e.g. the Mesh Configurator or Nimbus. Note! You must be member of the correct security group to start Mesh Configurator. Update the Mesh object model There will be a new version of the Mesh object model (EnergySystem) delivered with each release. The installed object model must be updated to the latest version for the applications using Mesh to work correctly. As part of a Smart Power release there exists a separate package named ModelUpdate.zip that contains the new model together with scripts and descriptions of how to update the Mesh model. Error situations General installation problems If errors occur during installation, you should: Verify that you have followed the prerequisite steps, see Prerequisites. Verify that the installation is complete, see What the installer does. Verify the configurations, see Server manager configuration and Application configuration. Verify that the user executing the Mesh service is administrator or has been granted appropriate privileges (Logon as a Service, Logon as a Batch Job, URL ACLs). The Mesh Service logs service calls and errors to the Windows Event Log. The relevant source names for log entries are Powel Mesh and Powel.Object.Structure.Service . Problems related to Oracle 19 If you get the error message ORA-22922: nonexistent LOB value , that may be caused by an incorrect value ( true ) for the Oracle init parameter optimizer_capture_sql_plan_baselines . Verify this by executing the following SQL statement from SQL Plus: show parameter optimizer_capture_sql_plan_baselines; If the parameter is set to true , this must be changed to false with the following SQL statement: alter system set optimizer_capture_sql_plan_baselines = false; Note! This must be run by a user with system administrator privileges. Security considerations File system For security reasons, access to configuration files like: mesh.json, authorisation groups file, private key (if stored in file system), etc. MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). Account running Mesh service MUST have access to those files. Database It is strongly recommended to configure the database connection to use encryption. This ensures that sensitive data, including credentials and queries, is protected from interception during transmission. mesh.json - complete Below is the complete mesh.json listed with all options with default values. { \"FailOnSyncErrors\": false, \"SerializationVersion\": 25, \"ComputerName\": \"localhost\", \"Log\": { \"Console\": true, // Log to stdout \"WindowsEventLog\": false, // Log to the Windows Event Log \"Directory\": \"C:\\\\Powel\\\\Mesh\\\\logs\", // Log to the given directory \"Level\": \"info\", // One of \"trace\", \"debug\", \"info\", \"warning\", \"error\", default \"info\" \"RequestLogging\": true, \"MaxLogFiles\": 10, // Maximum number of log files \"MaxLogSizeMb\": 10, // Maximum size of each log file in MB \"MaxRequestLogFiles\": 10, // Maximum number of request log files \"MaxRequestLogSizeMb\": 10 // Maximum size of each request log file in MB }, \"SynchronizationIntervalSeconds\": 30, \"Audit\": { \"Directory\": \"\", \"CircularLog\": true }, \"Oracle\": { \"ExternalCredentials\": false, \"ReadOnly\": false, \"Cleanup\": true, \"SerializableCleanup\": true, \"Server\": \"\", \"Username\": \"\", \"Password\": \"\", \"TimeseriesPointsSplit\": 8000000 }, \"HighAvailability\": { \"KillProcessOnSwitchingToInactiveMode\": true, \"UsePingPongProtection\": false, \"UseServersInActiveZoneInfo\": false, \"HeartbeatIntervalSeconds\": 10, \"HeartbeatValiditySeconds\": 20, \"AllTransactionsDeadlineSeconds\": 30, \"PingPongIntervalSeconds\": 600, \"PingPongMaxStartAttemptsWithinInterval\": 2, \"ServiceName\": \"Mesh\" }, \"HttpConfig\": { \"Port\": 20000, \"Kerberos\": true, \"HealthEnabled\": true }, \"Grpc\": { \"Kerberos\": true, \"OAuth\": false, \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"\", \"CertificateKeyPath\": \"\", \"WindowsCertStore\": { \"CertificateThumbprint\": \"\", \"SystemStoreName\": \"\" } }, \"Authorization\": { \"Audience\": \"\", \"JwksEndpoint\": \"\", \"Issuer\": \"\", \"Scope\": \"\", \"GroupsFile\": \"\", } }, \"Zmq\": { \"Threads\": 8, \"Kerberos\": true, \"Port\": 40321 }, \"SharedPointCache\": { \"LimitMb\": 1000, \"DefaultIntervalDays\": 20, \"PreloadAllTimeSeries\": true, \"PreloadPreviousState\": true, \"CacheStateFileDirectory\": \"<path>\" }, \"configPath\": \"\" } Contact information To purchase Volue software and additional licenses, please contact our sales staff or departmental managers. Software patches are normally placed on the support website, unless the patches are particularly large. To upgrade your Volue software with new releases or patches, please contact the support department by telephone or e-mail. Support will also answer your questions on software, patches or upgrades in general. Telephone: +47 73 80 45 10 E-mail: support@volue.com Web: www.volue.com","title":"Installation"},{"location":"mesh/installation/MeshServiceInstallationGuide/#mesh-service-installation-guide","text":"Mesh Service Installation Guide About this document Prerequisites System requirements Checklist before you start the installation General setup Hardware requirements Windows services and TCP communication Communication between Nimbus Client and Mesh server Install the Mesh Service Configuring core dump creation Configuration mesh.json - minimum version Database connection Mesh ports and authentication for ZMQ Mesh gRPC server Enable the server and configure port numbers Use Transport Layer Security (TLS) Certificates Loading certificates from file system Windows Certificate Store Authentication Kerberos OAuth 2.0 access tokens Access token types Configuration Authorisation Limit time series cache usage Verify the installation Update the Mesh object model Error situations General installation problems Problems related to Oracle 19 Security considerations mesh.json - complete Contact information","title":"Mesh Service Installation Guide"},{"location":"mesh/installation/MeshServiceInstallationGuide/#about-this-document","text":"This document describes how to install and upgrade the Mesh Service. Installation and upgrade follow the same steps. It is intended for a technical audience, to be used by system administrator/IT personnel or by Volue\u2019s consultants.","title":"About this document"},{"location":"mesh/installation/MeshServiceInstallationGuide/#prerequisites","text":"","title":"Prerequisites"},{"location":"mesh/installation/MeshServiceInstallationGuide/#system-requirements","text":"Operating system: Windows Server Standard 2019 or 2022, 64-bit SmG Database (with compatible SmG version) Microsoft Visual C++ Redistributable for Visual Studio 2015-2022 .NET Framework 4.8 Database upgrades are done via the SmG database upgrade. Ensure you have the correct version of SmG, see latest release notes. Note! Running more than one instance of Mesh against a single Oracle database may cause major errors. This configuration is only supported in some special cases.","title":"System requirements"},{"location":"mesh/installation/MeshServiceInstallationGuide/#checklist-before-you-start-the-installation","text":"Before installing the Mesh Service, ensure you have: Administrator access to the target server. The required Operating system installed on target server, see System requirements. The required Microsoft Visual C++ Redistributable installed on the target server, see System requirements. The information needed to connect to the Oracle database from the Mesh server. Usually a TNSNAMES.ora file, a database name, a username, and a password. The name of the directory containing TNSNAMES.ora should be specified in the TNS_ADMIN environment variable. The Mesh Service installation package.","title":"Checklist before you start the installation"},{"location":"mesh/installation/MeshServiceInstallationGuide/#general-setup","text":"","title":"General setup"},{"location":"mesh/installation/MeshServiceInstallationGuide/#hardware-requirements","text":"Note! You should dimension servers running Mesh to handle both high CPU load, expansive memory use and high I/O throughput regarding network interconnect towards the database. The results of requested calculations are kept in memory as much as possible; for this reason, we recommend a high amount of memory to gain optimal performance.","title":"Hardware requirements"},{"location":"mesh/installation/MeshServiceInstallationGuide/#windows-services-and-tcp-communication","text":"Windows Firewall with Advanced Security: For remote calls, you must set an inbound rule, allowing TCP connections in the following default ports: Port Direction Usage 1521 Outbound Default port to access the Oracle database 9000 Inbound Http communication from Nimbus 9001 Inbound Net.Tcp communication from Nimbus 20000 Inbound Access to the Mesh health endpoint, used from Nimbus when failover is configured 40321 Inbound ZMQ communication 50051 Inbound Communication from clients using gRPC","title":"Windows services and TCP communication"},{"location":"mesh/installation/MeshServiceInstallationGuide/#communication-between-nimbus-client-and-mesh-server","text":"Port 20000 must be open on the server where the Mesh server is installed in order to avoid performance issues in the Nimbus Client connected to Mesh. In addition, port 20000 is needed if failover of the Nimbus Client against the Mesh server is required.","title":"Communication between Nimbus Client and Mesh server"},{"location":"mesh/installation/MeshServiceInstallationGuide/#install-the-mesh-service","text":"Mesh Service is a Windows service. It can run as a user member of the local Administrator group or as a user with log on as a service rights. The installer is distributed as a ZIP file named like Mesh-2.12.1.21.zip. To install the Mesh Service: Extract the zip file containing the installation package to desired location. Navigate to this location and run: .\\mesh.ps1 -Install -UrlAclUser BUILTIN\\Users This script will register necessary endpoints and create a Windows service named Powel Mesh Service .","title":"Install the Mesh Service"},{"location":"mesh/installation/MeshServiceInstallationGuide/#configuring-core-dump-creation","text":"A core dump is an image of the process and all of its memory at a point in time. These dumps make it significantly easier to debug and fix errors. We recommend that all users enable automatic core dumps for the Mesh process, and that core dumps for any crashes are sent to the Volue Support together with the Mesh log and any information about what was happening in the system at the time of the crash. See https://docs.microsoft.com/en-us/windows/win32/wer/collecting-user-mode-dumps for more information on how to collect core dumps. Alternatively set the following registry values under HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\Windows Error Reporting\\LocalDumps\\Powel.Mesh.Server.exe : Parameter Type Value REG_EXPAND_SZ DumpFolder C:\\MeshCoreDumps REG_DWORD DumpType 2 REG_DWORD DumpCount 10 The size of a Mesh core dump with the configuration above is equal to the memory used by Mesh at the time of the dump. If disk space is an issue you may reduce DumpCount, or set DumpType to 1 which makes the dumps smaller but less useful.","title":"Configuring core dump creation"},{"location":"mesh/installation/MeshServiceInstallationGuide/#configuration","text":"After the service is installed, the following configuration is required. Database connection Mesh ports and authentication for ZMQ Mesh gRPC server Use Transport Layer Security (TLS) Authentication Authorisation Limit cache","title":"Configuration"},{"location":"mesh/installation/MeshServiceInstallationGuide/#meshjson-minimum-version","text":"The Mesh configuration is defined in the mesh.json file which normally is located in the directory above the Mesh service application ( Powel.Mesh.Server.exe ). A minimal configuration looks like this: { \"Log\": { \"Console\": true, // Log to stdout when not run as a service \"WindowsEventLog\": false, // Log to the Windows Event Log \"Directory\": \"C:\\\\Powel\\\\Mesh\\\\logs\", // Log to the given directory \"Level\": \"info\" // One of \"trace\", \"debug\", \"info\", \"warning\", \"error\", default \"info\" }, \"Oracle\": { \"Server\": \"<DatabaseServer>\", \"Username\": \"<DatabaseUser>\", \"Password\": \"<DatabasePassword>\" }, \"Http\": { \"Port\": 20000, \"Kerberos\": true, \"Health\": true // Enable the health endpoint. }, \"Grpc\": { \"Address\": \"[::]:50051\", \"Kerberos\": true, \"Tls\": { \"CertificatePath\": \"<PathToCertificateInPEMFormat>\", \"CertificateKeyPath\": \"<PathToPrivateKeyInPEMFormat>\" } }, \"Zmq\": { \"Port\": 40321, \"Kerberos\": true } }","title":"mesh.json - minimum version"},{"location":"mesh/installation/MeshServiceInstallationGuide/#database-connection","text":"The Mesh database is part of the SmG database. The Mesh service has to connect and operate on the SmG database as the SmG Schema Owner. There are 2 ways of connecting to the database. Using credentials or using external authentication. You define the database connection string in mesh.json :","title":"Database connection"},{"location":"mesh/installation/MeshServiceInstallationGuide/#credentials","text":"\"Oracle\": { \"Server\": \"<Database>\", \"Username\": \"<DatabaseUser>\", \"Password\": \"<DatabasePassword>\" }, Verify that the values in these files are correct by executing the following statement from command prompt: sqlplus <DatabaseUser>/<DatabasePassword>@<Database>","title":"Credentials"},{"location":"mesh/installation/MeshServiceInstallationGuide/#oracle-external-authentication","text":"To use it: - The database server must be configured to support external authentication and the account running Mesh service must be granted proper privileges in the database. The following privileges are required: - execute on sys.dbms_lock - execute on sys.dbms_change_notification - change notification - On the client side (i.e. server running Mesh service) the Oracle client must be configured to use NTS authentication. See sqlnet.ora file: SQLNET.AUTHENTICATION_SERVICES= (NTS) - On the client side, set ExternalCredentials parameter to true in the Oracle section in mesh.json configuration file: json \"Oracle\": { \"Server\": \"<Database>\", \"ExternalCredentials\": true }","title":"Oracle external authentication"},{"location":"mesh/installation/MeshServiceInstallationGuide/#mesh-ports-and-authentication-for-zmq","text":"In the Mesh configuration file mesh.json the lines are used (with default values): \"Zmq\": { \"Threads\": 8, //optional \"Kerberos\": true, \"Port\": 40321 }, This defines which port Mesh use to listen for ZMQ requests. This port number must be the same in clients using ZMQ. The firewall must also be open on this port. Kerberization of ZMQ, is by default turned on. Clients using ZMQ are all Smart Power clients interfacing with Mesh, except Mesh Data Transfer.","title":"Mesh ports and authentication for ZMQ"},{"location":"mesh/installation/MeshServiceInstallationGuide/#mesh-grpc-server","text":"A gRPC interface is exposed for both external and internal usage. There is also a gRPC client, Mesh Python SDK , that uses the gRPC interface and provides an easy and optimised way of working with Mesh for Python developers. Note! The Mesh gRPC interface is still in alpha. The interface is changing rapidly, breaking changes are allowed and stability is not guaranteed nor expected.","title":"Mesh gRPC server"},{"location":"mesh/installation/MeshServiceInstallationGuide/#enable-the-server-and-configure-port-numbers","text":"To enable Mesh gRPC server, configure the following lines in the Mesh configuration file mesh.json . \"Grpc\": { \"Kerberos\": true, \"OAuth\": false, \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"<PathToCertificateInPEMFormat>\", \"CertificateKeyPath\": \"<PathToPrivateKeyInPEMFormat>\" } }, This defines which port Mesh uses to listen for gRPC requests. This port number must be the same in the clients using gRPC. The firewall must also be open on this port. The example shows an unencrypted and unauthenticated configuration, and we highly recommend to both encrypt and authenticate/authorize the gRPC interface (see below for how to configure it).","title":"Enable the server and configure port numbers"},{"location":"mesh/installation/MeshServiceInstallationGuide/#use-transport-layer-security-tls","text":"There are two possible types of connections to the gRPC server from the clients. An insecure, where data is unencrypted and sent as plaintext over the network, thus it is not recommended for production environment. A secure where the server is authenticated by the clients via the Transport Layer Security (TLS protocol) certificate and data is encrypted. Mesh server gRPC interface can be configured to use Transport Layer Security (TLS) and if used then only TLS connections from the clients will be accepted. The TLS server authentication serves two purposes: It authenticates the server, a client that connects to a server can verify the server's certificate and check if it is trusted . It encrypts the communication, by using HTTPS as a transport protocol. For security reasons, encryption is required for client authentication and authorisation.","title":"Use Transport Layer Security (TLS)"},{"location":"mesh/installation/MeshServiceInstallationGuide/#certificates","text":"TLS uses X.509 digital certificates, further on referred as TLS certificate. Such certificate contains, among others, public key and information about the issuer. Additionally for each TLS certificate there is a corresponding private key. Contrary to the public key, it is a secret and must be kept secure. The Mesh team requires/strongly advises to use certificates signed by publicly trusted Certificate Authorities (CAs). Such certificates can be obtained for free and they ensure no additional configuration is needed to be done on the client side in order to connect to a TLS secured Mesh gRPC server. On the other hand using self-signed certificates, depending on the client environment, may require configuration work in order to connect to a TLS secured Mesh gRPC server. That is why we require/strongly suggest using the former type of certificates. For more information see the document about client certificates. Note! As Volue we do not suggest using specific TLS certificate vendors. We provide a set of guidelines and requirements. The final decision belongs to the customer. By default Mesh configuration ( mesh.json ) has the TLS enabled, but the certificate settings must be set manually for each environment. There are two options to load the certificates.","title":"Certificates"},{"location":"mesh/installation/MeshServiceInstallationGuide/#loading-certificates-from-file-system","text":"Providing paths to certificate and private key in PEM format. The files mustn't be encrypted and must be accessible by the account that is running Mesh server. \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, ... }, For security reasons, access to private key MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege).","title":"Loading certificates from file system"},{"location":"mesh/installation/MeshServiceInstallationGuide/#windows-certificate-store","text":"Alternatively the certificates can be loaded from the Windows Certificate Store. To use it: The private key must be marked as \"exportable\" in the Windows Certificate Store. The certificate must have a corresponding private key defined in the Windows Certificate Store. The certificate must be accessible by the user account that is running Mesh. All current user certificate stores except the Current User/Personal store inherit the contents of the local machine certificate stores. Moreover, currently the support is limited to private keys based on the RSA algorithm. To enable reading certificate from the Windows Certificate Store you need to specify: { \"Grpc\": { \"Tls\": { \"WindowsCertStore\": { \"CertificateThumbprint\": \"142e888b1640210e83b1c21b6fc414aefb1f8813\", \"SystemStoreName\": \"ROOT\" } }, ... } } Parameters: CertificateThumbprint is a 160 bit SHA1 hash. Listed in the certificate details section. SystemStoreName name of the system store. Some predefined system stores are: ROOT - mapping to *Trusted Root Certification Authorities\" MY - mapping to Personal CA - mapping to *Intermediate Certification Authorities\"","title":"Windows Certificate Store"},{"location":"mesh/installation/MeshServiceInstallationGuide/#authentication","text":"Mesh server could be configured to protect its gRPC API so that only authenticated users that are assigned to specific roles can access it. There are two options: Kerberos OAuth 2.0 access tokens Note! If the Mesh gRPC server is configured to use authentication, only authenticated users may work with Mesh.","title":"Authentication"},{"location":"mesh/installation/MeshServiceInstallationGuide/#kerberos","text":"Mesh authenticates users and grants access to specific APIs based on what AD groups the authenticated users belong to. Configuration: \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, \"Kerberos\": true, \"Authorization\": { \"GroupsFile\": \"roles_mapping.json\" }, ... } If the gRPC client runs as \"Local System\" then in calls to Mesh it is represented as the machine account itself. If Mesh service is running on the same machine then in such cases the gRPC client belongs to \"System\" group. This is useful in cases where for example: customers do not want to create extra service accounts for Mesh Data Transfer services that are running locally. Example groups file: { \"Kerberos\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], // For localhost services running as \"Local System\" \"System\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } } Mesh clients need to provide a service principal name (SPN) when connecting to Mesh with Kerberos enabled. If Mesh is running as AD User: Start Windows Server PowerShell and enter: Get-ADUser -Filter {UserPrincipalName -eq \"user.name@domain.com\"} | Select-Object SamAccountName Then check if SPN exists: setspn -L SamAccountName setspn -L domain\\SamAccountName Depending on the SPN found, use it as the service principal name in clients like Mesh Data Transfer. If Mesh is running as a machine user (like Local System): Then the service principal name will usually be HOST/full.qualified.domain.name or HOST/f.q.d.n@DOMAIN.COM but it might be different in your environment.","title":"Kerberos"},{"location":"mesh/installation/MeshServiceInstallationGuide/#oauth-20-access-tokens","text":"The users authenticate and request access to Mesh from external authorisation servers, and Mesh validates the access token that is obtained from the authorisation server. OAuth 2.0 is an industry-standard protocol for authorisation. Depending on the Identity Provider implementing the OAuth 2.0 protocol, there might be some differences in the access token structure, flows, etc. Implementation of Mesh server OAuth authorisation was tested against Microsoft Entra ID (previously known as Azure Active Directory) Identity Provider and supports: user access tokens acquired by using authorisation code flow (token version 1 and 2) application-only access tokens acquired by using client credentials flow (token version 1 and 2) We do not guarantee that authorisation based on other Identity Providers will work.","title":"OAuth 2.0 access tokens"},{"location":"mesh/installation/MeshServiceInstallationGuide/#access-token-types","text":"We distinguish between user and application-only access tokens: User access token - User tokens are used for flows like authorisation code flow where a user is authenticated and gives consent to the requested permissions. User access tokens must include scope ( scp or scope ) and name claims. Application-only access tokens - Application-only access tokens are acquired using client credentials flow. They are used in server-to-server interactions, where the client applications are referred to as daemons or service accounts . In this flow the client application is called confidential client. Contrary to user access tokens the application-only access tokens in Microsoft Entra do not contain scope ( scp or scope ) and name claims. Application-only access tokens have the same values of sub and oid claims. The client application must use authorisation based on application permissions (app roles) . With this approach the roles claim will be part of the access token.","title":"Access token types"},{"location":"mesh/installation/MeshServiceInstallationGuide/#configuration_1","text":"To use it: An OAuth 2.0 JWT compatible access token must be signed using RSA algorithm. Authorisation is done using roles claim that must be part of the access token. Additionally, all access tokens must contain the following claims: oid, aud, iss and sub. All those claims must have string data types (not an array). Additionally, user access tokens must contain scope (scp or scope) and name claims. All those claims must have string data types (not an array). TLS connection must be enabled. To enable OAuth support you need to specify (change the values according to customer's environment): \"Grpc\": { \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"C:\\\\certs\\\\certificate.crt\", \"CertificateKeyPath\": \"C:\\\\certs\\\\privatekey.pem\" }, \"OAuth\": true, \"Authorization\": { \"Audience\": \"api://CLIENT_ID\", \"JwksEndpoint\": \"https://login.microsoftonline.com/TENANT_ID/discovery/v2.0/keys\", \"Issuer\": \"https://sts.windows.net/TENANT_ID/\", \"Scope\": \"mesh.grpc\", // this is required for user access tokens, not used for application-only access tokens \"GroupsFile\": \"roles_mapping.json\" }, ... } Note that Kerberos is enabled by default. Parameters: JwksEndpoint - JSON Web Key Set (JWKS) endpoint URI. JWKS contains all public keys needed to validate (check signature) generated access token by the authorisation server. Audience - audience token claim. Must match aud token claim. Depending on the access token version, the expected format may be different. For v1.0 tokens it may have the \u201capi://\u201d prefix. For v2.0 tokens it is always just a client ID. It is best to check decode access token in e.g. jwt.io website and check the actual aud claim value. Issuer - issuer token claim. Must match iss token claim. Scope - scope token claim. Must match scp or scope token claim. The check is done only for user access tokens. GroupsFile - JSON file that maps roles to specific permissions in our API. Example groups file: { \"OAuth\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], \"Daemons\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } }","title":"Configuration"},{"location":"mesh/installation/MeshServiceInstallationGuide/#authorisation","text":"We can limit access to Mesh functionality through the gRPC interface to the following groups: time_series - functionality accessing time series values. model - functionality accessing the model and model definition instances. For each of these groups it is possible to limit access to the normal CRUD operations: create - functionality that will create new information. read - functionality that will read information without changing anything. update - functionality that will update existing information. delete - functionality that will delete existing information. The GroupsFile defines the access to the different functionality for any user dependent on which groups or roles this user is assigned to in the company's user store. An example of such a definition is shown below giving all users in the Users group/role only read access to time series and model, while users in the Admins or Daemons group/role has full access to time series and model. When a user is a member of multiple groups or assigned multiple roles, their effective access rights are the union of the rights granted by each group and role. For security reasons, access to GroupsFile MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). The Kerberos group names and OAuth roles mappings are defined separately. { \"Kerberos\": { \"Users\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], \"Daemons\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ], // For localhost services running as \"Local System\" \"System\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] }, // if both OAuth and Kerberos are enabled: \"OAuth\": { \"OAuthUsers\": [\"(time_series, read)\", \"(model, read)\"], \"Admins\": [ \"(time_series, create)\", \"(time_series, read)\", \"(time_series, update)\", \"(time_series, delete)\", \"(model, create)\", \"(model, read)\", \"(model, update)\", \"(model, delete)\" ] } }","title":"Authorisation"},{"location":"mesh/installation/MeshServiceInstallationGuide/#limit-time-series-cache-usage","text":"By default, Mesh will read into memory all time series values found in the database for the requested time series and these values will stay in memory as long as the service is running. It is possible to limit/control the memory usage by the cache by adding the following configuration: \"SharedPointCache\": { \"LimitMb\": 1000, \"DefaultIntervalDays\": 20, \"PreloadAllTimeSeries\": false, \"PreloadPreviousState\": false, \"CacheStateFileDirectory\": \"<path>\" }, Parameters: LimitMb - the maximum number of megabytes allowed in the shared point cache. DefaultIntervalDays - when the preloading is enabled Mesh will not preload points before now minus the configured number of days. PreloadAllTimeSeries - if set to true , Mesh will preload all physical time series points on startup. PreloadPreviousState - if set to true , Mesh will preload previous cache state on startup. If both PreloadAllTimeSeries and PreloadPreviousState is set to true at the same time, Mesh will first preload the previous cache state and then the other time series values. CacheStateFileDirectory - path to the directory where Mesh persists the cache state. Note! Most installations should not have to change the default configuration, except the CacheStateFileDirectory field, as it is related to the memory/performance tuning. For security reasons, access to CacheStateFileDirectory should be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege).","title":"Limit time series cache usage"},{"location":"mesh/installation/MeshServiceInstallationGuide/#verify-the-installation","text":"To verify the installation: Check that the service is running. Run tests using the service, e.g. the Mesh Configurator or Nimbus. Note! You must be member of the correct security group to start Mesh Configurator.","title":"Verify the installation"},{"location":"mesh/installation/MeshServiceInstallationGuide/#update-the-mesh-object-model","text":"There will be a new version of the Mesh object model (EnergySystem) delivered with each release. The installed object model must be updated to the latest version for the applications using Mesh to work correctly. As part of a Smart Power release there exists a separate package named ModelUpdate.zip that contains the new model together with scripts and descriptions of how to update the Mesh model.","title":"Update the Mesh object model"},{"location":"mesh/installation/MeshServiceInstallationGuide/#error-situations","text":"","title":"Error situations"},{"location":"mesh/installation/MeshServiceInstallationGuide/#general-installation-problems","text":"If errors occur during installation, you should: Verify that you have followed the prerequisite steps, see Prerequisites. Verify that the installation is complete, see What the installer does. Verify the configurations, see Server manager configuration and Application configuration. Verify that the user executing the Mesh service is administrator or has been granted appropriate privileges (Logon as a Service, Logon as a Batch Job, URL ACLs). The Mesh Service logs service calls and errors to the Windows Event Log. The relevant source names for log entries are Powel Mesh and Powel.Object.Structure.Service .","title":"General installation problems"},{"location":"mesh/installation/MeshServiceInstallationGuide/#problems-related-to-oracle-19","text":"If you get the error message ORA-22922: nonexistent LOB value , that may be caused by an incorrect value ( true ) for the Oracle init parameter optimizer_capture_sql_plan_baselines . Verify this by executing the following SQL statement from SQL Plus: show parameter optimizer_capture_sql_plan_baselines; If the parameter is set to true , this must be changed to false with the following SQL statement: alter system set optimizer_capture_sql_plan_baselines = false; Note! This must be run by a user with system administrator privileges.","title":"Problems related to Oracle 19"},{"location":"mesh/installation/MeshServiceInstallationGuide/#security-considerations","text":"","title":"Security considerations"},{"location":"mesh/installation/MeshServiceInstallationGuide/#file-system","text":"For security reasons, access to configuration files like: mesh.json, authorisation groups file, private key (if stored in file system), etc. MUST be restricted at the operating-system level. Grant permissions only to the specific users or groups that require access (principle of least privilege). Account running Mesh service MUST have access to those files.","title":"File system"},{"location":"mesh/installation/MeshServiceInstallationGuide/#database","text":"It is strongly recommended to configure the database connection to use encryption. This ensures that sensitive data, including credentials and queries, is protected from interception during transmission.","title":"Database"},{"location":"mesh/installation/MeshServiceInstallationGuide/#meshjson-complete","text":"Below is the complete mesh.json listed with all options with default values. { \"FailOnSyncErrors\": false, \"SerializationVersion\": 25, \"ComputerName\": \"localhost\", \"Log\": { \"Console\": true, // Log to stdout \"WindowsEventLog\": false, // Log to the Windows Event Log \"Directory\": \"C:\\\\Powel\\\\Mesh\\\\logs\", // Log to the given directory \"Level\": \"info\", // One of \"trace\", \"debug\", \"info\", \"warning\", \"error\", default \"info\" \"RequestLogging\": true, \"MaxLogFiles\": 10, // Maximum number of log files \"MaxLogSizeMb\": 10, // Maximum size of each log file in MB \"MaxRequestLogFiles\": 10, // Maximum number of request log files \"MaxRequestLogSizeMb\": 10 // Maximum size of each request log file in MB }, \"SynchronizationIntervalSeconds\": 30, \"Audit\": { \"Directory\": \"\", \"CircularLog\": true }, \"Oracle\": { \"ExternalCredentials\": false, \"ReadOnly\": false, \"Cleanup\": true, \"SerializableCleanup\": true, \"Server\": \"\", \"Username\": \"\", \"Password\": \"\", \"TimeseriesPointsSplit\": 8000000 }, \"HighAvailability\": { \"KillProcessOnSwitchingToInactiveMode\": true, \"UsePingPongProtection\": false, \"UseServersInActiveZoneInfo\": false, \"HeartbeatIntervalSeconds\": 10, \"HeartbeatValiditySeconds\": 20, \"AllTransactionsDeadlineSeconds\": 30, \"PingPongIntervalSeconds\": 600, \"PingPongMaxStartAttemptsWithinInterval\": 2, \"ServiceName\": \"Mesh\" }, \"HttpConfig\": { \"Port\": 20000, \"Kerberos\": true, \"HealthEnabled\": true }, \"Grpc\": { \"Kerberos\": true, \"OAuth\": false, \"Address\": \"[::]:50051\", \"Tls\": { \"CertificatePath\": \"\", \"CertificateKeyPath\": \"\", \"WindowsCertStore\": { \"CertificateThumbprint\": \"\", \"SystemStoreName\": \"\" } }, \"Authorization\": { \"Audience\": \"\", \"JwksEndpoint\": \"\", \"Issuer\": \"\", \"Scope\": \"\", \"GroupsFile\": \"\", } }, \"Zmq\": { \"Threads\": 8, \"Kerberos\": true, \"Port\": 40321 }, \"SharedPointCache\": { \"LimitMb\": 1000, \"DefaultIntervalDays\": 20, \"PreloadAllTimeSeries\": true, \"PreloadPreviousState\": true, \"CacheStateFileDirectory\": \"<path>\" }, \"configPath\": \"\" }","title":"mesh.json - complete"},{"location":"mesh/installation/MeshServiceInstallationGuide/#contact-information","text":"To purchase Volue software and additional licenses, please contact our sales staff or departmental managers. Software patches are normally placed on the support website, unless the patches are particularly large. To upgrade your Volue software with new releases or patches, please contact the support department by telephone or e-mail. Support will also answer your questions on software, patches or upgrades in general. Telephone: +47 73 80 45 10 E-mail: support@volue.com Web: www.volue.com","title":"Contact information"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/","text":"General introduction Mesh operates under a few basic assumptions: Every object has a unique GUID. Every object is able to do binary serialization (read/write). Every object has an associated version number. \"Model definition\" vs \"model\" A model definition is a description of a domain with respect to object types, attributes, and relations. It defines what information is available through Mesh for this domain. An instance of a model definition is simply called a \"model\". See also the Mesh Glossary . The EnergySystem model definition This is the Mesh model definition made by Volue to cover the information needed by the Mesh connected modules. It defines the basic types to describe a hydro/thermal/wind system, case management and time series quality related to this. Customer extensions An important point in Mesh modelling is the capability for customers, and specific projects, to extend the EnergySystem model definition. This can be: Adding new attributes to existing types. Modifying time series calculation expressions initially provided by Volue. Modifying time series attributes to have an expression. Adding new object types. Making new connections between objects. This feature is widely used in large projects, but also applicable for smaller customers. Managing customer extensions Currently this is supported by use of Mesh namespaces. Changes made by customer/projects end up in the Custom namespace. This basic configuration also prevents customers from making changes on mandatory parts of the model definition. It's a simple solution while waiting for a full blown authentication/authorization feature. Current process Master model The master model definition is maintained through a server owned by Volue connected to an Oracle database. Model definition update Mesh model definitions can be exported into a binary file by using the Model.ImportExport tool. These binaries normally have an .mdump extension and are not human-readable (and thus not suited for regular version control systems). The scope of the export can be specified through CLI options. The exports can also include the corresponding model instances from the model definitions. Model.ImportExport can also be used to import .mdump files into a target system in order to perform an update of the model definition. A successful update of the model definition will include saving the target binary file as a Mesh resource, located in a folder called ObjectModelUpdates . The resource's name will consist of the name of the model definition and a timestamp. This storage is actively used to retrieve the base for delta-based updates. In practice, model definition updates are done by using a script called ModelUpdate.ps1 which is distributed alongside release packages. However, this document dwelves deeper into the underlying process for updating, and indicates some of the problems that may arise along the way. Throughout this document (and other literature) we'll use the term \"model update\" to refer to an update of the model definition (as well as its derived models). Delta-based updates This is the preferred approach for model updates. It performs the following steps: Get the differences between the model definition which is currently installed on the target system ( Base ) and the new one to be installed ( New ). These can include: Objects that exist in both versions, but are different (marked for updating). Objects that exist in New but not in Base , i.e. created after the Base installation (marked as new). Objects that exist in Base but not in New , i.e. removed from the model definition since the Base installation (marked for deletion). Push the changes found in the previous point onto the target system. In our current process, Base is the latest master model definition which the customer has installed (and potentially expanded on) on the target system, and New is a newer master model definition. The customer's own changes to the model definition are not taken into account when calculating the delta between Base and New . Assign-based (\"on-top\") updates This approach should be avoided, but experience shows that this sometimes may be the only way to fix some problematic cases. It's similar to forcing the model definition to change into a new state. It performs the following steps: Push objects from the New model definition to the target system. If the target system accepts the incoming changes, it becomes the new model definition. This operation does not delete anything, just stores unconditionally on top of the existing state. Alternatively, it is possible to specify that only whatever's missing should be imported by passing the -w ImportOnlyMissingElementTypesAndDefinitions option to the Model.ImportExport tool. Challenges related to current approach/toolset Delta-based Prior to the last step (push), the Model.ImportExport tool will check the following: Problem D1: An object is marked as new on the, but this object does exist on the target system (based on ID lookup). Problem D2: An object marked for updating does not exist on the target system. Problem D3: An object marked for deletion does not exist on the target system. Problem D4: An object is marked for updating, but is really a switch between a time series attribute being a calculation or not. Problem D5: Version number conflicts. For example, pushing a version with a lower number than the target object's. In general, the versioning is not active by default on Model.ImportExport due to the lack of a global version number that can be applied across database instances. The reason behind problems D1..D3 is hard to determine. Some probably come from the target system missing validations and accepting operations that should not be allowed/authorized. Another reason could be a wrong understanding of the latest installed master model definition ( Base ) when doing version comparison. An \"on-top\" update can probably also lead to a situation like this, for instance because parts that should be removed from the model definition are still not removed. There exist some other problems as well: Problem D6: Assume that there have been changes to an expression both in the master model definition and the customer's target system. In this case the delta-based import will favor the changes from the master model definition over the customer's. Problem D7: An attribute has been removed from the master model definition, and then recreated on master with the same name. Since the re-created object will now have a different GUID, this will appear as a new object in the delta update cause a duplicate name conflict on the target system. As a side note, in the past there had been issues arising from conflicts related to the usage of PDCTimeseriesReferenceEntity , which is no longer used in our master model definitions. Since delta updates only handle differences between two versions of master, this means that such conflicts should no longer apply. Note that there can be still some PDCTimeseriesReferenceEntity objects in the customers' own models, but they won't be affected by the delta import since they're created by the customers themselves. Assign-based (\"on-top\") The following problems can appear on this approach: Problem A1: Some enumeration values related to no value seem to be recreated (especially the Undefined value) with a new GUID. This dangling definition may also create problems on imports. Problem A2: Because this approach does not delete anything, the target model definition may end up in a situation where leftovers from a previous version can create problems at some point. An immediate problem is e.g. when the master definition has changed the type of a given attribute, such as from double to integer, which would change the attribute's GUID. If the attribute's name remains the same, a conflict would arise when trying to perform the update. Problem A3: The version of the model definition stored in the ObjectModelUpdates resource folder will not give a correct picture of the updated state (ref Problem A2). This may create problems on later attempts to do delta-based updates. Example Consider the following sequence: Step 1 A Mesh model definition (MD) is in a master state 1. It is installed on a target system. This should be straightforward, no problems at all. The MD 1 is also stored as a file inside Mesh Resources, within the ObjectModelUpdates folder. Step 2 The master model definition is extended, and the version 3 is going to be updated on the target system. There have been no customer changes on the MD on the target system at this point. A delta update is provided from MD 3 \"minus\" MD 1, illustrated as triangle a . There should be no problems doing this update. The ObjectModelUpdates folder will now also contain the MD 3. Step 3 Now we wish to update the target system to master version 6, but the MD on the target system has been modified as well by the customer. However, as the figure shows, these changes merely extend the target system's MD, but do not modify the \"core\" MD 3. The delta update b is done based on master MD 6 minus master MD 3. There should be no problems doing this update either. The ObjectModelUpdates folder will now also contain the MD 6. Step 4 As before, we wish to update the target system to MD 7. However, in this case there have been customer changes on core parts of the MD originating from master (represented by the two extra boxes within the MD), so that the delta update c would be in conflict with such customer changes. A merge conflict will happen in this case, with some of the problems indicated by D1..D4 above. If there are changes on both master and target system, the master definition will be pushed. In many cases this is accepted by the target system, so that the master MD is favored over the local one. Summary This document provides some background information on the process of model definition maintenance. It shows that there are basic features in the tools supporting the maintenance process. Experience shows that problems may arise, which must be worked around using miscellaneous cleanup tools. In some cases, the only solution is to perform an \"on-top\" model update, which is not usually recommended because it can cause further problems later on.","title":"Model maintenance"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#general-introduction","text":"Mesh operates under a few basic assumptions: Every object has a unique GUID. Every object is able to do binary serialization (read/write). Every object has an associated version number.","title":"General introduction"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#model-definition-vs-model","text":"A model definition is a description of a domain with respect to object types, attributes, and relations. It defines what information is available through Mesh for this domain. An instance of a model definition is simply called a \"model\". See also the Mesh Glossary .","title":"\"Model definition\" vs \"model\""},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#the-energysystem-model-definition","text":"This is the Mesh model definition made by Volue to cover the information needed by the Mesh connected modules. It defines the basic types to describe a hydro/thermal/wind system, case management and time series quality related to this.","title":"The EnergySystem model definition"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#customer-extensions","text":"An important point in Mesh modelling is the capability for customers, and specific projects, to extend the EnergySystem model definition. This can be: Adding new attributes to existing types. Modifying time series calculation expressions initially provided by Volue. Modifying time series attributes to have an expression. Adding new object types. Making new connections between objects. This feature is widely used in large projects, but also applicable for smaller customers.","title":"Customer extensions"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#managing-customer-extensions","text":"Currently this is supported by use of Mesh namespaces. Changes made by customer/projects end up in the Custom namespace. This basic configuration also prevents customers from making changes on mandatory parts of the model definition. It's a simple solution while waiting for a full blown authentication/authorization feature.","title":"Managing customer extensions"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#current-process","text":"","title":"Current process"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#master-model","text":"The master model definition is maintained through a server owned by Volue connected to an Oracle database.","title":"Master model"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#model-definition-update","text":"Mesh model definitions can be exported into a binary file by using the Model.ImportExport tool. These binaries normally have an .mdump extension and are not human-readable (and thus not suited for regular version control systems). The scope of the export can be specified through CLI options. The exports can also include the corresponding model instances from the model definitions. Model.ImportExport can also be used to import .mdump files into a target system in order to perform an update of the model definition. A successful update of the model definition will include saving the target binary file as a Mesh resource, located in a folder called ObjectModelUpdates . The resource's name will consist of the name of the model definition and a timestamp. This storage is actively used to retrieve the base for delta-based updates. In practice, model definition updates are done by using a script called ModelUpdate.ps1 which is distributed alongside release packages. However, this document dwelves deeper into the underlying process for updating, and indicates some of the problems that may arise along the way. Throughout this document (and other literature) we'll use the term \"model update\" to refer to an update of the model definition (as well as its derived models).","title":"Model definition update"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#delta-based-updates","text":"This is the preferred approach for model updates. It performs the following steps: Get the differences between the model definition which is currently installed on the target system ( Base ) and the new one to be installed ( New ). These can include: Objects that exist in both versions, but are different (marked for updating). Objects that exist in New but not in Base , i.e. created after the Base installation (marked as new). Objects that exist in Base but not in New , i.e. removed from the model definition since the Base installation (marked for deletion). Push the changes found in the previous point onto the target system. In our current process, Base is the latest master model definition which the customer has installed (and potentially expanded on) on the target system, and New is a newer master model definition. The customer's own changes to the model definition are not taken into account when calculating the delta between Base and New .","title":"Delta-based updates"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#assign-based-on-top-updates","text":"This approach should be avoided, but experience shows that this sometimes may be the only way to fix some problematic cases. It's similar to forcing the model definition to change into a new state. It performs the following steps: Push objects from the New model definition to the target system. If the target system accepts the incoming changes, it becomes the new model definition. This operation does not delete anything, just stores unconditionally on top of the existing state. Alternatively, it is possible to specify that only whatever's missing should be imported by passing the -w ImportOnlyMissingElementTypesAndDefinitions option to the Model.ImportExport tool.","title":"Assign-based (\"on-top\") updates"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#challenges-related-to-current-approachtoolset","text":"","title":"Challenges related to current approach/toolset"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#delta-based","text":"Prior to the last step (push), the Model.ImportExport tool will check the following: Problem D1: An object is marked as new on the, but this object does exist on the target system (based on ID lookup). Problem D2: An object marked for updating does not exist on the target system. Problem D3: An object marked for deletion does not exist on the target system. Problem D4: An object is marked for updating, but is really a switch between a time series attribute being a calculation or not. Problem D5: Version number conflicts. For example, pushing a version with a lower number than the target object's. In general, the versioning is not active by default on Model.ImportExport due to the lack of a global version number that can be applied across database instances. The reason behind problems D1..D3 is hard to determine. Some probably come from the target system missing validations and accepting operations that should not be allowed/authorized. Another reason could be a wrong understanding of the latest installed master model definition ( Base ) when doing version comparison. An \"on-top\" update can probably also lead to a situation like this, for instance because parts that should be removed from the model definition are still not removed. There exist some other problems as well: Problem D6: Assume that there have been changes to an expression both in the master model definition and the customer's target system. In this case the delta-based import will favor the changes from the master model definition over the customer's. Problem D7: An attribute has been removed from the master model definition, and then recreated on master with the same name. Since the re-created object will now have a different GUID, this will appear as a new object in the delta update cause a duplicate name conflict on the target system. As a side note, in the past there had been issues arising from conflicts related to the usage of PDCTimeseriesReferenceEntity , which is no longer used in our master model definitions. Since delta updates only handle differences between two versions of master, this means that such conflicts should no longer apply. Note that there can be still some PDCTimeseriesReferenceEntity objects in the customers' own models, but they won't be affected by the delta import since they're created by the customers themselves.","title":"Delta-based"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#assign-based-on-top","text":"The following problems can appear on this approach: Problem A1: Some enumeration values related to no value seem to be recreated (especially the Undefined value) with a new GUID. This dangling definition may also create problems on imports. Problem A2: Because this approach does not delete anything, the target model definition may end up in a situation where leftovers from a previous version can create problems at some point. An immediate problem is e.g. when the master definition has changed the type of a given attribute, such as from double to integer, which would change the attribute's GUID. If the attribute's name remains the same, a conflict would arise when trying to perform the update. Problem A3: The version of the model definition stored in the ObjectModelUpdates resource folder will not give a correct picture of the updated state (ref Problem A2). This may create problems on later attempts to do delta-based updates.","title":"Assign-based (\"on-top\")"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#example","text":"Consider the following sequence:","title":"Example"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#step-1","text":"A Mesh model definition (MD) is in a master state 1. It is installed on a target system. This should be straightforward, no problems at all. The MD 1 is also stored as a file inside Mesh Resources, within the ObjectModelUpdates folder.","title":"Step 1"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#step-2","text":"The master model definition is extended, and the version 3 is going to be updated on the target system. There have been no customer changes on the MD on the target system at this point. A delta update is provided from MD 3 \"minus\" MD 1, illustrated as triangle a . There should be no problems doing this update. The ObjectModelUpdates folder will now also contain the MD 3.","title":"Step 2"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#step-3","text":"Now we wish to update the target system to master version 6, but the MD on the target system has been modified as well by the customer. However, as the figure shows, these changes merely extend the target system's MD, but do not modify the \"core\" MD 3. The delta update b is done based on master MD 6 minus master MD 3. There should be no problems doing this update either. The ObjectModelUpdates folder will now also contain the MD 6.","title":"Step 3"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#step-4","text":"As before, we wish to update the target system to MD 7. However, in this case there have been customer changes on core parts of the MD originating from master (represented by the two extra boxes within the MD), so that the delta update c would be in conflict with such customer changes. A merge conflict will happen in this case, with some of the problems indicated by D1..D4 above. If there are changes on both master and target system, the master definition will be pushed. In many cases this is accepted by the target system, so that the master MD is favored over the local one.","title":"Step 4"},{"location":"mesh/model-maintenance/ModelMaintenanceConcepts/#summary","text":"This document provides some background information on the process of model definition maintenance. It shows that there are basic features in the tools supporting the maintenance process. Experience shows that problems may arise, which must be worked around using miscellaneous cleanup tools. In some cases, the only solution is to perform an \"on-top\" model update, which is not usually recommended because it can cause further problems later on.","title":"Summary"},{"location":"mesh-data-transfer/changelog/CHANGELOG/","text":"Change Log All notable changes to this project will be documented in this file. Version 2.17 Fixes When exporting revision availability events, the category attribute will now contain a string \"Revision\". Previously the category was an empty string for the revision events. Version 2.16 Features We have added support for Excel CSV time series export. We have added support for RabbitMQ Virtual Host feature. We have added full support for the Service Bus queues. If the queues defined in the configuration file do not exist, data-transfer will attempt to create them automatically. The message lock time will be set to 5 minutes, other settings will remain default. Fixes We have fixed an issue where the time series results would be grouped incorrectly when the sender host feature is used for the CSV export. When the result of an availability event export has an empty category attribute, it is now guaranteed that this is a revision availability event. Version 2.15.4 Features We have added an option to choose between ora and periodo nodes in Bidding export protocol. A new UsePeriodo flag in the Bidding export protocol section in EDS configuration is used to switch between the nodes. Fixes We have fixed an issue where exporting a large number of time series data using the standard export protocol would fail. Version 2.15.3 Features We have added an option to report ImportSuccess = true for partially successful time series import requests. The feature is toggled with an optional PartialImportSuccess parameter in the ImportWorker section of Mesh AMQP Relay configuration file. Fixes We have fixed an issue where debug logs could leak AMQP / ServiceBus connection strings. Version 2.15.2 Breaking changes We have added support for the Decimals export attribute in GS2 time series export. Since this attribute was previously ignored, GS2 time series export might start to produce different results if the Decimals attribute was already defined in the time series export definition. We have added support for the UTC offset in GS2 time series export. The standard time is used when custom UTC offset is not provided. Features We have added a new optional parameter named DefaultDecimals that can be applied per export protocol in the Export Data Store configuration. The DefaultDecimals parameter is supported for the EDIEL DELFOR and GS2 export types only. Fixes We have fixed an issue where the time series results would be grouped incorrectly when the sender host feature is used for the EDIEL DELFOR export. We have fixed an issue where the precision of the total sum of time series values would be lost in the GS2 time series export. We have fixed an issue where EDIEL export output file could contain zeros formatted with leading minus sign. We have fixed an issue where time series export would fail due to invalid UTC to local time conversions. We have changed the name of ora node to periodo in Bidding Strategy export. Version 2.15.1 Breaking changes We have changed the behaviour of the time series export when different export senders are used. The export results are now grouped per sender . If no sender is defined as the export request parameter, then the time series sender is either the sender host from the export definition or the default sender when the sender host is not defined. If the sender is defined as the export request parameter, the time series export definitions with a defined sender host that doesn't match the request sender are ignored during the export; the sender of all the time series is the request sender. Fixes We have fixed an issue where a failure of a single time series export in the Export Data Store would cause a failure of the whole time series export request. We have fixed an issue where participant short name would be used instead of the full name in the GS2 export. We have fixed an issue where missing numbers (NaN) would not be converted to zeroes in the GS2 time series export. We have fixed an issue where the output of the GS2 time series export would be incompatible with the SmG gs2imp time series import tool. We have fixed an issue where the sender host would be ignored in time series export. Version 2.15 Breaking changes We have added a new mandatory configuration parameter for TriggerRelay: ParticipantSettings:DefaultSender . It was done as a part of #283 and #316 . The DefaultSender parameter is a number that denotes a participant key to be used by default when exporting data from Mesh. Example configuration: \"ParticipantSettings\": { \"DefaultSender\": 13 } We have removed the support for the Mesh XML interface. Features We have added support for Bidding Strategy export with a 15-minute time series resolution. We have added support for changing the resolution of the exported time series. NB! The behavior of an export with a target resolution differs from the old export in release 2.15. When exporting time series points from an attribute that holds a physical time series, the Id field in the Standard Export Points node will contain a time series source ID instead of a physical time series ID. If the target export resolution is not defined, the Id will still contain the physical time series ID. <Timeseries QueryId=\"2ad565bc-412c-4674-b981-b1ad24537799\"> <Points Id=\"d3163dae-81de-413a-8c55-bc11ad5080c8\" Path=\"XYZ\" DeltaT=\"PT15M\" Reference=\"ABC\" UnitOfMeasurement=\"MW\" UnitOfMeasurementName=\"MW\" CurveType=\"StaircaseStartOfStep\"> <Segments> ... </Segment> We plan to place the time series source ID in the Standard Export's Id field unconditionally starting from the release 2.16 (Smart Power 2024.5). We have added support for specifying the export sender. We have added support for EDIEL DELFOR time series exports. Fixes We have changed the type of the attribute UnitOfMeasurement in TimeseriesPoints type from UUID to xsd:string . In consequence, the AmqpMessageTypes.xsd schema version has been bumped to 1.1. To start using version 1.1, please set Storage:StoragePerProtocol:StdExport:SchemaVersion item to \"1.1\" in Export Data Store appsettings.json . If this value is not specified, it defaults to version 1.0. Note! We will stop supporting schema version 1.0 in Mesh Data Transfer release 2.17. Note! When using schema version 1.0, the UnitOfMeasurement attribute value does not comply with its type defined in the schema. We have fixed an issue where the Mesh export response message size would exceed the default 4 MB We have fixed an issue where a failure to access the export directory did not cause the time series export request to fail. We have fixed an issue where the Message Log entries would not be created when exporting time series with the GS2 export protocol. We have fixed an issue where Message Log timestamps would not be aligned to the database time zone. Version 2.14.2 We have brought back the UnitOfMeasurementName attribute to the standard export format due to compatibility reasons. It carries a human-readable version of the unit of measurement. Its value will be the same as the value of UnitofMeasurement attribute. We have fixed an issue where MAR and TR could occupy a lot of network ports when using Kerberos authorization. Version 2.14.1 We have fixed an issue where import requests using Reference parameter could delete points outside of the original request interval. Version 2.14 As of time of writing this note (release 2024.3 in progress) data-transfer uses a separate version for every service. Since data-transfer is part of Smart Power, we see value in unifying the data-transfer versioning scheme with the Mesh versioning system. All releases (originating from new development and from backporting to the past releases) will start to receive a version according to the Mesh versioning system. All new data-transfer executables will be stamped with release indicator and the build number: Major.Minor.Patch.(BuildNumber) , where Major and Minor will match with corresponding Mesh version. Changelog will be divided into release sections. We will leave current changelog entries unchanged as all data-transfer deployed at the customers use the old versioning scheme. We have fixed an issue where the import request could not be opened using MessageLog application. We have fixed an issue where the request timeout would not be taken into account when communicating with Mesh using gRPC interface. We have fixed an issue where an export of complex availability events would fail. We have upgraded data-transfer services to .NET8. We have fixed a memory leak that occurred during timeseries export. Version 2.13 [TR3.6.3] [MAR4.5.3] [EDS4.1.1] [DBGW2.1.1] We have renamed the appsettings.json file to appsettings.json.sample to improve the upgrade process. [TR3.6.2] [MAR4.5.2] We have fixed an issue where availability event occurrences would not be handled correctly. [TR3.6.1] [MAR4.5.1] We have fixed an issue where ForceAvailabilityEventCreation flag would not work correctly. [TR3.6.0] [MAR4.5.0] We have switched to the Mesh gRPC NuGet package used for the communication with the Mesh server. [DBGW2.1.0] [EDS4.1.0] [MAR4.4.0] [TR3.5.0] We have added support for GS2 time series exports [MAR4.3.13] We have added functionality to automatically unzip import messages if the ContentType or ContentEncoding property of the import message contains the string 'gzip'. Version 2.12.1 We have fixed a memory leak that occurred during timeseries export. Version 2.12.0 We are backporting .NET8 upgrade to data-transfer in Smart Power 2024.1. As of time of writing this note (release 2024.3 in progress) data-transfer uses a separate version for every service. Since data-transfer is part of Smart Power, we see value in unifying the data-transfer versioning scheme with the Mesh versioning system. All releases (originating from new development and from backporting to the past releases) will start to receive a version according to the Mesh versioning system. All new data-transfer executables will be stamped with release indicator and the build number: Major.Minor.Patch.(BuildNumber) , where Major and Minor will match with corresponding Mesh version. Changelog will be divided into release sections. We will leave current changelog entries unchanged as all data-transfer deployed at the customers use the old versioning scheme. We have upgraded data-transfer services to .NET8. [MAR4.3.12] We have fixed an issue where import files were incorrectly stored in a directory named with local date [DBGW2.0.2] We have fixed an issue where we would try to export time series points outside of the time series' validity interval [TR3.4.4] [MAR4.3.11] We have added Kerberos authentication support to the gRPC interface. Services talking to Mesh using gRPC will now be able to authenticate to Mesh using Kerberos. We have added a ServerPrincipal configuration item in HttpEndpoints:Mesh node. The user should set its value to the server principal of the Mesh server. We have also removed the TlsCertificate configuration item from HttpEndpoints:Mesh node. Users should enable secure Mesh communication by using https protocol in HttpEndpoints:Mesh:Uri . [TR3.4.3] [MAR4.3.10] We have added support for 30 minute resolution time series [TR3.4.2] [DBGW2.0.1] [MAR4.3.9] [EDS4.0.1] We have changed the way Created and Transferred columns work in Message Log . Until now, Created would display the time when the export has completed and Transferred would be empty. Created will now display the time when the export order was received in Trigger Relay and Transferred will display the time when the export has completed. [EDS4.0.0] [DBGW2.0.0] We have changed the way EDS retrieves target queue names. In the previous versions there were 2 ways to specify target queue names to send the exports to. Using the Queues array filled with queue aliases in the config file Using RECADR database table to store the queue names. Broker should be specified in the Broker configuration item. Queue names were associated with an export protocol and a receiver identifier. Approach #1 turned out to be not flexible enough and approach #2 is too messy (keeping the broker name and the queue name separately). In this version we introduce (protocol, receiver)-to-queue mapping into EDS configuration file: \"Storage\": { \"StoragePerProtocol\": { \"PVPLAN\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"PVPLAN2023\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"StdExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"APORAPOTExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"2\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"BiddingTool\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" } } }, \"QueuesConfiguration\": { \"exportReplyQueue\": { \"Broker\": \"B1\", \"QueueName\": \"exportReplyQueue\", \"Role\": \"Sender\" }, \"someOtherQueue\": { \"Broker\": \"B1\", \"QueueName\": \"someOtherQueue\", \"Role\": \"Sender\" } }, We introduce DestinationQueues mapping into StoragePerProtocol children nodes. It is a dictionary consisting of keys being export receiver identfiers and values being queue aliases arrays. When the DestinationQueues has a key equal to an export receiver value for given export protocol, the export data will be sent to the queues in the respective array. In the StoragePerProtocol nodes the Queues array is renamed to DefaultQueues . If the DestinationQueues mapping does not provide target queue information, DefaultQueues values are used as target queues. [MAR4.3.8] We have modified the content of the standard XML format slightly. If you specify an external reference in the export definition, this information will now be put into both the Path (as before) and the Reference field. For breakpoint time series, the DeltaT field has now changed from 0 to PT0S (which is a legal resolution value). We have fixed an issue where Receiver and Sender fields in time series import request could be translated incorrectly. [TR3.4.1] We have added a possibility to specify a SessionId in timeseries and availability export requests. The session ID can be provided in an optional SessionId header in Order and AvailabilityExport endpoints [TR3.4.0] We have introduced status reporting to Trigger Relay time series and availability export requests. (issue #196 ) [EDS3.3.3] We have fixed an issue where PvPlan 2023 export results would be overwritten if input interval would span for more than one day. [MAR4.3.6] We have fixed gRPC session handling in case of Mesh unavailability. [MAR4.3.5] We have added automatic extension of session in gRPC Mesh communication interface. [EDS3.3.2] We have fixed an issue where PvPlan 2023 export results would be corrupted if input interval would span for more than one day. [MAR4.3.4] We have fixed an issue where AvailabilityEventRemove import would fail. [MAR4.3.3] We have added Reason field to availablity events import and export. [MAR4.3.2] We have fixed an issue where revision availability events import would fail. [MAR4.3.1] We have fixed an issue where time series import logs would not be visible in MessageLog . [MAR4.3.0] It is now possible to import timeseries using a reference and Id when using gRPC Mesh communication interface. [DBGW1.1.1] Mapping of sender and receiver participants are now possible to configure using the Database/OpunKeyMode option in the appsettings.json file. SHORNAME is the default mapping item if not specified. [MAR4.2.8] We have fixed an issue where putting arbitrary MessageId in import request would break the timeseries import. [MAR4.2.7] An issue with high CPU usage by MAR while Mesh was unavailable was fixed. [MAR4.2.6] We have fixed an issue where availability update request would be mapped to create request [MAR4.2.5] We have fixed an issue where igoreImportErrors and logRequest flags would not be present in availability import request sent to Mesh server. [EDS3.3.1] [MAR4.2.4] We have fixed an issue where exported XML files contained numbers in invalid format [MAR4.2.3] We have fixed an issue where IgnoreImportErrors flag would not be present [MAR4.2.2] We have fixed an issue where time series import reply would contain MessageId instead of RequestMessageId field. We have fixed import logging when using XML protocol [MAR4.2.1] We have fixed an issue where export would not work due to incorrect QueryId comparison. [MAR4.2.0] We have fixed an issue where UnitOfMeasurementName parameter would not be present in exported data. [MAR4.1.1] We have fixed an issue where Path parameter would not be visible in data exports. [EDS3.3.0] [TR3.3.0] [MAR4.1.0] [DBGW1.1.0] A new PVPLAN 2023 export format is introduced [TR3.2.1] [EDS3.2.3] [MAR4.0.1] [DBGW1.0.1] We have fixed a memory leak caused by incorrect usage of XmlSerializer class. [EDS3.2.2] We have updated allowed symbol set for Bidding Strategy's Mercato and US parameters. [EDS3.2.1] We have fixed an issue where breakpoint time series would be exported incorrectly using BiddingTool protocol gRPC Interface Support [MAR4.0] Mesh AMQP Relay is now able to communicate with Mesh using gRPC interface. New parameters are introduced to HttpEndpoints::Mesh node: MeshInterface - allows the user to choose how MAR communicates with Mesh. Possible values: { gRPC , XML }. TslCertificate - allows the user to specify the certificate used to encrypt the communication when using gRPC interface and HTTPS . It can be set to null when using XML interface. Uri should be adjusted to the URI of XML Mesh server or gRPC Mesh server. ```json \"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"https://localhost:50051\", \"MeshInterface\": \"gRPC\", \"TslCertificate\": \"C:\\certs\\certificate.crt\", \"RequestTimeout\": 60 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000\" }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } ``` [EDS 3.2.0] PvPlan and APOR/APOT report filenames are extended with milliseconds to prevent report overwriting. Single File Builds Since build #390 we will publish services with Single File Build option enabled. This will reduce number of files in the directories greatly. This change requires adding following settings to Serilog options: \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"Serilog.Enrichers.Thread\" ], [TR 3.1.1] HttpEndpoints/DatabaseGateway configuration is required for the database connection. Example: \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } [MAR3.2.0] The configuration of HTTP endpoints has changed. There is a new config container introduced: HttpEndpoints . MeshHttpEndpoint/MeshHttpInterface is now moved to HttpEndpoints/Mesh/Uri . MeshHttpEndpoint/RequestTimeout becomes HttpEndpoints/Mesh/RequestTimeout . ExportWorker/ExportServiceAddress becomes HttpEndpoints/ExportDataStore/Uri . Support of MeshHttpEndpoint and ExportWorker/ExportServiceAddress nodes is dropped. HttpEndpoints/DatabaseGateway configuration is required for the database connection. All the HTTP endpoints accept an optional RequestTimeout parameter (unit: seconds, default value: 60). Example HttpEndpoints section: \"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"http://localhost:20000/mesh\", \"RequestTimeout\": 60 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000/\", \"RequestTimeout\": 30 }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } [DBGW1.0.0] There is a new service: DatabaseGateway. It is supposed to be a database proxy for other data-transfer services. Currently DatabaseGateway is utilized by MAR and Trigger Relay. EDS still invokes database operations on its own. There is a README for DatabaseGateway service. [MAR3.0.9] We have changed an error category of the condition where Mesh would return an error to time series query from internal to external. [EDS3.0.7] We have fixed an issue where APOT/APOT time series export would fail if export start time was set to some specific value. [EDS3.0.6] We have added tracking of export index file numbers in PDDBENV table to support failover case. [TR3.0.5] [EDS3.0.5] We introduced bidding strategy export customisation to make sure full days are always exported. [MAR3.0.8] We have added more fine-grained error handling in Mesh AMQP Relay. FailedMessages setting now contains two items: UseFailureQueueOnInternalError and UseFailureQueueOnExternalError of boolean type. Internal errors are the ones that originated from inside Mesh AMQP Relay (for example XML/JSON parsing problem). External errors come from Mesh and EDS (like an Oracle issue). If set to true the problematic message will be sent to failure queue. Otherwise the application will try to put it back on the queue process it again. [MAR3.0.7] [TR3.0.4] [EDS3.0.4] We have fixed an issue where CreationDate would be presented incorrectly in MessageLog. [MAR3.0.6] [TR3.0.3] [EDS3.0.3] We have fixed an issue that prevented AMQP receiver links from properly removing messages from the queue. [MAR3.0.5] [TR3.0.2] [EDS3.0.2] We have fixed an issue with common config that stopped is from being recognized. [MAR3.0.4] We have added a configuration file option to enable/disable reimport. [TR3.0.1] [MAR3.0.3] [EDS3.0.1] We have fixed a problem with service logs not being written to log files. [MAR3.0.2] We have added experimental support for Open Telemetry tracing and metrics. New OpenTelemetry can be used in the MAR configuration file. It offers following options: \"OpenTelemetry\": { \"UseTraces\": true, // Enable traces \"UseMetrics\": true, // Enable metrics \"MetricsEndpoint\": \"http://localhost:3303\" //Endpoint for metrics reading. } [MAR3.0.1] We have fixed an issue where MAR would store imported files in wrong directory. [TR3.0.0] [MAR3.0.0] [EDS3.0.0] We have added support for reimport functionality. Data transfer services from now on require Mesh 2.5.2 or newer to work. Import Worker settings must contain ICC_TRANSLOG_DIR [TR2.0.7] We have fixed an issue that caused MessageId to be an empty GUID when exporting timeseries. [TR2.0.6] [MAR2.0.8] [EDS2.0.13] Changed We have changed appsettings.json organisation. Now common parts of the configuration can be kept in src/CommonConfig/appsettings_common.json. Also developers can use VOLUE_IMPORTEXPORT_COMMON_CONFIG_PATH environmental variable to change the common config directory in the development process. [MAR2.0.7] [EDS2.0.12] We have increased max HTTP body request size from 28.6 MB to 2048 MB [EDS2.0.11] We have fixed CREATION_DATE in MESSAGE_HEADER table [EDS2.0.10] We have changed Unit Schedule path and added Err values to dinamici file. [EDS2.0.9] We have changed the format of Bidding Strategy export. We filled the US parameter and moved it to the giorno node. [TR2.0.5] [MAR2.0.6] [EDS2.0.8] Fixed We have changed an internal AMQP Session parameter responsible for maximal number of queues attached to the session from 10 to 30. [MAR2.0.5] [EDS2.0.7] - 2022-02-09 Fixed We have added a property validator attribute that supports local and network volumes. Fixed internal enum translation problem [EDS2.0.6] - 2022-02-07 Added We have added a possiblity to store Standard Export content on the disk. [EDS2.0.5] - 2022-02-04 Fixed We have fixed an issue where StorePath network storage volumes parsing would not work. Disk space health check removed. [EDS2.0.4] - 2022-02-03 Fixed We have fixed an issue where network storage volumes in StorePath would stop EDS from starting [TR2.0.4] [EDS2.0.3] - 2022-02-01 Changed We have changed bidding strategy export according to the new requirements provided by Enel [MAR2.0.4] [TR2.0.3] [EDS2.0.2] - 2022-02-01 Fixed We have fixed an issue where services would not log configuration validation errors [MAR2.0.3] [TR2.0.2] - 2022-21-01 Added We have added support for multiple import queues with priorities. Introduced configuration parameter called Priority . Full description on how to use it in README [EDS2.0.1] - 2022-14-01 Fixed Fix month format in directory names for month numbers < 10","title":"Changelog"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file.","title":"Change Log"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-217","text":"","title":"Version 2.17"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes","text":"When exporting revision availability events, the category attribute will now contain a string \"Revision\". Previously the category was an empty string for the revision events.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-216","text":"","title":"Version 2.16"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#features","text":"We have added support for Excel CSV time series export. We have added support for RabbitMQ Virtual Host feature. We have added full support for the Service Bus queues. If the queues defined in the configuration file do not exist, data-transfer will attempt to create them automatically. The message lock time will be set to 5 minutes, other settings will remain default.","title":"Features"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_1","text":"We have fixed an issue where the time series results would be grouped incorrectly when the sender host feature is used for the CSV export. When the result of an availability event export has an empty category attribute, it is now guaranteed that this is a revision availability event.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2154","text":"","title":"Version 2.15.4"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#features_1","text":"We have added an option to choose between ora and periodo nodes in Bidding export protocol. A new UsePeriodo flag in the Bidding export protocol section in EDS configuration is used to switch between the nodes.","title":"Features"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_2","text":"We have fixed an issue where exporting a large number of time series data using the standard export protocol would fail.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2153","text":"","title":"Version 2.15.3"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#features_2","text":"We have added an option to report ImportSuccess = true for partially successful time series import requests. The feature is toggled with an optional PartialImportSuccess parameter in the ImportWorker section of Mesh AMQP Relay configuration file.","title":"Features"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_3","text":"We have fixed an issue where debug logs could leak AMQP / ServiceBus connection strings.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2152","text":"","title":"Version 2.15.2"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#breaking-changes","text":"We have added support for the Decimals export attribute in GS2 time series export. Since this attribute was previously ignored, GS2 time series export might start to produce different results if the Decimals attribute was already defined in the time series export definition. We have added support for the UTC offset in GS2 time series export. The standard time is used when custom UTC offset is not provided.","title":"Breaking changes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#features_3","text":"We have added a new optional parameter named DefaultDecimals that can be applied per export protocol in the Export Data Store configuration. The DefaultDecimals parameter is supported for the EDIEL DELFOR and GS2 export types only.","title":"Features"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_4","text":"We have fixed an issue where the time series results would be grouped incorrectly when the sender host feature is used for the EDIEL DELFOR export. We have fixed an issue where the precision of the total sum of time series values would be lost in the GS2 time series export. We have fixed an issue where EDIEL export output file could contain zeros formatted with leading minus sign. We have fixed an issue where time series export would fail due to invalid UTC to local time conversions. We have changed the name of ora node to periodo in Bidding Strategy export.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2151","text":"","title":"Version 2.15.1"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#breaking-changes_1","text":"We have changed the behaviour of the time series export when different export senders are used. The export results are now grouped per sender . If no sender is defined as the export request parameter, then the time series sender is either the sender host from the export definition or the default sender when the sender host is not defined. If the sender is defined as the export request parameter, the time series export definitions with a defined sender host that doesn't match the request sender are ignored during the export; the sender of all the time series is the request sender.","title":"Breaking changes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_5","text":"We have fixed an issue where a failure of a single time series export in the Export Data Store would cause a failure of the whole time series export request. We have fixed an issue where participant short name would be used instead of the full name in the GS2 export. We have fixed an issue where missing numbers (NaN) would not be converted to zeroes in the GS2 time series export. We have fixed an issue where the output of the GS2 time series export would be incompatible with the SmG gs2imp time series import tool. We have fixed an issue where the sender host would be ignored in time series export.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-215","text":"","title":"Version 2.15"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#breaking-changes_2","text":"We have added a new mandatory configuration parameter for TriggerRelay: ParticipantSettings:DefaultSender . It was done as a part of #283 and #316 . The DefaultSender parameter is a number that denotes a participant key to be used by default when exporting data from Mesh. Example configuration: \"ParticipantSettings\": { \"DefaultSender\": 13 } We have removed the support for the Mesh XML interface.","title":"Breaking changes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#features_4","text":"We have added support for Bidding Strategy export with a 15-minute time series resolution. We have added support for changing the resolution of the exported time series. NB! The behavior of an export with a target resolution differs from the old export in release 2.15. When exporting time series points from an attribute that holds a physical time series, the Id field in the Standard Export Points node will contain a time series source ID instead of a physical time series ID. If the target export resolution is not defined, the Id will still contain the physical time series ID. <Timeseries QueryId=\"2ad565bc-412c-4674-b981-b1ad24537799\"> <Points Id=\"d3163dae-81de-413a-8c55-bc11ad5080c8\" Path=\"XYZ\" DeltaT=\"PT15M\" Reference=\"ABC\" UnitOfMeasurement=\"MW\" UnitOfMeasurementName=\"MW\" CurveType=\"StaircaseStartOfStep\"> <Segments> ... </Segment> We plan to place the time series source ID in the Standard Export's Id field unconditionally starting from the release 2.16 (Smart Power 2024.5). We have added support for specifying the export sender. We have added support for EDIEL DELFOR time series exports.","title":"Features"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixes_6","text":"We have changed the type of the attribute UnitOfMeasurement in TimeseriesPoints type from UUID to xsd:string . In consequence, the AmqpMessageTypes.xsd schema version has been bumped to 1.1. To start using version 1.1, please set Storage:StoragePerProtocol:StdExport:SchemaVersion item to \"1.1\" in Export Data Store appsettings.json . If this value is not specified, it defaults to version 1.0. Note! We will stop supporting schema version 1.0 in Mesh Data Transfer release 2.17. Note! When using schema version 1.0, the UnitOfMeasurement attribute value does not comply with its type defined in the schema. We have fixed an issue where the Mesh export response message size would exceed the default 4 MB We have fixed an issue where a failure to access the export directory did not cause the time series export request to fail. We have fixed an issue where the Message Log entries would not be created when exporting time series with the GS2 export protocol. We have fixed an issue where Message Log timestamps would not be aligned to the database time zone.","title":"Fixes"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2142","text":"We have brought back the UnitOfMeasurementName attribute to the standard export format due to compatibility reasons. It carries a human-readable version of the unit of measurement. Its value will be the same as the value of UnitofMeasurement attribute. We have fixed an issue where MAR and TR could occupy a lot of network ports when using Kerberos authorization.","title":"Version 2.14.2"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2141","text":"We have fixed an issue where import requests using Reference parameter could delete points outside of the original request interval.","title":"Version 2.14.1"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-214","text":"As of time of writing this note (release 2024.3 in progress) data-transfer uses a separate version for every service. Since data-transfer is part of Smart Power, we see value in unifying the data-transfer versioning scheme with the Mesh versioning system. All releases (originating from new development and from backporting to the past releases) will start to receive a version according to the Mesh versioning system. All new data-transfer executables will be stamped with release indicator and the build number: Major.Minor.Patch.(BuildNumber) , where Major and Minor will match with corresponding Mesh version. Changelog will be divided into release sections. We will leave current changelog entries unchanged as all data-transfer deployed at the customers use the old versioning scheme. We have fixed an issue where the import request could not be opened using MessageLog application. We have fixed an issue where the request timeout would not be taken into account when communicating with Mesh using gRPC interface. We have fixed an issue where an export of complex availability events would fail. We have upgraded data-transfer services to .NET8. We have fixed a memory leak that occurred during timeseries export.","title":"Version 2.14"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-213","text":"","title":"Version 2.13"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr363-mar453-eds411-dbgw211","text":"We have renamed the appsettings.json file to appsettings.json.sample to improve the upgrade process.","title":"[TR3.6.3] [MAR4.5.3] [EDS4.1.1] [DBGW2.1.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr362-mar452","text":"We have fixed an issue where availability event occurrences would not be handled correctly.","title":"[TR3.6.2] [MAR4.5.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr361-mar451","text":"We have fixed an issue where ForceAvailabilityEventCreation flag would not work correctly.","title":"[TR3.6.1] [MAR4.5.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr360-mar450","text":"We have switched to the Mesh gRPC NuGet package used for the communication with the Mesh server.","title":"[TR3.6.0] [MAR4.5.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#dbgw210-eds410-mar440-tr350","text":"We have added support for GS2 time series exports","title":"[DBGW2.1.0] [EDS4.1.0] [MAR4.4.0] [TR3.5.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar4313","text":"We have added functionality to automatically unzip import messages if the ContentType or ContentEncoding property of the import message contains the string 'gzip'.","title":"[MAR4.3.13]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2121","text":"We have fixed a memory leak that occurred during timeseries export.","title":"Version 2.12.1"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#version-2120","text":"We are backporting .NET8 upgrade to data-transfer in Smart Power 2024.1. As of time of writing this note (release 2024.3 in progress) data-transfer uses a separate version for every service. Since data-transfer is part of Smart Power, we see value in unifying the data-transfer versioning scheme with the Mesh versioning system. All releases (originating from new development and from backporting to the past releases) will start to receive a version according to the Mesh versioning system. All new data-transfer executables will be stamped with release indicator and the build number: Major.Minor.Patch.(BuildNumber) , where Major and Minor will match with corresponding Mesh version. Changelog will be divided into release sections. We will leave current changelog entries unchanged as all data-transfer deployed at the customers use the old versioning scheme. We have upgraded data-transfer services to .NET8.","title":"Version 2.12.0"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar4312","text":"We have fixed an issue where import files were incorrectly stored in a directory named with local date","title":"[MAR4.3.12]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#dbgw202","text":"We have fixed an issue where we would try to export time series points outside of the time series' validity interval","title":"[DBGW2.0.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr344-mar4311","text":"We have added Kerberos authentication support to the gRPC interface. Services talking to Mesh using gRPC will now be able to authenticate to Mesh using Kerberos. We have added a ServerPrincipal configuration item in HttpEndpoints:Mesh node. The user should set its value to the server principal of the Mesh server. We have also removed the TlsCertificate configuration item from HttpEndpoints:Mesh node. Users should enable secure Mesh communication by using https protocol in HttpEndpoints:Mesh:Uri .","title":"[TR3.4.4] [MAR4.3.11]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr343-mar4310","text":"We have added support for 30 minute resolution time series","title":"[TR3.4.3] [MAR4.3.10]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr342-dbgw201-mar439-eds401","text":"We have changed the way Created and Transferred columns work in Message Log . Until now, Created would display the time when the export has completed and Transferred would be empty. Created will now display the time when the export order was received in Trigger Relay and Transferred will display the time when the export has completed.","title":"[TR3.4.2] [DBGW2.0.1] [MAR4.3.9] [EDS4.0.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds400-dbgw200","text":"We have changed the way EDS retrieves target queue names. In the previous versions there were 2 ways to specify target queue names to send the exports to. Using the Queues array filled with queue aliases in the config file Using RECADR database table to store the queue names. Broker should be specified in the Broker configuration item. Queue names were associated with an export protocol and a receiver identifier. Approach #1 turned out to be not flexible enough and approach #2 is too messy (keeping the broker name and the queue name separately). In this version we introduce (protocol, receiver)-to-queue mapping into EDS configuration file: \"Storage\": { \"StoragePerProtocol\": { \"PVPLAN\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"PVPLAN2023\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"StdExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"APORAPOTExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"2\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"BiddingTool\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" } } }, \"QueuesConfiguration\": { \"exportReplyQueue\": { \"Broker\": \"B1\", \"QueueName\": \"exportReplyQueue\", \"Role\": \"Sender\" }, \"someOtherQueue\": { \"Broker\": \"B1\", \"QueueName\": \"someOtherQueue\", \"Role\": \"Sender\" } }, We introduce DestinationQueues mapping into StoragePerProtocol children nodes. It is a dictionary consisting of keys being export receiver identfiers and values being queue aliases arrays. When the DestinationQueues has a key equal to an export receiver value for given export protocol, the export data will be sent to the queues in the respective array. In the StoragePerProtocol nodes the Queues array is renamed to DefaultQueues . If the DestinationQueues mapping does not provide target queue information, DefaultQueues values are used as target queues.","title":"[EDS4.0.0] [DBGW2.0.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar438","text":"We have modified the content of the standard XML format slightly. If you specify an external reference in the export definition, this information will now be put into both the Path (as before) and the Reference field. For breakpoint time series, the DeltaT field has now changed from 0 to PT0S (which is a legal resolution value). We have fixed an issue where Receiver and Sender fields in time series import request could be translated incorrectly.","title":"[MAR4.3.8]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr341","text":"We have added a possibility to specify a SessionId in timeseries and availability export requests. The session ID can be provided in an optional SessionId header in Order and AvailabilityExport endpoints","title":"[TR3.4.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr340","text":"We have introduced status reporting to Trigger Relay time series and availability export requests. (issue #196 )","title":"[TR3.4.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds333","text":"We have fixed an issue where PvPlan 2023 export results would be overwritten if input interval would span for more than one day.","title":"[EDS3.3.3]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar436","text":"We have fixed gRPC session handling in case of Mesh unavailability.","title":"[MAR4.3.6]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar435","text":"We have added automatic extension of session in gRPC Mesh communication interface.","title":"[MAR4.3.5]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds332","text":"We have fixed an issue where PvPlan 2023 export results would be corrupted if input interval would span for more than one day.","title":"[EDS3.3.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar434","text":"We have fixed an issue where AvailabilityEventRemove import would fail.","title":"[MAR4.3.4]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar433","text":"We have added Reason field to availablity events import and export.","title":"[MAR4.3.3]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar432","text":"We have fixed an issue where revision availability events import would fail.","title":"[MAR4.3.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar431","text":"We have fixed an issue where time series import logs would not be visible in MessageLog .","title":"[MAR4.3.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar430","text":"It is now possible to import timeseries using a reference and Id when using gRPC Mesh communication interface.","title":"[MAR4.3.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#dbgw111","text":"Mapping of sender and receiver participants are now possible to configure using the Database/OpunKeyMode option in the appsettings.json file. SHORNAME is the default mapping item if not specified.","title":"[DBGW1.1.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar428","text":"We have fixed an issue where putting arbitrary MessageId in import request would break the timeseries import.","title":"[MAR4.2.8]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar427","text":"An issue with high CPU usage by MAR while Mesh was unavailable was fixed.","title":"[MAR4.2.7]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar426","text":"We have fixed an issue where availability update request would be mapped to create request","title":"[MAR4.2.6]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar425","text":"We have fixed an issue where igoreImportErrors and logRequest flags would not be present in availability import request sent to Mesh server.","title":"[MAR4.2.5]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds331-mar424","text":"We have fixed an issue where exported XML files contained numbers in invalid format","title":"[EDS3.3.1] [MAR4.2.4]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar423","text":"We have fixed an issue where IgnoreImportErrors flag would not be present","title":"[MAR4.2.3]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar422","text":"We have fixed an issue where time series import reply would contain MessageId instead of RequestMessageId field. We have fixed import logging when using XML protocol","title":"[MAR4.2.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar421","text":"We have fixed an issue where export would not work due to incorrect QueryId comparison.","title":"[MAR4.2.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar420","text":"We have fixed an issue where UnitOfMeasurementName parameter would not be present in exported data.","title":"[MAR4.2.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar411","text":"We have fixed an issue where Path parameter would not be visible in data exports.","title":"[MAR4.1.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds330-tr330-mar410-dbgw110","text":"A new PVPLAN 2023 export format is introduced","title":"[EDS3.3.0] [TR3.3.0] [MAR4.1.0] [DBGW1.1.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr321-eds323-mar401-dbgw101","text":"We have fixed a memory leak caused by incorrect usage of XmlSerializer class.","title":"[TR3.2.1] [EDS3.2.3] [MAR4.0.1] [DBGW1.0.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds322","text":"We have updated allowed symbol set for Bidding Strategy's Mercato and US parameters.","title":"[EDS3.2.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds321","text":"We have fixed an issue where breakpoint time series would be exported incorrectly using BiddingTool protocol","title":"[EDS3.2.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#grpc-interface-support-mar40","text":"Mesh AMQP Relay is now able to communicate with Mesh using gRPC interface. New parameters are introduced to HttpEndpoints::Mesh node: MeshInterface - allows the user to choose how MAR communicates with Mesh. Possible values: { gRPC , XML }. TslCertificate - allows the user to specify the certificate used to encrypt the communication when using gRPC interface and HTTPS . It can be set to null when using XML interface. Uri should be adjusted to the URI of XML Mesh server or gRPC Mesh server. ```json \"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"https://localhost:50051\", \"MeshInterface\": \"gRPC\", \"TslCertificate\": \"C:\\certs\\certificate.crt\", \"RequestTimeout\": 60 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000\" }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } ```","title":"gRPC Interface Support [MAR4.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds-320","text":"PvPlan and APOR/APOT report filenames are extended with milliseconds to prevent report overwriting.","title":"[EDS 3.2.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#single-file-builds","text":"Since build #390 we will publish services with Single File Build option enabled. This will reduce number of files in the directories greatly. This change requires adding following settings to Serilog options: \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"Serilog.Enrichers.Thread\" ],","title":"Single File Builds"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr-311","text":"HttpEndpoints/DatabaseGateway configuration is required for the database connection. Example: \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }","title":"[TR 3.1.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar320","text":"The configuration of HTTP endpoints has changed. There is a new config container introduced: HttpEndpoints . MeshHttpEndpoint/MeshHttpInterface is now moved to HttpEndpoints/Mesh/Uri . MeshHttpEndpoint/RequestTimeout becomes HttpEndpoints/Mesh/RequestTimeout . ExportWorker/ExportServiceAddress becomes HttpEndpoints/ExportDataStore/Uri . Support of MeshHttpEndpoint and ExportWorker/ExportServiceAddress nodes is dropped. HttpEndpoints/DatabaseGateway configuration is required for the database connection. All the HTTP endpoints accept an optional RequestTimeout parameter (unit: seconds, default value: 60). Example HttpEndpoints section: \"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"http://localhost:20000/mesh\", \"RequestTimeout\": 60 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000/\", \"RequestTimeout\": 30 }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }","title":"[MAR3.2.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#dbgw100","text":"There is a new service: DatabaseGateway. It is supposed to be a database proxy for other data-transfer services. Currently DatabaseGateway is utilized by MAR and Trigger Relay. EDS still invokes database operations on its own. There is a README for DatabaseGateway service.","title":"[DBGW1.0.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar309","text":"We have changed an error category of the condition where Mesh would return an error to time series query from internal to external.","title":"[MAR3.0.9]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds307","text":"We have fixed an issue where APOT/APOT time series export would fail if export start time was set to some specific value.","title":"[EDS3.0.7]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds306","text":"We have added tracking of export index file numbers in PDDBENV table to support failover case.","title":"[EDS3.0.6]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr305-eds305","text":"We introduced bidding strategy export customisation to make sure full days are always exported.","title":"[TR3.0.5] [EDS3.0.5]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar308","text":"We have added more fine-grained error handling in Mesh AMQP Relay. FailedMessages setting now contains two items: UseFailureQueueOnInternalError and UseFailureQueueOnExternalError of boolean type. Internal errors are the ones that originated from inside Mesh AMQP Relay (for example XML/JSON parsing problem). External errors come from Mesh and EDS (like an Oracle issue). If set to true the problematic message will be sent to failure queue. Otherwise the application will try to put it back on the queue process it again.","title":"[MAR3.0.8]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar307-tr304-eds304","text":"We have fixed an issue where CreationDate would be presented incorrectly in MessageLog.","title":"[MAR3.0.7] [TR3.0.4] [EDS3.0.4]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar306-tr303-eds303","text":"We have fixed an issue that prevented AMQP receiver links from properly removing messages from the queue.","title":"[MAR3.0.6] [TR3.0.3] [EDS3.0.3]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar305-tr302-eds302","text":"We have fixed an issue with common config that stopped is from being recognized.","title":"[MAR3.0.5] [TR3.0.2] [EDS3.0.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar304","text":"We have added a configuration file option to enable/disable reimport.","title":"[MAR3.0.4]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr301-mar303-eds301","text":"We have fixed a problem with service logs not being written to log files.","title":"[TR3.0.1] [MAR3.0.3] [EDS3.0.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar302","text":"We have added experimental support for Open Telemetry tracing and metrics. New OpenTelemetry can be used in the MAR configuration file. It offers following options: \"OpenTelemetry\": { \"UseTraces\": true, // Enable traces \"UseMetrics\": true, // Enable metrics \"MetricsEndpoint\": \"http://localhost:3303\" //Endpoint for metrics reading. }","title":"[MAR3.0.2]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar301","text":"We have fixed an issue where MAR would store imported files in wrong directory.","title":"[MAR3.0.1]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr300-mar300-eds300","text":"We have added support for reimport functionality. Data transfer services from now on require Mesh 2.5.2 or newer to work. Import Worker settings must contain ICC_TRANSLOG_DIR","title":"[TR3.0.0] [MAR3.0.0] [EDS3.0.0]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr207","text":"We have fixed an issue that caused MessageId to be an empty GUID when exporting timeseries.","title":"[TR2.0.7]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr206-mar208-eds2013","text":"","title":"[TR2.0.6] [MAR2.0.8] [EDS2.0.13]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#changed","text":"We have changed appsettings.json organisation. Now common parts of the configuration can be kept in src/CommonConfig/appsettings_common.json. Also developers can use VOLUE_IMPORTEXPORT_COMMON_CONFIG_PATH environmental variable to change the common config directory in the development process.","title":"Changed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar207-eds2012","text":"We have increased max HTTP body request size from 28.6 MB to 2048 MB","title":"[MAR2.0.7] [EDS2.0.12]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds2011","text":"We have fixed CREATION_DATE in MESSAGE_HEADER table","title":"[EDS2.0.11]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds2010","text":"We have changed Unit Schedule path and added Err values to dinamici file.","title":"[EDS2.0.10]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds209","text":"We have changed the format of Bidding Strategy export. We filled the US parameter and moved it to the giorno node.","title":"[EDS2.0.9]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr205-mar206-eds208","text":"","title":"[TR2.0.5] [MAR2.0.6] [EDS2.0.8]"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed","text":"We have changed an internal AMQP Session parameter responsible for maximal number of queues attached to the session from 10 to 30.","title":"Fixed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar205-eds207-2022-02-09","text":"","title":"[MAR2.0.5] [EDS2.0.7] - 2022-02-09"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed_1","text":"We have added a property validator attribute that supports local and network volumes. Fixed internal enum translation problem","title":"Fixed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds206-2022-02-07","text":"","title":"[EDS2.0.6] - 2022-02-07"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#added","text":"We have added a possiblity to store Standard Export content on the disk.","title":"Added"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds205-2022-02-04","text":"","title":"[EDS2.0.5] - 2022-02-04"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed_2","text":"We have fixed an issue where StorePath network storage volumes parsing would not work. Disk space health check removed.","title":"Fixed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds204-2022-02-03","text":"","title":"[EDS2.0.4] - 2022-02-03"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed_3","text":"We have fixed an issue where network storage volumes in StorePath would stop EDS from starting","title":"Fixed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#tr204-eds203-2022-02-01","text":"","title":"[TR2.0.4] [EDS2.0.3] - 2022-02-01"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#changed_1","text":"We have changed bidding strategy export according to the new requirements provided by Enel","title":"Changed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar204-tr203-eds202-2022-02-01","text":"","title":"[MAR2.0.4] [TR2.0.3] [EDS2.0.2] - 2022-02-01"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed_4","text":"We have fixed an issue where services would not log configuration validation errors","title":"Fixed"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#mar203-tr202-2022-21-01","text":"","title":"[MAR2.0.3] [TR2.0.2] - 2022-21-01"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#added_1","text":"We have added support for multiple import queues with priorities. Introduced configuration parameter called Priority . Full description on how to use it in README","title":"Added"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#eds201-2022-14-01","text":"","title":"[EDS2.0.1] - 2022-14-01"},{"location":"mesh-data-transfer/changelog/CHANGELOG/#fixed_5","text":"Fix month format in directory names for month numbers < 10","title":"Fixed"},{"location":"mesh-data-transfer/configuration/configuration/","text":"Configuration Common configuration items Logging Logging functionality of all Data Transfer services is provided by Serilog library. \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Debug\", \"Override\": { \"Microsoft\": \"Warning\", \"System\": \"Warning\" } MinimumLevel options sets the minimum severity level of messages that will be put in the log. Serilog supports 5 different logging levels: Verbose , Debug , Information , Warning , Error and Fatal . This option can be changes at the runtime and will take effect immediately. }, \"Enrich\": [ \"WithMachineName\", \"WithProcessName\", \"WithThreadId\" ], Enrich specifies additional information that will be added to all log entries. For more information refer to enrichers documentation \"WriteTo\": [ WriteTo section specifies list of all destination that logs will be saved to. By default only destination is File . Other possible and useful option could be `Console. { \"Name\": \"File\", \"Args\": { \"path\": \".\\\\log.json\", \"formatter\": \"Serilog.Formatting.Json.JsonFormatter, Serilog\" path defines location and name of the log file. formatter defines the way of storing log data. By default logs are stored as a json file. For more options refer to formatters documentation . Other useful options in Args section are: - rollOnFileSizeLimit - enables log rotation when fileSizeLimitBytes is reached (bool, default is false). - fileSizeLimitBytes - specifies maximum size of log file in bytes (default is 1 GB). - retainedFileCountLimit - specifies how many log files will be kept. Default value is 31. Use null to disable the limit. - rollingInterval - enables log rotation when specific interval elapses (e.g. Day , Month , Year ) More information can be found in serilog file sink documentation . Brokers Configuration ImportExport services operate on AMQP entities. AMQP broker is a piece of software capable of relaying messages from one service to another. BrokersConfiguration configuration item allows the user to specify broker connection strings - we allow to specify more than one connection string. In case of connection failure, the service will choose the next connection string from the list and will try to establish a new connection. \"BrokersConfiguration\": { \"B1\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\", \"amqp://otherhost:5672\" ] }, \"B2\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\" ] } }, Each connection string should start with: - amqp:// - Non secure amqp connection will be created. Messages will be sent using AMQP protocol. - amqps:// - Secure amqp connection will be created. Messages will be sent using AMQP protocol. - Endpoint=sb:// - Instead of using AMQP protocol, Azure Service Bus communication library will be used for connection and messaging. We support RabbitMQ Virtual Host feature (see RabbitMQ docs ). Example Virtual Host configuration: \"BrokersConfiguration\": { \"B1\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\", \"amqp://otherhost:5672\" ], \"VirtualHost\": \"Virtus\" } }, Queues Configuration Trigger Relay and Mesh Amqp Relay allow configuration of queues that can be later assigned to various components. Each json object in Queues Configuration describes single queue. It can have any name that is unique within Queues Configuration . \"QueuesConfiguration\": { \"Queue1\": { \"Broker\": \"B1\", Broker is a reference to one of the broker names defined in the BrokersConfiguration , for example B1 . \"QueueName\": \"exportQueue\", QueueName specifies a queue to connect to on the broker. \"Role\": \"Sender\", Role specifies whether this queue will be used to send to or receive from. Valid values are: Sender , Receiver , Failure , Confirmation and ReimportSender . \"Priority\": 0 Priority is an integer used for indicating import queue priority. Based on this number (the lower the number, the more important given queue is) MAR will process messages placed in the queues with higher priority before messages placed in the queues with lower priorities. If the queue doesn't have the Priority parameter specified, its default priority is 50. Example: there are 3 import queues defined with following priorities: 0, 1 and for the last queue the Priority parameter is missing (it results to priority 50). Messages in the queue with priority 0 will be handled first, then messages in the queue with priority 1 and at the end the messages in the queue with priority 50. Kestrel Configuration Kestrel is an http server used by Trigger Relay , Export Data Store and Database Gateway in order to expose endpoints for receiving orders data and for health endpoints. \"Kestrel\": { \"Endpoints\": { \"Http\": { \"Url\": \"http://localhost:7000\" Url specifies address and port that should be used when accessing the service. For most cases it is reasonable to replace localhost with machine hostname . HttpEndpoints configuration \"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"https://localhost:20000/mesh\", \"ServerPrincipal\": \"HOST/server.mydomain.com\", \"TokenRefreshIntervalMinutes\": 30, \"RequestTimeout\": 60, \"MaxReceiveMessageSizeInBytes\": 16777216 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000/\" }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }, This part applies to Trigger Relay or Mesh Amqp Relay , depending on which export flow is in use. HttpEndpoints:Mesh:Uri contains address of Mesh server endpoint that will be used for all exports and imports of data. Use https in the Uri to enable Transport Layer Security (TLS) and communicate with Mesh over secure channel. HttpEndpoints:Mesh:ServerPrincipal field should be set if the user wants to enable Kerberos authentication. The value should be set to Kerberos server principal of the Mesh server. HttpEndpoints:Mesh:TokenRefreshIntervalMinutes is the refresh period of the Kerberos token. By default it is set to 30 minutes. HttpEndpoints:Mesh:MaxReceiveMessageSizeInBytes is an optional size limit for the messages received from Mesh (e.g. time series export response). Defaults to 4 MB (4194304 bytes) when not provided. The example extends the received message size limit to 16 MB. HttpEndpoints:ExportDataStore is an address of Export Data Store endpoint (formerly ExportWorker:ExportServiceAddress ). This is the address that will be used to send all timeseries export data, received from Mesh , in order to store it and create Message Log entries. HttpEndpoints:DatabaseGateway is the address of DatabaseGateway service endpoint. All of the endpoints above can specify an optional RequestTimeout attribute (defaults to 60 ). Database Configuration The Database Gateway service requires direct database access. Currently data required to access the database is stored in the configuration file. \"Database\": { \"User\": \"dbuser\", \"Password\": \"dbpass\", \"DataSource\": \"dbserver\", \"OpunKeyMode\": \"SHORNAME\" // legal values: SHORNAME/BANKACC/POSTACC/ESETT_ID, SHORNAME is default if not specified } Trigger Relay Specific Configuration: { \"AmqpSender\": { \"Queues\": [ \"ExportQueue\" ] }, AmqpSender is used to send export orders to the AMQP queues. Queues is expected to contains single Sender queue name defined in QueuesConfiguration configuration item. \"AdditionalPvplanPrefix\": { \"Separator\": \";\" }, AdditionalPvplanPrefix separator is a character used in Participant application export definition. It separates External Reference from prefix string being added to the PVPLAN data file names. \"ContentCode\": { \"Separator\": \";\" }, } ContentCode separator is a character used in Participant application export definition. It separates Product Code from exact protocol name ('APOR' or 'APOT') in case of APOR/APOT export. \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } HttpEndpoints:DatabaseGateway specifies the endpoint of Database Gateway service. It accepts an optional RequestTimeout attribute (defaults to 60 ). \"ParticipantSettings\": { \"DefaultSender\": 26 } ParticipantSettings:DefaultSender specifies the default sender to be used when exporting time series or availability data. The DefaultSender participant key is used as a fallback when the sender is not defined in the time series export definition or in the export request. Mesh Amqp Relay Specific Configuration: \"ImportWorker\": { \"Queues\": [ \"Q3\", \"Q4\", \"FailureQ\" ], \"ICC_TRANSLOG_DIR\": \"C:\\\\ICC_TRANSLOG_DIR\\\\\", \"ReimportEnabled\": false, \"PartialImportSuccess\": false }, ImportWorker is used to handle import requests. In order to work properly it needs Queues to contain a list of queues from QueuesConfiguration . One of the queues needs to be a Receiver queue which will be used to receive import orders. Second queues needs to be a Sender queue, it will be used for sending import status data. The third, optional queue, needs to be a Failure queue. Its use depends on FailedMessages node below. If ReimportEnabled flag is set to true , ICC_TRANSLOG_DIR is a directory where received import requests are kept for potential reimports. PartialImportSuccess is an optional flag that makes Mesh Data Transfer include <ImportSuccess>true</ImportSuccess> in the time series import reply when the import was partially successful. The default value is false , which means ImportSuccess is true only when all of the requested time series were imported correctly. \"ExportWorker\": { \"Queues\": [ \"Q1\", \"FailureQ\" ] }, ExportWorker is used to handle export requests. In order to work properly it needs Queues to contain a list of two queues from QueuesConfiguration . One of the queues needs to be a Receiver queue which will be used to receive export orders. Second queues needs to be a Sender queue, it will be used for sending export data. The Sender queue will be used only for timeseries exports that are defined as a StdExport and all Availability exports. More information about export types can be found in the Export Protocols section. \"MeshMonitor\": { \"MeshHealthEndpoint\": \"http://localhost:20000/meshHealth/health\", \"CheckInterval\": 5000 } MeshMonitor contains address of Mesh server health endpoint. It will be used to establish whether Mesh is in suitable condition to perform exports and imports. \"FailedMessages\": { \"UseFailureQueueOnInternalError\": true, \"UseFailureQueueOnExternalError\": false }, Internal errors are the ones that originated from inside Mesh AMQP Relay (for example XML / JSON parsing problem). External errors come from Mesh and EDS (like an Oracle issue). If set to true the problematic message will be sent to failure queue. Otherwise the application will try to put it back on the queue process it again. Export Data Store Specific Configuration: 'MercatoMapping' is used only for Bidding Strategy export protocol. It associates numbers with user-defined strings. They are used later in the Bidding Strategy export file to map timeseries values to strings. \"MercatoMapping\": { \"0\": \"MGP\", \"1\": \"MI1\", \"2\": \"MI2\", \"3\": \"MI3\", \"4\": \"MI4\", \"5\": \"MI5\", \"6\": \"MI6\", \"7\": \"MI7\", \"8\": \"\" }, UnitScheduleMapping is similar to MercatoMapping . It is used for Bidding Strategy export protocol as well. \"UnitScheduleMapping\": { \"A\": \"dummyA\", \"B\": \"dummyB\" }, StoragePerProtocol node contains storage settings for each protocol. StorageKinds valid values are File and Queue - it is allowed to specify the target storage: filesystem, AMQP/ServiceBus queue or both. Parameter called StoragePath specifies disk storage location in case of the StorageKinds array containing a File value. DestinationQueues is a (protocol, receiver)-to-queue mapping. It is a dictionary consisting of keys being export receiver identfiers and values being queue aliases arrays. When the DestinationQueues contains a key equal to an export receiver value for given export protocol, the export data will be sent to the queues in the respective array. In the StoragePerProtocol nodes there is also an array called DefaultQueues . If the DestinationQueues mapping does not provide target queue information needed, DefaultQueues values are used as target queues. It is allowed to have one of ( DestinationQueues , DefaultQueues ) empty, but not both. Another parameter for StoragePerProtocol nodes is DefaultDecimals . It defines the number of decimals that is saved in the exported time series values if the decimals parameter is not defined in the time series export definition. It is optional and currently it is only supported for EDIEL DELFOR, ExcelCSV and GS2 export types. ICC_TRANSLOG_DIR is a directory where export files are kept in order to look them up from MessageLog application. Please make sure that these directories are created. AvailabilityExportQueue is a reference to one of the queues defined in QueuesConfiguration item. \"Storage\": { \"StoragePerProtocol\": { \"PVPLAN\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"PVPLAN2023\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"StdExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"APORAPOTExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"2\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"BiddingTool\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"GS2\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\", \"DefaultDecimals\": 3 // optional, used when the time series export definition does not define the decimals parameter; for GS2 the default value is null (number of decimals not specified) }, \"EdielDelfor\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\", \"DefaultDecimals\": 2 // optional, used when the time series export definition does not define the decimals parameter; for EDIEL DELFOR the default value is 3 }, \"ExcelCSV\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" \"DefaultDecimals\": 2, // optional, used when the time series export definition does not define the decimals parameter; for Excel CSV the default value is 6 } }, \"ICC_TRANSLOG_DIR\": \"C:\\\\ICC_TRANSLOG_DIR\\\\\", \"AvailabilityExportQueue\": \"Q\", \"PvPlan2023\": false }, \"QueuesConfiguration\": { \"exportReplyQueue\": { \"Broker\": \"B1\", \"QueueName\": \"exportReplyQueue\", \"Role\": \"Sender\" }, \"someOtherQueue\": { \"Broker\": \"B1\", \"QueueName\": \"someOtherQueue\", \"Role\": \"Sender\" } }, HttpEndpoints:DatabaseGateway specifies the endpoint of Database Gateway service. It accepts an optional RequestTimeout attribute (defaults to 60 ). \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }","title":"Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#configuration","text":"","title":"Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#common-configuration-items","text":"","title":"Common configuration items"},{"location":"mesh-data-transfer/configuration/configuration/#logging","text":"Logging functionality of all Data Transfer services is provided by Serilog library. \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Debug\", \"Override\": { \"Microsoft\": \"Warning\", \"System\": \"Warning\" } MinimumLevel options sets the minimum severity level of messages that will be put in the log. Serilog supports 5 different logging levels: Verbose , Debug , Information , Warning , Error and Fatal . This option can be changes at the runtime and will take effect immediately. }, \"Enrich\": [ \"WithMachineName\", \"WithProcessName\", \"WithThreadId\" ], Enrich specifies additional information that will be added to all log entries. For more information refer to enrichers documentation \"WriteTo\": [ WriteTo section specifies list of all destination that logs will be saved to. By default only destination is File . Other possible and useful option could be `Console. { \"Name\": \"File\", \"Args\": { \"path\": \".\\\\log.json\", \"formatter\": \"Serilog.Formatting.Json.JsonFormatter, Serilog\" path defines location and name of the log file. formatter defines the way of storing log data. By default logs are stored as a json file. For more options refer to formatters documentation . Other useful options in Args section are: - rollOnFileSizeLimit - enables log rotation when fileSizeLimitBytes is reached (bool, default is false). - fileSizeLimitBytes - specifies maximum size of log file in bytes (default is 1 GB). - retainedFileCountLimit - specifies how many log files will be kept. Default value is 31. Use null to disable the limit. - rollingInterval - enables log rotation when specific interval elapses (e.g. Day , Month , Year ) More information can be found in serilog file sink documentation .","title":"Logging"},{"location":"mesh-data-transfer/configuration/configuration/#brokers-configuration","text":"ImportExport services operate on AMQP entities. AMQP broker is a piece of software capable of relaying messages from one service to another. BrokersConfiguration configuration item allows the user to specify broker connection strings - we allow to specify more than one connection string. In case of connection failure, the service will choose the next connection string from the list and will try to establish a new connection. \"BrokersConfiguration\": { \"B1\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\", \"amqp://otherhost:5672\" ] }, \"B2\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\" ] } }, Each connection string should start with: - amqp:// - Non secure amqp connection will be created. Messages will be sent using AMQP protocol. - amqps:// - Secure amqp connection will be created. Messages will be sent using AMQP protocol. - Endpoint=sb:// - Instead of using AMQP protocol, Azure Service Bus communication library will be used for connection and messaging. We support RabbitMQ Virtual Host feature (see RabbitMQ docs ). Example Virtual Host configuration: \"BrokersConfiguration\": { \"B1\": { \"ConnectionStrings\": [ \"amqp://localhost:5672\", \"amqp://otherhost:5672\" ], \"VirtualHost\": \"Virtus\" } },","title":"Brokers Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#queues-configuration","text":"Trigger Relay and Mesh Amqp Relay allow configuration of queues that can be later assigned to various components. Each json object in Queues Configuration describes single queue. It can have any name that is unique within Queues Configuration . \"QueuesConfiguration\": { \"Queue1\": { \"Broker\": \"B1\", Broker is a reference to one of the broker names defined in the BrokersConfiguration , for example B1 . \"QueueName\": \"exportQueue\", QueueName specifies a queue to connect to on the broker. \"Role\": \"Sender\", Role specifies whether this queue will be used to send to or receive from. Valid values are: Sender , Receiver , Failure , Confirmation and ReimportSender . \"Priority\": 0 Priority is an integer used for indicating import queue priority. Based on this number (the lower the number, the more important given queue is) MAR will process messages placed in the queues with higher priority before messages placed in the queues with lower priorities. If the queue doesn't have the Priority parameter specified, its default priority is 50. Example: there are 3 import queues defined with following priorities: 0, 1 and for the last queue the Priority parameter is missing (it results to priority 50). Messages in the queue with priority 0 will be handled first, then messages in the queue with priority 1 and at the end the messages in the queue with priority 50.","title":"Queues Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#kestrel-configuration","text":"Kestrel is an http server used by Trigger Relay , Export Data Store and Database Gateway in order to expose endpoints for receiving orders data and for health endpoints. \"Kestrel\": { \"Endpoints\": { \"Http\": { \"Url\": \"http://localhost:7000\" Url specifies address and port that should be used when accessing the service. For most cases it is reasonable to replace localhost with machine hostname .","title":"Kestrel Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#httpendpoints-configuration","text":"\"HttpEndpoints\": { \"Mesh\": { \"Uri\": \"https://localhost:20000/mesh\", \"ServerPrincipal\": \"HOST/server.mydomain.com\", \"TokenRefreshIntervalMinutes\": 30, \"RequestTimeout\": 60, \"MaxReceiveMessageSizeInBytes\": 16777216 }, \"ExportDataStore\": { \"Uri\": \"http://localhost:17000/\" }, \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }, This part applies to Trigger Relay or Mesh Amqp Relay , depending on which export flow is in use. HttpEndpoints:Mesh:Uri contains address of Mesh server endpoint that will be used for all exports and imports of data. Use https in the Uri to enable Transport Layer Security (TLS) and communicate with Mesh over secure channel. HttpEndpoints:Mesh:ServerPrincipal field should be set if the user wants to enable Kerberos authentication. The value should be set to Kerberos server principal of the Mesh server. HttpEndpoints:Mesh:TokenRefreshIntervalMinutes is the refresh period of the Kerberos token. By default it is set to 30 minutes. HttpEndpoints:Mesh:MaxReceiveMessageSizeInBytes is an optional size limit for the messages received from Mesh (e.g. time series export response). Defaults to 4 MB (4194304 bytes) when not provided. The example extends the received message size limit to 16 MB. HttpEndpoints:ExportDataStore is an address of Export Data Store endpoint (formerly ExportWorker:ExportServiceAddress ). This is the address that will be used to send all timeseries export data, received from Mesh , in order to store it and create Message Log entries. HttpEndpoints:DatabaseGateway is the address of DatabaseGateway service endpoint. All of the endpoints above can specify an optional RequestTimeout attribute (defaults to 60 ).","title":"HttpEndpoints configuration"},{"location":"mesh-data-transfer/configuration/configuration/#database-configuration","text":"The Database Gateway service requires direct database access. Currently data required to access the database is stored in the configuration file. \"Database\": { \"User\": \"dbuser\", \"Password\": \"dbpass\", \"DataSource\": \"dbserver\", \"OpunKeyMode\": \"SHORNAME\" // legal values: SHORNAME/BANKACC/POSTACC/ESETT_ID, SHORNAME is default if not specified }","title":"Database Configuration"},{"location":"mesh-data-transfer/configuration/configuration/#trigger-relay-specific-configuration","text":"{ \"AmqpSender\": { \"Queues\": [ \"ExportQueue\" ] }, AmqpSender is used to send export orders to the AMQP queues. Queues is expected to contains single Sender queue name defined in QueuesConfiguration configuration item. \"AdditionalPvplanPrefix\": { \"Separator\": \";\" }, AdditionalPvplanPrefix separator is a character used in Participant application export definition. It separates External Reference from prefix string being added to the PVPLAN data file names. \"ContentCode\": { \"Separator\": \";\" }, } ContentCode separator is a character used in Participant application export definition. It separates Product Code from exact protocol name ('APOR' or 'APOT') in case of APOR/APOT export. \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } } HttpEndpoints:DatabaseGateway specifies the endpoint of Database Gateway service. It accepts an optional RequestTimeout attribute (defaults to 60 ). \"ParticipantSettings\": { \"DefaultSender\": 26 } ParticipantSettings:DefaultSender specifies the default sender to be used when exporting time series or availability data. The DefaultSender participant key is used as a fallback when the sender is not defined in the time series export definition or in the export request.","title":"Trigger Relay Specific Configuration:"},{"location":"mesh-data-transfer/configuration/configuration/#mesh-amqp-relay-specific-configuration","text":"\"ImportWorker\": { \"Queues\": [ \"Q3\", \"Q4\", \"FailureQ\" ], \"ICC_TRANSLOG_DIR\": \"C:\\\\ICC_TRANSLOG_DIR\\\\\", \"ReimportEnabled\": false, \"PartialImportSuccess\": false }, ImportWorker is used to handle import requests. In order to work properly it needs Queues to contain a list of queues from QueuesConfiguration . One of the queues needs to be a Receiver queue which will be used to receive import orders. Second queues needs to be a Sender queue, it will be used for sending import status data. The third, optional queue, needs to be a Failure queue. Its use depends on FailedMessages node below. If ReimportEnabled flag is set to true , ICC_TRANSLOG_DIR is a directory where received import requests are kept for potential reimports. PartialImportSuccess is an optional flag that makes Mesh Data Transfer include <ImportSuccess>true</ImportSuccess> in the time series import reply when the import was partially successful. The default value is false , which means ImportSuccess is true only when all of the requested time series were imported correctly. \"ExportWorker\": { \"Queues\": [ \"Q1\", \"FailureQ\" ] }, ExportWorker is used to handle export requests. In order to work properly it needs Queues to contain a list of two queues from QueuesConfiguration . One of the queues needs to be a Receiver queue which will be used to receive export orders. Second queues needs to be a Sender queue, it will be used for sending export data. The Sender queue will be used only for timeseries exports that are defined as a StdExport and all Availability exports. More information about export types can be found in the Export Protocols section. \"MeshMonitor\": { \"MeshHealthEndpoint\": \"http://localhost:20000/meshHealth/health\", \"CheckInterval\": 5000 } MeshMonitor contains address of Mesh server health endpoint. It will be used to establish whether Mesh is in suitable condition to perform exports and imports. \"FailedMessages\": { \"UseFailureQueueOnInternalError\": true, \"UseFailureQueueOnExternalError\": false }, Internal errors are the ones that originated from inside Mesh AMQP Relay (for example XML / JSON parsing problem). External errors come from Mesh and EDS (like an Oracle issue). If set to true the problematic message will be sent to failure queue. Otherwise the application will try to put it back on the queue process it again.","title":"Mesh Amqp Relay Specific Configuration:"},{"location":"mesh-data-transfer/configuration/configuration/#export-data-store-specific-configuration","text":"'MercatoMapping' is used only for Bidding Strategy export protocol. It associates numbers with user-defined strings. They are used later in the Bidding Strategy export file to map timeseries values to strings. \"MercatoMapping\": { \"0\": \"MGP\", \"1\": \"MI1\", \"2\": \"MI2\", \"3\": \"MI3\", \"4\": \"MI4\", \"5\": \"MI5\", \"6\": \"MI6\", \"7\": \"MI7\", \"8\": \"\" }, UnitScheduleMapping is similar to MercatoMapping . It is used for Bidding Strategy export protocol as well. \"UnitScheduleMapping\": { \"A\": \"dummyA\", \"B\": \"dummyB\" }, StoragePerProtocol node contains storage settings for each protocol. StorageKinds valid values are File and Queue - it is allowed to specify the target storage: filesystem, AMQP/ServiceBus queue or both. Parameter called StoragePath specifies disk storage location in case of the StorageKinds array containing a File value. DestinationQueues is a (protocol, receiver)-to-queue mapping. It is a dictionary consisting of keys being export receiver identfiers and values being queue aliases arrays. When the DestinationQueues contains a key equal to an export receiver value for given export protocol, the export data will be sent to the queues in the respective array. In the StoragePerProtocol nodes there is also an array called DefaultQueues . If the DestinationQueues mapping does not provide target queue information needed, DefaultQueues values are used as target queues. It is allowed to have one of ( DestinationQueues , DefaultQueues ) empty, but not both. Another parameter for StoragePerProtocol nodes is DefaultDecimals . It defines the number of decimals that is saved in the exported time series values if the decimals parameter is not defined in the time series export definition. It is optional and currently it is only supported for EDIEL DELFOR, ExcelCSV and GS2 export types. ICC_TRANSLOG_DIR is a directory where export files are kept in order to look them up from MessageLog application. Please make sure that these directories are created. AvailabilityExportQueue is a reference to one of the queues defined in QueuesConfiguration item. \"Storage\": { \"StoragePerProtocol\": { \"PVPLAN\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"PVPLAN2023\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"StdExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"13\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"APORAPOTExport\": { \"StorageKinds\": [ \"Queue\" ], \"DestinationQueues\": { \"1\": [ \"exportReplyQueue\" ], \"2\": [ \"exportReplyQueue\", \"someOtherQueue\" ] }, \"DefaultQueues\": [ \"exportReplyQueue\" ] }, \"BiddingTool\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" }, \"GS2\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\", \"DefaultDecimals\": 3 // optional, used when the time series export definition does not define the decimals parameter; for GS2 the default value is null (number of decimals not specified) }, \"EdielDelfor\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\", \"DefaultDecimals\": 2 // optional, used when the time series export definition does not define the decimals parameter; for EDIEL DELFOR the default value is 3 }, \"ExcelCSV\": { \"StorageKinds\": [ \"File\" ], \"StorePath\": \"C:\\\\files\\\\\" \"DefaultDecimals\": 2, // optional, used when the time series export definition does not define the decimals parameter; for Excel CSV the default value is 6 } }, \"ICC_TRANSLOG_DIR\": \"C:\\\\ICC_TRANSLOG_DIR\\\\\", \"AvailabilityExportQueue\": \"Q\", \"PvPlan2023\": false }, \"QueuesConfiguration\": { \"exportReplyQueue\": { \"Broker\": \"B1\", \"QueueName\": \"exportReplyQueue\", \"Role\": \"Sender\" }, \"someOtherQueue\": { \"Broker\": \"B1\", \"QueueName\": \"someOtherQueue\", \"Role\": \"Sender\" } }, HttpEndpoints:DatabaseGateway specifies the endpoint of Database Gateway service. It accepts an optional RequestTimeout attribute (defaults to 60 ). \"HttpEndpoints\": { \"DatabaseGateway\": { \"Uri\": \"http://localhost:7137\" } }","title":"Export Data Store Specific Configuration:"},{"location":"mesh-data-transfer/general/general/","text":"General info Mesh Data Transfer solution enables users to perform time series and availability data exports and imports from a Mesh server. It uses AMQP protocol as an external communication method to guarantee high level of reliability and versatility. Mesh Data Transfer consists of four services - Trigger Relay , Mesh Amqp Relay , Export Data Store and Database Gateway . These services are provided as a separate installer/zip package. Trigger Relay Trigger Relay is an entry point for export orders sent from certain Volue products (eg. Participant, Nimbus). It offers HTTP endpoints for creating both availability and time series export orders. Mesh Amqp Relay Mesh Amqp Relay receives export and import orders from configured queues. It is responsible for communicating with Mesh server and then sending outcome of that communication to AMQP reply queues and/or Export Data Store . Export Data Store Export Data Store stores data received from Mesh Amqp Relay / Trigger Relay via HTTP endpoint. This data can be stored either as a file on a configured disk location or sent to the AMQP queue. This service is also responsible for saving export status to the Message Log and determining final outcome of the export operation. Database Gateway Database Gateway is responsible for database communication. It provides HTTP endpoints for other services to invoke predefined SQL queries. For more details see the DatabaseGateway README . Usage Time series export To invoke a Mesh time series export one has to post a HTTP request to Trigger Relay 's Order service. Minimal working example: curl.exe -s http://localhost:7000/Order -H \"Content-Type: application/json\" -d '[{\"Date\":\"2024-10-11T17:10:37\",\"Receiver\":\"DemoBase\",\"Keytab\":1,\"ValuesFrom\":\"2024-05-09T00:00:00\",\"ValuesTo\":\"2024-05-11T00:00:00\",\"Protocol\":126}]'.replace('\"', '\\\"') A prerequisite of a successful time series export is a pre-filled keytab9 database table with references to the time series we want to export. The keytab parameter refers to the taret keytab9 row. keytab9 is normally filled by the client application like Participant or Nimbus. Protocol denotes the export type. Possible options are: ID Protocol 121 PVPLAN 122 Bidding 123 Standard export 125 APOR/APOT 134 GS2 135 EDIEL DELFOR 137 Excel CSV Receiver can be either the name or the integer key ( opun_key ) of the receiver participant. Export sender The sender defined in the time series export definition (a \"sender host\") is used by Mesh Data Transfer to specify the sender of the time series data (the sender is then referenced in the Message Log or directly in case of some of the export types, like Standard export or GS2; moreover all the output is grouped by the senders (see below)). If the sender is not defined in the time series export definition, a default sender is selected (which is defined by ParticipantSettings/ICC_SENDER parameter in Trigger Relay configuration). There is also an option to specify the sender in the time series export request: curl.exe -s http://localhost:7000/Order -H \"Content-Type: application/json\" -d '[{\"Date\":\"2024-10-11T17:10:37\",\"Receiver\":\"DemoBase\",\"Sender\":\"Mesh\",Keytab\":1,\"ValuesFrom\":\"2024-05-09T00:00:00\",\"ValuesTo\":\"2024-05-11T00:00:00\",\"Protocol\":126}]'.replace('\"', '\\\"') In this case the exported time series will be limited to those that match the input sender parameter. When the time series export definition does not specify the sender host, it will be replaced with the input sender parameter (instead of the default sender). The same rules apply to Sender request parameter as to the Receiver parameter, i.e. it can be a name or an integer. Grouping of the output by sender If the time series included in a single time series export request refer to a different sender, these time series will be grouped into separate export results. Data Flow Message flow when importing data to Mesh : Message flow when exporting data from Mesh : Trigger Relay provides request tracking capability. A request ID is included in the response to the export request. It can be used to check the request status by sending HTTP GET to the Trigger Relay 's exportstatus/<ID> endpoint. Example: curl.exe -s http://localhost:7000/exportstatus/4bb1306d-5259-411a-8e28-2c41107d48c9 The Data Transfer services still support a legacy export flow, which involves Mesh AMQP Relay service and depends on an AMQP broker. In the legacy export flow, the request tracking capability is not present. Message flow when exporting data from Mesh with legacy export flow enabled:","title":"General"},{"location":"mesh-data-transfer/general/general/#general-info","text":"Mesh Data Transfer solution enables users to perform time series and availability data exports and imports from a Mesh server. It uses AMQP protocol as an external communication method to guarantee high level of reliability and versatility. Mesh Data Transfer consists of four services - Trigger Relay , Mesh Amqp Relay , Export Data Store and Database Gateway . These services are provided as a separate installer/zip package.","title":"General info"},{"location":"mesh-data-transfer/general/general/#trigger-relay","text":"Trigger Relay is an entry point for export orders sent from certain Volue products (eg. Participant, Nimbus). It offers HTTP endpoints for creating both availability and time series export orders.","title":"Trigger Relay"},{"location":"mesh-data-transfer/general/general/#mesh-amqp-relay","text":"Mesh Amqp Relay receives export and import orders from configured queues. It is responsible for communicating with Mesh server and then sending outcome of that communication to AMQP reply queues and/or Export Data Store .","title":"Mesh Amqp Relay"},{"location":"mesh-data-transfer/general/general/#export-data-store","text":"Export Data Store stores data received from Mesh Amqp Relay / Trigger Relay via HTTP endpoint. This data can be stored either as a file on a configured disk location or sent to the AMQP queue. This service is also responsible for saving export status to the Message Log and determining final outcome of the export operation.","title":"Export Data Store"},{"location":"mesh-data-transfer/general/general/#database-gateway","text":"Database Gateway is responsible for database communication. It provides HTTP endpoints for other services to invoke predefined SQL queries. For more details see the DatabaseGateway README .","title":"Database Gateway"},{"location":"mesh-data-transfer/general/general/#usage","text":"","title":"Usage"},{"location":"mesh-data-transfer/general/general/#time-series-export","text":"To invoke a Mesh time series export one has to post a HTTP request to Trigger Relay 's Order service. Minimal working example: curl.exe -s http://localhost:7000/Order -H \"Content-Type: application/json\" -d '[{\"Date\":\"2024-10-11T17:10:37\",\"Receiver\":\"DemoBase\",\"Keytab\":1,\"ValuesFrom\":\"2024-05-09T00:00:00\",\"ValuesTo\":\"2024-05-11T00:00:00\",\"Protocol\":126}]'.replace('\"', '\\\"') A prerequisite of a successful time series export is a pre-filled keytab9 database table with references to the time series we want to export. The keytab parameter refers to the taret keytab9 row. keytab9 is normally filled by the client application like Participant or Nimbus. Protocol denotes the export type. Possible options are: ID Protocol 121 PVPLAN 122 Bidding 123 Standard export 125 APOR/APOT 134 GS2 135 EDIEL DELFOR 137 Excel CSV Receiver can be either the name or the integer key ( opun_key ) of the receiver participant.","title":"Time series export"},{"location":"mesh-data-transfer/general/general/#export-sender","text":"The sender defined in the time series export definition (a \"sender host\") is used by Mesh Data Transfer to specify the sender of the time series data (the sender is then referenced in the Message Log or directly in case of some of the export types, like Standard export or GS2; moreover all the output is grouped by the senders (see below)). If the sender is not defined in the time series export definition, a default sender is selected (which is defined by ParticipantSettings/ICC_SENDER parameter in Trigger Relay configuration). There is also an option to specify the sender in the time series export request: curl.exe -s http://localhost:7000/Order -H \"Content-Type: application/json\" -d '[{\"Date\":\"2024-10-11T17:10:37\",\"Receiver\":\"DemoBase\",\"Sender\":\"Mesh\",Keytab\":1,\"ValuesFrom\":\"2024-05-09T00:00:00\",\"ValuesTo\":\"2024-05-11T00:00:00\",\"Protocol\":126}]'.replace('\"', '\\\"') In this case the exported time series will be limited to those that match the input sender parameter. When the time series export definition does not specify the sender host, it will be replaced with the input sender parameter (instead of the default sender). The same rules apply to Sender request parameter as to the Receiver parameter, i.e. it can be a name or an integer.","title":"Export sender"},{"location":"mesh-data-transfer/general/general/#grouping-of-the-output-by-sender","text":"If the time series included in a single time series export request refer to a different sender, these time series will be grouped into separate export results.","title":"Grouping of the output by sender"},{"location":"mesh-data-transfer/general/general/#data-flow","text":"Message flow when importing data to Mesh : Message flow when exporting data from Mesh : Trigger Relay provides request tracking capability. A request ID is included in the response to the export request. It can be used to check the request status by sending HTTP GET to the Trigger Relay 's exportstatus/<ID> endpoint. Example: curl.exe -s http://localhost:7000/exportstatus/4bb1306d-5259-411a-8e28-2c41107d48c9 The Data Transfer services still support a legacy export flow, which involves Mesh AMQP Relay service and depends on an AMQP broker. In the legacy export flow, the request tracking capability is not present. Message flow when exporting data from Mesh with legacy export flow enabled:","title":"Data Flow"}]}